#!/usr/bin/env python3
"""
Oasisä»»åŠ¡å®ç°æµ‹è¯•è„šæœ¬
==================

æµ‹è¯•Oasisä»»åŠ¡å®šä¹‰å’Œå®ç°æ˜¯å¦æ­£å¸¸å·¥ä½œï¼Œ
åŒ…æ‹¬é”™è¯¯ä¿¡æ¯æ£€æµ‹ã€ç¾¤ä½“ç«äº‰åˆ†æã€ä¿¡æ¯ä¼ æ’­ç­‰æ ¸å¿ƒåœºæ™¯ã€‚
"""

import sys
import os
import logging
import asyncio
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_imports():
    """æµ‹è¯•æ¨¡å—å¯¼å…¥"""
    logger.info("æµ‹è¯•Oasisä»»åŠ¡å®ç°æ¨¡å—å¯¼å…¥...")
    
    try:
        from demo.oasis_task_implementation import (
            OasisScenarioConfig,
            ScenarioPerformanceMetrics,
            ContentGenerationTask,
            MisinformationDetectionTask,
            GroupBehaviorAnalysisTask,
            OasisTaskScheduler,
            TaskPerformanceMonitor,
            EvolutionTrigger
        )
        logger.info("âœ“ Oasisä»»åŠ¡å®ç°æ¨¡å—å¯¼å…¥æˆåŠŸ")
        return True
    except ImportError as e:
        logger.error(f"âœ— Oasisä»»åŠ¡å®ç°æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False


def test_config():
    """æµ‹è¯•é…ç½®åˆ›å»º"""
    logger.info("æµ‹è¯•Oasisåœºæ™¯é…ç½®...")
    
    try:
        from demo.oasis_task_implementation import OasisScenarioConfig
        
        # æµ‹è¯•é»˜è®¤é…ç½®
        config = OasisScenarioConfig()
        logger.info(f"âœ“ é»˜è®¤é…ç½®åˆ›å»ºæˆåŠŸ: ç­–ç•¥={config.evolution_strategy}")
        
        # æµ‹è¯•è‡ªå®šä¹‰é…ç½®
        custom_config = OasisScenarioConfig(
            evolution_strategy="adaptive_compression",
            enable_lora=True,
            enable_kv_cache_compression=True,
            evolution_interval=5,
            performance_threshold=0.8
        )
        logger.info(f"âœ“ è‡ªå®šä¹‰é…ç½®åˆ›å»ºæˆåŠŸ: ç­–ç•¥={custom_config.evolution_strategy}, é˜ˆå€¼={custom_config.performance_threshold}")
        
        return True
    except Exception as e:
        logger.error(f"âœ— é…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_performance_metrics():
    """æµ‹è¯•æ€§èƒ½æŒ‡æ ‡"""
    logger.info("æµ‹è¯•æ€§èƒ½æŒ‡æ ‡...")
    
    try:
        from demo.oasis_task_implementation import ScenarioPerformanceMetrics
        
        # åˆ›å»ºæ€§èƒ½æŒ‡æ ‡
        metrics = ScenarioPerformanceMetrics(
            detection_accuracy=0.85,
            false_positive_rate=0.1,
            false_negative_rate=0.05,
            response_time=1.2,
            competition_prediction_accuracy=0.8,
            strategy_effectiveness=0.75,
            conflict_resolution_success=0.9,
            propagation_prediction_accuracy=0.82,
            influence_assessment_accuracy=0.78,
            path_analysis_quality=0.85,
            connection_optimization_effectiveness=0.7,
            network_stability_improvement=0.6,
            resource_utilization_efficiency=0.8
        )
        
        logger.info(f"âœ“ æ€§èƒ½æŒ‡æ ‡åˆ›å»ºæˆåŠŸ: æ£€æµ‹å‡†ç¡®ç‡={metrics.detection_accuracy}, å“åº”æ—¶é—´={metrics.response_time}")
        
        return True
    except Exception as e:
        logger.error(f"âœ— æ€§èƒ½æŒ‡æ ‡æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_task_creation():
    """æµ‹è¯•ä»»åŠ¡åˆ›å»º"""
    logger.info("æµ‹è¯•ä»»åŠ¡åˆ›å»º...")
    
    try:
        from sandgraph.core.self_evolving_oasis import create_self_evolving_oasis
        from demo.oasis_task_implementation import (
            ContentGenerationTask,
            MisinformationDetectionTask,
            GroupBehaviorAnalysisTask
        )
        
        # åˆ›å»ºè‡ªè¿›åŒ–LLM
        sandbox = create_self_evolving_oasis(
            evolution_strategy="multi_model",
            enable_lora=True,
            enable_kv_cache_compression=True,
            model_pool_size=3
        )
        evolving_llm = sandbox.evolving_llm
        
        # åˆ›å»ºä»»åŠ¡å®ä¾‹
        content_task = ContentGenerationTask(evolving_llm)
        detection_task = MisinformationDetectionTask(evolving_llm)
        competition_task = GroupBehaviorAnalysisTask(evolving_llm)
        
        logger.info("âœ“ ä»»åŠ¡å®ä¾‹åˆ›å»ºæˆåŠŸ")
        
        return True
    except Exception as e:
        logger.error(f"âœ— ä»»åŠ¡åˆ›å»ºæµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_content_generation():
    """æµ‹è¯•å†…å®¹ç”Ÿæˆä»»åŠ¡"""
    logger.info("æµ‹è¯•å†…å®¹ç”Ÿæˆä»»åŠ¡...")
    
    try:
        from sandgraph.core.self_evolving_oasis import create_self_evolving_oasis
        from demo.oasis_task_implementation import ContentGenerationTask
        
        # åˆ›å»ºè‡ªè¿›åŒ–LLM
        sandbox = create_self_evolving_oasis(
            evolution_strategy="multi_model",
            enable_lora=True,
            enable_kv_cache_compression=True
        )
        evolving_llm = sandbox.evolving_llm
        
        # åˆ›å»ºå†…å®¹ç”Ÿæˆä»»åŠ¡
        content_task = ContentGenerationTask(evolving_llm)
        
        # æµ‹è¯•å†…å®¹ç”Ÿæˆ
        agent_profile = {
            "personality": "tech_enthusiast",
            "interests": ["AI", "technology"],
            "activity_level": 0.8
        }
        
        target_audience = {
            "age_distribution": "18-35",
            "interests": ["technology", "AI"],
            "active_hours": "evening",
            "propagation_tendency": 0.8
        }
        
        result = await content_task.generate_content(
            agent_profile=agent_profile,
            content_type="news",
            target_audience=target_audience,
            propagation_goal="maximize_influence"
        )
        
        logger.info(f"âœ“ å†…å®¹ç”ŸæˆæˆåŠŸ: {result['content'][:50]}...")
        logger.info(f"  é¢„æœŸä¼ æ’­æ•ˆæœ: {result['expected_propagation']}")
        
        return True
    except Exception as e:
        logger.error(f"âœ— å†…å®¹ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_misinformation_detection():
    """æµ‹è¯•é”™è¯¯ä¿¡æ¯æ£€æµ‹ä»»åŠ¡"""
    logger.info("æµ‹è¯•é”™è¯¯ä¿¡æ¯æ£€æµ‹ä»»åŠ¡...")
    
    try:
        from sandgraph.core.self_evolving_oasis import create_self_evolving_oasis
        from demo.oasis_task_implementation import MisinformationDetectionTask
        
        # åˆ›å»ºè‡ªè¿›åŒ–LLM
        sandbox = create_self_evolving_oasis(
            evolution_strategy="multi_model",
            enable_lora=True,
            enable_kv_cache_compression=True
        )
        evolving_llm = sandbox.evolving_llm
        
        # åˆ›å»ºé”™è¯¯ä¿¡æ¯æ£€æµ‹ä»»åŠ¡
        detection_task = MisinformationDetectionTask(evolving_llm)
        
        # æµ‹è¯•é”™è¯¯ä¿¡æ¯æ£€æµ‹
        content = "æœ€æ–°ç ”ç©¶å‘ç°ï¼ŒæŸç§æ–°æŠ€æœ¯å¯èƒ½å¯¹äººä½“å¥åº·é€ æˆä¸¥é‡å±å®³ï¼Œä¸“å®¶å‘¼åç«‹å³åœæ­¢ä½¿ç”¨ã€‚"
        
        source_profile = {
            "credibility_score": 0.3,
            "history": "frequent_misinformation",
            "propagation_tendency": "high"
        }
        
        propagation_context = {
            "spread_velocity": "fast",
            "impact_scope": "large",
            "audience_reaction": "concerned"
        }
        
        fact_check_data = {
            "verified_sources": ["scientific_journal"],
            "contradicting_evidence": ["health_authority_statement"],
            "expert_opinions": ["safety_confirmed"]
        }
        
        result = await detection_task.detect_misinformation(
            content=content,
            source_profile=source_profile,
            propagation_context=propagation_context,
            fact_check_data=fact_check_data
        )
        
        logger.info(f"âœ“ é”™è¯¯ä¿¡æ¯æ£€æµ‹æˆåŠŸ: çœŸå®æ€§è¯„åˆ†={result['authenticity_score']:.3f}")
        logger.info(f"  é£é™©ç­‰çº§: {result['risk_level']}")
        logger.info(f"  æ˜¯å¦ä¸ºé”™è¯¯ä¿¡æ¯: {result['is_misinformation']}")
        
        return True
    except Exception as e:
        logger.error(f"âœ— é”™è¯¯ä¿¡æ¯æ£€æµ‹æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_group_competition_analysis():
    """æµ‹è¯•ç¾¤ä½“ç«äº‰åˆ†æä»»åŠ¡"""
    logger.info("æµ‹è¯•ç¾¤ä½“ç«äº‰åˆ†æä»»åŠ¡...")
    
    try:
        from sandgraph.core.self_evolving_oasis import create_self_evolving_oasis
        from demo.oasis_task_implementation import GroupBehaviorAnalysisTask
        
        # åˆ›å»ºè‡ªè¿›åŒ–LLM
        sandbox = create_self_evolving_oasis(
            evolution_strategy="multi_model",
            enable_lora=True,
            enable_kv_cache_compression=True
        )
        evolving_llm = sandbox.evolving_llm
        
        # åˆ›å»ºç¾¤ä½“ç«äº‰åˆ†æä»»åŠ¡
        competition_task = GroupBehaviorAnalysisTask(evolving_llm)
        
        # æµ‹è¯•ç¾¤ä½“ç«äº‰åˆ†æ
        group_a = {
            "size": 5000,
            "influence": 0.7,
            "strategy_tendency": "aggressive",
            "activity_level": 0.8
        }
        
        group_b = {
            "size": 3000,
            "influence": 0.6,
            "strategy_tendency": "defensive",
            "activity_level": 0.7
        }
        
        competition_history = [
            {"type": "content_battle", "winner": "group_a", "timestamp": 1234567890},
            {"type": "influence_contest", "winner": "group_b", "timestamp": 1234567891}
        ]
        
        network_state = {
            "total_users": 100000,
            "active_users": 80000,
            "network_density": 0.01
        }
        
        result = await competition_task.analyze_competition_behavior(
            group_a=group_a,
            group_b=group_b,
            competition_history=competition_history,
            network_state=network_state
        )
        
        logger.info(f"âœ“ ç¾¤ä½“ç«äº‰åˆ†ææˆåŠŸ: ç«äº‰å¼ºåº¦={result['competition_intensity']:.3f}")
        logger.info(f"  ç¾¤ä½“Aç­–ç•¥: {result['group_a_strategy']}")
        logger.info(f"  ç¾¤ä½“Bç­–ç•¥: {result['group_b_strategy']}")
        logger.info(f"  å†²çªå‡çº§é£é™©: {result['conflict_escalation_risk']}")
        
        return True
    except Exception as e:
        logger.error(f"âœ— ç¾¤ä½“ç«äº‰åˆ†ææµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_task_scheduler():
    """æµ‹è¯•ä»»åŠ¡è°ƒåº¦å™¨"""
    logger.info("æµ‹è¯•ä»»åŠ¡è°ƒåº¦å™¨...")
    
    try:
        from sandgraph.core.self_evolving_oasis import create_self_evolving_oasis
        from demo.oasis_task_implementation import OasisTaskScheduler, OasisScenarioConfig
        
        # åˆ›å»ºé…ç½®
        config = OasisScenarioConfig(
            evolution_strategy="multi_model",
            enable_lora=True,
            enable_kv_cache_compression=True
        )
        
        # åˆ›å»ºè‡ªè¿›åŒ–LLM
        sandbox = create_self_evolving_oasis(
            evolution_strategy=config.evolution_strategy,
            enable_lora=config.enable_lora,
            enable_kv_cache_compression=config.enable_kv_cache_compression
        )
        evolving_llm = sandbox.evolving_llm
        
        # åˆ›å»ºä»»åŠ¡è°ƒåº¦å™¨
        scheduler = OasisTaskScheduler(evolving_llm, config)
        
        logger.info("âœ“ ä»»åŠ¡è°ƒåº¦å™¨åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•åœºæ™¯æ‰§è¡Œ
        scenario_data = {
            "content": "æµ‹è¯•å†…å®¹",
            "source_profile": {"credibility_score": 0.5},
            "propagation_context": {"spread_velocity": "medium"},
            "fact_check_data": {"verified_sources": []}
        }
        
        result = await scheduler.execute_scenario(
            scenario_type="misinformation_spread",
            scenario_data=scenario_data
        )
        
        logger.info(f"âœ“ åœºæ™¯æ‰§è¡ŒæˆåŠŸ: æˆåŠŸä»»åŠ¡æ•°={result['successful_tasks']}/{result['total_tasks']}")
        logger.info(f"  å¹³å‡æ€§èƒ½: {result['average_performance']:.3f}")
        
        return True
    except Exception as e:
        logger.error(f"âœ— ä»»åŠ¡è°ƒåº¦å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_performance_monitor():
    """æµ‹è¯•æ€§èƒ½ç›‘æ§å™¨"""
    logger.info("æµ‹è¯•æ€§èƒ½ç›‘æ§å™¨...")
    
    try:
        from demo.oasis_task_implementation import TaskPerformanceMonitor
        
        # åˆ›å»ºç›‘æ§å™¨
        monitor = TaskPerformanceMonitor()
        
        # è®°å½•æ€§èƒ½æ•°æ®
        monitor.record_task_performance("misinformation_detection", {
            "authenticity_score": 0.8,
            "is_misinformation": False,
            "performance_score": 0.9
        })
        
        monitor.record_task_performance("group_behavior_analysis", {
            "competition_intensity": 0.7,
            "performance_score": 0.8
        })
        
        # åˆ†ææ€§èƒ½è¶‹åŠ¿
        trends = monitor.analyze_scenario_trends("misinformation_spread")
        logger.info(f"âœ“ æ€§èƒ½è¶‹åŠ¿åˆ†ææˆåŠŸ: {trends['performance_trend']}")
        
        return True
    except Exception as e:
        logger.error(f"âœ— æ€§èƒ½ç›‘æ§å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_evolution_trigger():
    """æµ‹è¯•è¿›åŒ–è§¦å‘å™¨"""
    logger.info("æµ‹è¯•è¿›åŒ–è§¦å‘å™¨...")
    
    try:
        from demo.oasis_task_implementation import EvolutionTrigger
        
        # åˆ›å»ºè¿›åŒ–è§¦å‘å™¨
        trigger = EvolutionTrigger()
        
        # æµ‹è¯•è¿›åŒ–è§¦å‘
        high_performance_result = {"performance_score": 0.9}
        low_performance_result = {"performance_score": 0.5}
        
        should_evolve_high = trigger.should_evolve(high_performance_result)
        should_evolve_low = trigger.should_evolve(low_performance_result)
        
        logger.info(f"âœ“ è¿›åŒ–è§¦å‘æµ‹è¯•æˆåŠŸ:")
        logger.info(f"  é«˜æ€§èƒ½ç»“æœè§¦å‘è¿›åŒ–: {should_evolve_high}")
        logger.info(f"  ä½æ€§èƒ½ç»“æœè§¦å‘è¿›åŒ–: {should_evolve_low}")
        
        return True
    except Exception as e:
        logger.error(f"âœ— è¿›åŒ–è§¦å‘å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_integration():
    """æµ‹è¯•é›†æˆåŠŸèƒ½"""
    logger.info("æµ‹è¯•é›†æˆåŠŸèƒ½...")
    
    try:
        from sandgraph.core.self_evolving_oasis import create_self_evolving_oasis
        from demo.oasis_task_implementation import (
            OasisTaskScheduler,
            OasisScenarioConfig
        )
        
        # åˆ›å»ºé…ç½®
        config = OasisScenarioConfig(
            evolution_strategy="multi_model",
            enable_lora=True,
            enable_kv_cache_compression=True,
            evolution_interval=3
        )
        
        # åˆ›å»ºè‡ªè¿›åŒ–LLM
        sandbox = create_self_evolving_oasis(
            evolution_strategy=config.evolution_strategy,
            enable_lora=config.enable_lora,
            enable_kv_cache_compression=config.enable_kv_cache_compression
        )
        evolving_llm = sandbox.evolving_llm
        
        # åˆ›å»ºä»»åŠ¡è°ƒåº¦å™¨
        scheduler = OasisTaskScheduler(evolving_llm, config)
        
        # æ‰§è¡Œå¤šä¸ªåœºæ™¯
        scenarios = [
            {
                "name": "é”™è¯¯ä¿¡æ¯ä¼ æ’­æ£€æµ‹",
                "type": "misinformation_spread",
                "data": {
                    "content": "è™šå‡æ–°é—»å†…å®¹...",
                    "source_profile": {"credibility_score": 0.3},
                    "propagation_context": {"spread_velocity": "fast"},
                    "fact_check_data": {"verified_sources": []}
                }
            },
            {
                "name": "ç¾¤ä½“ç«äº‰åˆ†æ",
                "type": "group_competition",
                "data": {
                    "group_a": {"size": 5000, "influence": 0.7},
                    "group_b": {"size": 3000, "influence": 0.6},
                    "competition_history": [],
                    "network_state": {"total_users": 100000}
                }
            },
            {
                "name": "ä¿¡æ¯ä¼ æ’­é¢„æµ‹",
                "type": "information_propagation",
                "data": {
                    "agent_profile": {"personality": "influencer"},
                    "content_type": "news",
                    "target_audience": {"propagation_tendency": 0.8},
                    "propagation_goal": "maximize_influence"
                }
            }
        ]
        
        results = []
        for scenario in scenarios:
            logger.info(f"æ‰§è¡Œåœºæ™¯: {scenario['name']}")
            result = await scheduler.execute_scenario(
                scenario_type=scenario["type"],
                scenario_data=scenario["data"]
            )
            results.append(result)
        
        # åˆ†æç»“æœ
        total_tasks = sum(r["total_tasks"] for r in results)
        successful_tasks = sum(r["successful_tasks"] for r in results)
        avg_performance = sum(r["average_performance"] for r in results) / len(results)
        
        logger.info(f"âœ“ é›†æˆæµ‹è¯•æˆåŠŸ:")
        logger.info(f"  æ€»ä»»åŠ¡æ•°: {total_tasks}")
        logger.info(f"  æˆåŠŸä»»åŠ¡æ•°: {successful_tasks}")
        logger.info(f"  å¹³å‡æ€§èƒ½: {avg_performance:.3f}")
        logger.info(f"  è¿›åŒ–æ­¥éª¤: {sandbox.evolving_llm.get_evolution_stats()['evolution_step']}")
        
        return True
    except Exception as e:
        logger.error(f"âœ— é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False


async def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("å¼€å§‹è¿è¡ŒOasisä»»åŠ¡å®ç°æµ‹è¯•...")
    
    # åŒæ­¥æµ‹è¯•
    sync_tests = [
        test_imports,
        test_config,
        test_performance_metrics,
        test_performance_monitor,
        test_evolution_trigger
    ]
    
    # å¼‚æ­¥æµ‹è¯•
    async_tests = [
        test_task_creation,
        test_content_generation,
        test_misinformation_detection,
        test_group_competition_analysis,
        test_task_scheduler,
        test_integration
    ]
    
    passed = 0
    total = len(sync_tests) + len(async_tests)
    
    # è¿è¡ŒåŒæ­¥æµ‹è¯•
    for test in sync_tests:
        try:
            if test():
                passed += 1
            logger.info("-" * 50)
        except Exception as e:
            logger.error(f"æµ‹è¯• {test.__name__} è¿è¡Œå¼‚å¸¸: {e}")
            logger.info("-" * 50)
    
    # è¿è¡Œå¼‚æ­¥æµ‹è¯•
    for test in async_tests:
        try:
            if await test():
                passed += 1
            logger.info("-" * 50)
        except Exception as e:
            logger.error(f"æµ‹è¯• {test.__name__} è¿è¡Œå¼‚å¸¸: {e}")
            logger.info("-" * 50)
    
    logger.info(f"æµ‹è¯•å®Œæˆ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Oasisä»»åŠ¡å®ç°åŠŸèƒ½æ­£å¸¸ã€‚")
        return True
    else:
        logger.warning("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½ã€‚")
        return False


if __name__ == "__main__":
    success = asyncio.run(run_all_tests())
    sys.exit(0 if success else 1) 