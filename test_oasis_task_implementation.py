#!/usr/bin/env python3
"""
Oasisä»»åŠ¡å®ç°æµ‹è¯•è„šæœ¬
==================

æµ‹è¯•Oasisä»»åŠ¡å®šä¹‰å’Œå®ç°æ˜¯å¦æ­£å¸¸å·¥ä½œï¼Œ
åŒ…æ‹¬å†…å®¹ç”Ÿæˆã€è¡Œä¸ºåˆ†æã€ç¤¾äº¤åŠ¨æ€ç­‰æ ¸å¿ƒä»»åŠ¡ã€‚
"""

import sys
import os
import logging
import asyncio
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_imports():
    """æµ‹è¯•æ¨¡å—å¯¼å…¥"""
    logger.info("æµ‹è¯•Oasisä»»åŠ¡å®ç°æ¨¡å—å¯¼å…¥...")
    
    try:
        from demo.oasis_task_implementation import (
            OasisTaskConfig,
            TaskPerformanceMetrics,
            ContentGenerationTask,
            BehaviorAnalysisTask,
            SocialDynamicsTask,
            OasisTaskScheduler,
            TaskMonitor
        )
        logger.info("âœ“ Oasisä»»åŠ¡å®ç°æ¨¡å—å¯¼å…¥æˆåŠŸ")
        return True
    except ImportError as e:
        logger.error(f"âœ— Oasisä»»åŠ¡å®ç°æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False


def test_config():
    """æµ‹è¯•é…ç½®åˆ›å»º"""
    logger.info("æµ‹è¯•Oasisä»»åŠ¡é…ç½®...")
    
    try:
        from demo.oasis_task_implementation import OasisTaskConfig
        
        # æµ‹è¯•é»˜è®¤é…ç½®
        config = OasisTaskConfig()
        logger.info(f"âœ“ é»˜è®¤é…ç½®åˆ›å»ºæˆåŠŸ: ç­–ç•¥={config.evolution_strategy}")
        
        # æµ‹è¯•è‡ªå®šä¹‰é…ç½®
        custom_config = OasisTaskConfig(
            evolution_strategy="adaptive_compression",
            enable_lora=True,
            enable_kv_cache_compression=True,
            evolution_interval=5,
            performance_threshold=0.8
        )
        logger.info(f"âœ“ è‡ªå®šä¹‰é…ç½®åˆ›å»ºæˆåŠŸ: ç­–ç•¥={custom_config.evolution_strategy}, é˜ˆå€¼={custom_config.performance_threshold}")
        
        return True
    except Exception as e:
        logger.error(f"âœ— é…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_performance_metrics():
    """æµ‹è¯•æ€§èƒ½æŒ‡æ ‡"""
    logger.info("æµ‹è¯•æ€§èƒ½æŒ‡æ ‡...")
    
    try:
        from demo.oasis_task_implementation import TaskPerformanceMetrics
        
        # åˆ›å»ºæ€§èƒ½æŒ‡æ ‡
        metrics = TaskPerformanceMetrics(
            accuracy=0.85,
            precision=0.82,
            recall=0.88,
            f1_score=0.85,
            response_time=1.2,
            throughput=100.0,
            resource_usage=0.6,
            content_quality=0.9,
            user_satisfaction=0.8,
            engagement_rate=0.75,
            evolution_progress=0.6,
            adaptation_speed=0.7,
            learning_efficiency=0.8
        )
        
        logger.info(f"âœ“ æ€§èƒ½æŒ‡æ ‡åˆ›å»ºæˆåŠŸ: å‡†ç¡®ç‡={metrics.accuracy}, å“åº”æ—¶é—´={metrics.response_time}")
        
        return True
    except Exception as e:
        logger.error(f"âœ— æ€§èƒ½æŒ‡æ ‡æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_task_creation():
    """æµ‹è¯•ä»»åŠ¡åˆ›å»º"""
    logger.info("æµ‹è¯•ä»»åŠ¡åˆ›å»º...")
    
    try:
        from sandgraph.core.self_evolving_oasis import create_self_evolving_oasis
        from demo.oasis_task_implementation import (
            ContentGenerationTask,
            BehaviorAnalysisTask,
            SocialDynamicsTask
        )
        
        # åˆ›å»ºè‡ªè¿›åŒ–LLM
        sandbox = create_self_evolving_oasis(
            evolution_strategy="multi_model",
            enable_lora=True,
            enable_kv_cache_compression=True,
            model_pool_size=3
        )
        evolving_llm = sandbox.evolving_llm
        
        # åˆ›å»ºä»»åŠ¡å®ä¾‹
        content_task = ContentGenerationTask(evolving_llm)
        behavior_task = BehaviorAnalysisTask(evolving_llm)
        dynamics_task = SocialDynamicsTask(evolving_llm)
        
        logger.info("âœ“ ä»»åŠ¡å®ä¾‹åˆ›å»ºæˆåŠŸ")
        
        return True
    except Exception as e:
        logger.error(f"âœ— ä»»åŠ¡åˆ›å»ºæµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_content_generation():
    """æµ‹è¯•å†…å®¹ç”Ÿæˆä»»åŠ¡"""
    logger.info("æµ‹è¯•å†…å®¹ç”Ÿæˆä»»åŠ¡...")
    
    try:
        from sandgraph.core.self_evolving_oasis import create_self_evolving_oasis
        from demo.oasis_task_implementation import ContentGenerationTask
        
        # åˆ›å»ºè‡ªè¿›åŒ–LLM
        sandbox = create_self_evolving_oasis(
            evolution_strategy="multi_model",
            enable_lora=True,
            enable_kv_cache_compression=True
        )
        evolving_llm = sandbox.evolving_llm
        
        # åˆ›å»ºå†…å®¹ç”Ÿæˆä»»åŠ¡
        content_task = ContentGenerationTask(evolving_llm)
        
        # æµ‹è¯•å†…å®¹ç”Ÿæˆ
        agent_profile = {
            "personality": "tech_enthusiast",
            "interests": ["AI", "technology"],
            "activity_level": 0.8
        }
        
        context = {
            "platform": "reddit",
            "topic": "AI technology",
            "trends": ["AI", "social media", "technology"]
        }
        
        content = await content_task.generate_content(agent_profile, context)
        
        logger.info(f"âœ“ å†…å®¹ç”ŸæˆæˆåŠŸ: {content[:50]}...")
        
        return True
    except Exception as e:
        logger.error(f"âœ— å†…å®¹ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_behavior_analysis():
    """æµ‹è¯•è¡Œä¸ºåˆ†æä»»åŠ¡"""
    logger.info("æµ‹è¯•è¡Œä¸ºåˆ†æä»»åŠ¡...")
    
    try:
        from sandgraph.core.self_evolving_oasis import create_self_evolving_oasis
        from demo.oasis_task_implementation import BehaviorAnalysisTask
        
        # åˆ›å»ºè‡ªè¿›åŒ–LLM
        sandbox = create_self_evolving_oasis(
            evolution_strategy="multi_model",
            enable_lora=True,
            enable_kv_cache_compression=True
        )
        evolving_llm = sandbox.evolving_llm
        
        # åˆ›å»ºè¡Œä¸ºåˆ†æä»»åŠ¡
        behavior_task = BehaviorAnalysisTask(evolving_llm)
        
        # æµ‹è¯•è¡Œä¸ºåˆ†æ
        agent_actions = [
            {"type": "post", "content": "Hello world", "timestamp": 1234567890},
            {"type": "like", "target": "post_123", "timestamp": 1234567891},
            {"type": "comment", "content": "Great post!", "timestamp": 1234567892}
        ]
        
        network_state = {
            "total_users": 1000,
            "active_users": 800,
            "posts": 5000,
            "interactions": 15000
        }
        
        analysis_result = await behavior_task.analyze_behavior(agent_actions, network_state)
        
        logger.info(f"âœ“ è¡Œä¸ºåˆ†ææˆåŠŸ: {analysis_result}")
        
        return True
    except Exception as e:
        logger.error(f"âœ— è¡Œä¸ºåˆ†ææµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_social_dynamics():
    """æµ‹è¯•ç¤¾äº¤åŠ¨æ€ä»»åŠ¡"""
    logger.info("æµ‹è¯•ç¤¾äº¤åŠ¨æ€ä»»åŠ¡...")
    
    try:
        from sandgraph.core.self_evolving_oasis import create_self_evolving_oasis
        from demo.oasis_task_implementation import SocialDynamicsTask
        
        # åˆ›å»ºè‡ªè¿›åŒ–LLM
        sandbox = create_self_evolving_oasis(
            evolution_strategy="multi_model",
            enable_lora=True,
            enable_kv_cache_compression=True
        )
        evolving_llm = sandbox.evolving_llm
        
        # åˆ›å»ºç¤¾äº¤åŠ¨æ€ä»»åŠ¡
        dynamics_task = SocialDynamicsTask(evolving_llm)
        
        # æµ‹è¯•ç¤¾äº¤åŠ¨æ€ä¼˜åŒ–
        network_graph = {
            "nodes": 1000,
            "edges": 5000,
            "density": 0.01,
            "clustering_coefficient": 0.3
        }
        
        agent_states = {
            "active": 800,
            "inactive": 200,
            "engaged": 600,
            "disengaged": 400
        }
        
        optimization_result = await dynamics_task.optimize_social_dynamics(network_graph, agent_states)
        
        logger.info(f"âœ“ ç¤¾äº¤åŠ¨æ€ä¼˜åŒ–æˆåŠŸ: {optimization_result}")
        
        return True
    except Exception as e:
        logger.error(f"âœ— ç¤¾äº¤åŠ¨æ€æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_task_scheduler():
    """æµ‹è¯•ä»»åŠ¡è°ƒåº¦å™¨"""
    logger.info("æµ‹è¯•ä»»åŠ¡è°ƒåº¦å™¨...")
    
    try:
        from sandgraph.core.self_evolving_oasis import create_self_evolving_oasis
        from demo.oasis_task_implementation import OasisTaskScheduler, OasisTaskConfig
        
        # åˆ›å»ºé…ç½®
        config = OasisTaskConfig(
            evolution_strategy="multi_model",
            enable_lora=True,
            enable_kv_cache_compression=True
        )
        
        # åˆ›å»ºè‡ªè¿›åŒ–LLM
        sandbox = create_self_evolving_oasis(
            evolution_strategy=config.evolution_strategy,
            enable_lora=config.enable_lora,
            enable_kv_cache_compression=config.enable_kv_cache_compression
        )
        evolving_llm = sandbox.evolving_llm
        
        # åˆ›å»ºä»»åŠ¡è°ƒåº¦å™¨
        scheduler = OasisTaskScheduler(evolving_llm, config)
        
        logger.info("âœ“ ä»»åŠ¡è°ƒåº¦å™¨åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•ä»»åŠ¡æ‰§è¡Œ
        content_result = await scheduler.execute_task("content_generation", {
            "agent_profile": {"personality": "tech_enthusiast"},
            "context": {"platform": "reddit", "topic": "AI"}
        })
        
        logger.info(f"âœ“ ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ: {content_result['success']}")
        
        # æµ‹è¯•æ€§èƒ½ç»Ÿè®¡
        stats = scheduler.get_performance_stats()
        logger.info(f"âœ“ æ€§èƒ½ç»Ÿè®¡è·å–æˆåŠŸ: æ€»ä»»åŠ¡æ•°={stats['total_tasks']}")
        
        return True
    except Exception as e:
        logger.error(f"âœ— ä»»åŠ¡è°ƒåº¦å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_task_monitor():
    """æµ‹è¯•ä»»åŠ¡ç›‘æ§å™¨"""
    logger.info("æµ‹è¯•ä»»åŠ¡ç›‘æ§å™¨...")
    
    try:
        from demo.oasis_task_implementation import TaskMonitor
        
        # åˆ›å»ºç›‘æ§å™¨
        monitor = TaskMonitor()
        
        # è®°å½•æ€§èƒ½æ•°æ®
        monitor.record_task_performance("content_generation", {
            "score": 0.8,
            "response_time": 1.5,
            "success": True
        })
        
        monitor.record_task_performance("behavior_analysis", {
            "score": 0.7,
            "response_time": 2.0,
            "success": True
        })
        
        # åˆ†ææ€§èƒ½è¶‹åŠ¿
        trends = monitor.analyze_performance_trends()
        logger.info(f"âœ“ æ€§èƒ½è¶‹åŠ¿åˆ†ææˆåŠŸ: {trends['trend']}")
        
        # æµ‹è¯•è¿›åŒ–è§¦å‘
        should_evolve = monitor.trigger_evolution(0.9)  # é«˜é˜ˆå€¼
        logger.info(f"âœ“ è¿›åŒ–è§¦å‘æ£€æŸ¥æˆåŠŸ: {should_evolve}")
        
        return True
    except Exception as e:
        logger.error(f"âœ— ä»»åŠ¡ç›‘æ§å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_integration():
    """æµ‹è¯•é›†æˆåŠŸèƒ½"""
    logger.info("æµ‹è¯•é›†æˆåŠŸèƒ½...")
    
    try:
        from sandgraph.core.self_evolving_oasis import create_self_evolving_oasis
        from demo.oasis_task_implementation import (
            OasisTaskScheduler,
            OasisTaskConfig,
            TaskMonitor
        )
        
        # åˆ›å»ºé…ç½®
        config = OasisTaskConfig(
            evolution_strategy="multi_model",
            enable_lora=True,
            enable_kv_cache_compression=True,
            evolution_interval=3
        )
        
        # åˆ›å»ºè‡ªè¿›åŒ–LLM
        sandbox = create_self_evolving_oasis(
            evolution_strategy=config.evolution_strategy,
            enable_lora=config.enable_lora,
            enable_kv_cache_compression=config.enable_kv_cache_compression
        )
        evolving_llm = sandbox.evolving_llm
        
        # åˆ›å»ºä»»åŠ¡è°ƒåº¦å™¨å’Œç›‘æ§å™¨
        scheduler = OasisTaskScheduler(evolving_llm, config)
        monitor = TaskMonitor()
        
        # æ‰§è¡Œæ‰¹é‡ä»»åŠ¡
        tasks = [
            {
                "type": "content_generation",
                "data": {
                    "agent_profile": {"personality": "tech_enthusiast"},
                    "context": {"platform": "reddit", "topic": "AI"}
                }
            },
            {
                "type": "behavior_analysis",
                "data": {
                    "agent_actions": [{"type": "post", "content": "Hello"}],
                    "network_state": {"total_users": 1000, "active_users": 800}
                }
            },
            {
                "type": "social_dynamics",
                "data": {
                    "network_graph": {"nodes": 1000, "edges": 5000},
                    "agent_states": {"active": 800, "inactive": 200}
                }
            }
        ]
        
        results = await scheduler.execute_task_batch(tasks)
        
        # è®°å½•æ€§èƒ½
        for result in results:
            if result["success"]:
                monitor.record_task_performance(result["task_type"], {
                    "score": 0.8,
                    "response_time": 1.5,
                    "success": True
                })
        
        # åˆ†æç»“æœ
        scheduler_stats = scheduler.get_performance_stats()
        monitor_trends = monitor.analyze_performance_trends()
        evolution_stats = sandbox.evolving_llm.get_evolution_stats()
        
        logger.info(f"âœ“ é›†æˆæµ‹è¯•æˆåŠŸ:")
        logger.info(f"  è°ƒåº¦å™¨ç»Ÿè®¡: {scheduler_stats['total_tasks']} ä»»åŠ¡, æˆåŠŸç‡ {scheduler_stats['success_rate']:.3f}")
        logger.info(f"  ç›‘æ§è¶‹åŠ¿: {monitor_trends['trend']}")
        logger.info(f"  è¿›åŒ–æ­¥éª¤: {evolution_stats['evolution_step']}")
        
        return True
    except Exception as e:
        logger.error(f"âœ— é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False


async def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("å¼€å§‹è¿è¡ŒOasisä»»åŠ¡å®ç°æµ‹è¯•...")
    
    # åŒæ­¥æµ‹è¯•
    sync_tests = [
        test_imports,
        test_config,
        test_performance_metrics,
        test_task_monitor
    ]
    
    # å¼‚æ­¥æµ‹è¯•
    async_tests = [
        test_task_creation,
        test_content_generation,
        test_behavior_analysis,
        test_social_dynamics,
        test_task_scheduler,
        test_integration
    ]
    
    passed = 0
    total = len(sync_tests) + len(async_tests)
    
    # è¿è¡ŒåŒæ­¥æµ‹è¯•
    for test in sync_tests:
        try:
            if test():
                passed += 1
            logger.info("-" * 50)
        except Exception as e:
            logger.error(f"æµ‹è¯• {test.__name__} è¿è¡Œå¼‚å¸¸: {e}")
            logger.info("-" * 50)
    
    # è¿è¡Œå¼‚æ­¥æµ‹è¯•
    for test in async_tests:
        try:
            if await test():
                passed += 1
            logger.info("-" * 50)
        except Exception as e:
            logger.error(f"æµ‹è¯• {test.__name__} è¿è¡Œå¼‚å¸¸: {e}")
            logger.info("-" * 50)
    
    logger.info(f"æµ‹è¯•å®Œæˆ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Oasisä»»åŠ¡å®ç°åŠŸèƒ½æ­£å¸¸ã€‚")
        return True
    else:
        logger.warning("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½ã€‚")
        return False


if __name__ == "__main__":
    success = asyncio.run(run_all_tests())
    sys.exit(0 if success else 1) 