# SandBox RL - Multi-Model Reinforcement Learning

<div align="center">

<img src="assets/logo.png" alt="Core SRL Logo" width="200">

**Advanced Multi-Model RL Framework for Training Modern LLMs**

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

</div>

## What is Core SRL?

Core SRL enables **simultaneous training of multiple modern LLMs** using reinforcement learning with **cooperative-competitive dynamics**. Train 4-8 models like Qwen3-14B, together with real-time weight updates.

### Key Features

- **Multi-Model Training**: Simultaneous RL training of 4-8 modern LLMs
- **Live Weight Updates**: Real-time parameter synchronization during training  
- **Cooperative-Competitive RL**: Novel algorithm balancing cooperation and competition
- **Modern Model Support**: Qwen3-14B, Llama-3.1, and other open-weight models
- **VERL/AReaL Integration**: Efficient training with advanced caching
- **Checkpoint Management**: Automatic saving and recovery

## System Architecture

![System Architecture](assets/archi.jpeg)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Core SRL Architecture                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Multi-Model Trainer                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚   Qwen3-14B â”‚ â”‚   Qwen-Math â”‚ â”‚ Qwen-Coder  â”‚ â”‚ Llama-3.1   â”‚â”‚
â”‚  â”‚   + LoRA    â”‚ â”‚   + LoRA    â”‚ â”‚   + LoRA    â”‚ â”‚   + LoRA    â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚         â”‚               â”‚               â”‚               â”‚        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚           Cooperative-Competitive RL Engine               â”‚ â”‚
â”‚  â”‚  â€¢ Weight Update Coordination  â€¢ Parameter Sharing        â”‚ â”‚
â”‚  â”‚  â€¢ VERL Integration           â€¢ AReaL Optimization        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Quick Start

### Installation

```bash
git clone https://github.com/NoakLiu/SandBox-RL.git
cd core-srl
pip install -r requirements.txt
```

### Basic Training

```python
import asyncio
from core_srl import quick_start_multimodel_training

async def main():
    results = await quick_start_multimodel_training(
        num_models=4,
        max_episodes=100
    )
    print(f"Training completed: {results['status']}")

asyncio.run(main())
```

### Advanced Configuration

```python
from core_srl import MultiModelTrainer, MultiModelConfig, TrainingMode

config = MultiModelConfig(
    num_models=6,
    model_types=["qwen3", "qwen_coder", "llama3"],
    training_mode=TrainingMode.MIXED,
    max_episodes=1000,
    checkpoint_dir="./my_checkpoints"
)

trainer = MultiModelTrainer(config)
results = asyncio.run(trainer.train())
```

### Checkpoint Management

```python
from core_srl import list_available_checkpoints

# List checkpoints
checkpoints = list_available_checkpoints()
print("Available:", checkpoints)

# Resume training
trainer.load_checkpoint(checkpoints[0])
```

## Supported Models

```python
MODERN_MODELS = {
    "qwen3": "Qwen/Qwen2.5-14B-Instruct",           # Latest Qwen
    "qwen_coder": "Qwen/Qwen2.5-Coder-14B-Instruct", # Code specialized
    "qwen_math": "Qwen/Qwen2.5-Math-14B-Instruct",   # Math specialized
    "llama3": "meta-llama/Llama-3.1-8B-Instruct"     # Latest Llama
}
```

## ğŸ“ Project Structure

```
core-srl/
â”œâ”€â”€ core_srl/           # Core framework (8 files)
â”œâ”€â”€ examples/           # Training examples (8 examples)
â”œâ”€â”€ tests/              # Test suites
â”œâ”€â”€ docs/               # Documentation (6 docs)
â”œâ”€â”€ data/               # Training data and results
â””â”€â”€ checkpoints/        # Model checkpoints
```

## ğŸ“š Documentation

- **[Quick Start](docs/quick_start.md)** - 5-minute setup
- **[Multi-Model Training](docs/multimodel_training.md)** - Training guide
- **[Model Configuration](docs/model_config.md)** - Modern LLM setup
- **[Checkpoints](docs/checkpoints.md)** - Save/restore training
- **[VERL/AReaL](docs/verl_areal.md)** - Advanced optimization
- **[API Reference](docs/api_reference.md)** - Complete API

## Contributing

Focus areas:
- New modern LLM integrations
- Advanced multi-model strategies
- Performance optimizations

## ğŸ“„ License

MIT License

---

<div align="center">
<b>Core SRL v2.0.0 - Multi-Model RL Training Made Efficient</b>
</div>