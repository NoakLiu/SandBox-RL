# Sandbox-RLX

<div align="center">
  <img src="assets/logo.png" alt="Sandbox-RLX Logo" width="200"/>
</div>

Sandbox-RLX æ˜¯ä¸€ä¸ªåŸºäºç¯å¢ƒå­é›†ï¼ˆEnvironment Subsetsï¼‰æŠ½è±¡å’Œä¼˜åŒ–ç›®æ ‡ï¼ˆOptimization Goalï¼‰çš„æ™ºèƒ½ä¼˜åŒ–æ¡†æ¶ã€‚å®ƒé€šè¿‡ SandBox Workflow Graph æ¥åè°ƒ LLM å†³ç­–å’Œ RL æƒé‡æ›´æ–°ï¼Œå®ç°å¤æ‚ä»»åŠ¡çš„è‡ªåŠ¨åŒ–ä¼˜åŒ–ã€‚

## ğŸŒŸ æ ¸å¿ƒæ¦‚å¿µ

### 1. ç¯å¢ƒå­é›†ï¼ˆEnvironment Subsetsï¼‰
- å°†å¤æ‚ç¯å¢ƒåˆ†è§£ä¸ºå¯ç®¡ç†çš„å­é›†
- æ¯ä¸ªå­é›†éƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ SandBox
- æ”¯æŒè‡ªå®šä¹‰çŠ¶æ€ç©ºé—´å’ŒåŠ¨ä½œç©ºé—´
- æä¾›æ ‡å‡†åŒ–çš„æ‰§è¡Œå’Œè¯„ä¼°æ¥å£

### 2. ä¼˜åŒ–ç›®æ ‡ï¼ˆOptimization Goalï¼‰
- å®šä¹‰ä»»åŠ¡çš„å…·ä½“ä¼˜åŒ–ç›®æ ‡
- å¯ä»¥æ˜¯å•ä¸€ç›®æ ‡æˆ–å¤šç›®æ ‡ä¼˜åŒ–
- æ”¯æŒè‡ªå®šä¹‰è¯„åˆ†å‡½æ•°
- æä¾›ç›®æ ‡è¾¾æˆåº¦çš„é‡åŒ–è¯„ä¼°

### 3. SandBox Workflow Graph
- å°†ä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ª SandBox èŠ‚ç‚¹
- é€šè¿‡æœ‰å‘æ— ç¯å›¾ï¼ˆDAGï¼‰ç»„ç»‡èŠ‚ç‚¹å…³ç³»
- æ”¯æŒå¹¶è¡Œå’Œä¸²è¡Œæ‰§è¡Œ
- å®ç°èŠ‚ç‚¹é—´çš„çŠ¶æ€ä¼ é€’å’Œç»“æœèšåˆ

### 4. æ™ºèƒ½å†³ç­–ç³»ç»Ÿ
- **RL æƒé‡æ›´æ–°**ï¼šä¼˜åŒ–å†³ç­–ç­–ç•¥
- **çŠ¶æ€ç®¡ç†**ï¼šè¿½è¸ªå’Œæ›´æ–°ç³»ç»ŸçŠ¶æ€
- **ä¸LLMå’Œèµ„æºåˆ†ç¦»äº¤äº’**ï¼šSandBoxä½œä¸ºworkflow graphèŠ‚ç‚¹ä¸LLM(Decision Making),RL(LLM Weight Update)å’ŒComputational Resources(GPU, CPU, etc)éš”ç»ï¼ŒSandbox-RLXå¯¹åä¸¤è€…å…¨å±€æ‰˜ç®¡ã€‚

<div align="center">
  <img src="assets/archi.jpeg" alt="Sandbox-RLX Architecture" width="800"/>
</div>

## ğŸŒŸ æ ¸å¿ƒç‰¹æ€§

- **æ²™ç›’ç¯å¢ƒ**ï¼šéµå¾ª InternBootCamp æ¨¡å¼çš„æ ‡å‡†åŒ–ä»»åŠ¡ç¯å¢ƒ
- **å·¥ä½œæµå›¾**ï¼šæ”¯æŒSandbox DAG Workflow
- **æ ‡å‡†åŒ–é€šä¿¡**ï¼šä½¿ç”¨å®˜æ–¹ MCP åè®®è¿›è¡Œ Sandboxé€šä¿¡ä¸LLMè¿›è¡Œè®¡ç®—
- **å¤šç§ä½¿ç”¨åœºæ™¯**ï¼šä»å•ä¸€æ²™ç›’(single node)æ‰§è¡Œåˆ°å¤æ‚å¤šé˜¶æ®µ(multiple node, large DAGs)å·¥ä½œæµ
- **åŠ¨æ€å·¥ä½œæµå¼•æ“**ï¼šæ”¯æŒå¤æ‚çš„DAGï¼ˆæœ‰å‘æ— ç¯å›¾ï¼‰å·¥ä½œæµï¼Œå®ç°å¤šèŠ‚ç‚¹åä½œ
- **æ™ºèƒ½çŠ¶æ€ç®¡ç†**ï¼šæ¯ä¸ªèŠ‚ç‚¹ç»´æŠ¤ç‹¬ç«‹çš„çŠ¶æ€ï¼Œæ”¯æŒåŠ¨æ€æ›´æ–°å’ŒçŠ¶æ€è¿½è¸ª
- **èµ„æºç®¡ç†ç³»ç»Ÿ**ï¼šèµ„æºï¼ˆèƒ½é‡ã€ä»¤ç‰Œã€æ—¶é—´ã€çŸ¥è¯†ï¼‰ç®¡ç†æœºåˆ¶
- **è‡ªé€‚åº”å†³ç­–**ï¼šæ”¯æŒåŸºäºå†å²ä¿¡æ¯å’Œå½“å‰çŠ¶æ€çš„æ™ºèƒ½å†³ç­–
- **å¯æ‰©å±•æ¶æ„**ï¼šæ˜“äºæ·»åŠ æ–°çš„èŠ‚ç‚¹ç±»å‹å’ŒåŠŸèƒ½æ¨¡å—
- **ğŸ”¥ ä¸°å¯Œçš„LLMæ¨¡å‹æ”¯æŒ**ï¼šæ”¯æŒå¤šç§ç«çƒ­çš„å¤§è¯­è¨€æ¨¡å‹ï¼ŒåŒ…æ‹¬ï¼š
  - **é»˜è®¤æ¨è**ï¼šMistral-7B
  - **ä¸­æ–‡æ¨¡å‹**ï¼šQwen-7B, Yi-6B, ChatGLM3
  - **ä»£ç æ¨¡å‹**ï¼šCodeLLaMA, StarCoder
  - **è½»é‡çº§**ï¼šPhi-2, Gemma-2B
  - **é«˜æ€§èƒ½**ï¼šLLaMA2-13B
  - **å¼€æºæ›¿ä»£**ï¼šGPT-2, Falcon

## ğŸ“ æ–‡ä»¶ç»“æ„

```
Sandbox-RLX/
â”œâ”€â”€ sandgraph/                    # æ ¸å¿ƒåŒ…ç›®å½•
â”‚   â”œâ”€â”€ core/                     # æ ¸å¿ƒåŠŸèƒ½æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ workflow.py          # åŸºç¡€å·¥ä½œæµå®ç°
â”‚   â”‚   â”œâ”€â”€ sg_workflow.py       # Sandbox-RLå·¥ä½œæµå®ç°
â”‚   â”‚   â”œâ”€â”€ dag_manager.py       # DAGå›¾ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ llm_interface.py     # LLMæ¥å£
â”‚   â”‚   â”œâ”€â”€ sandbox.py           # æ²™ç›’åŸºç¡€ç±»
â”‚   â”‚   â”œâ”€â”€ rl_framework.py      # å¼ºåŒ–å­¦ä¹ æ¡†æ¶
â”‚   â”‚   â””â”€â”€ rl_algorithms.py     # å¼ºåŒ–å­¦ä¹ ç®—æ³•
â”‚   â”œâ”€â”€ sandbox_implementations.py # æ²™ç›’å®ç°
â”‚   â””â”€â”€ examples.py              # ç¤ºä¾‹ä»£ç 
â”œâ”€â”€ demo/                        # ç¤ºä¾‹ä»£ç ç›®å½•
â”‚   â”œâ”€â”€ trading_demo.py         # äº¤æ˜“ç³»ç»Ÿç¤ºä¾‹
â”‚   â”œâ”€â”€ social_network_demo.py  # ç¤¾äº¤ç½‘ç»œåˆ†ææ¼”ç¤º
â”‚   â”œâ”€â”€ misinformation_spread_demo.py # è™šå‡ä¿¡æ¯ä¼ æ’­æ¼”ç¤º
â”‚   â””â”€â”€ oasis_social_demo.py    # OASISç¤¾äº¤ç½‘ç»œæ¨¡æ‹Ÿ
â””â”€â”€ setup.py                     # å®‰è£…é…ç½®
```

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Sandbox-RL Core                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Workflow   â”‚   SandBox   â”‚    LLM      â”‚     RL      â”‚
â”‚   Engine    â”‚  Manager    â”‚  Manager    â”‚  Manager    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚             â”‚             â”‚             â”‚
       â–¼             â–¼             â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DAG Nodes  â”‚ â”‚ Environment â”‚ â”‚  Decision   â”‚ â”‚  Weight     â”‚
â”‚             â”‚ â”‚  Subsets    â”‚ â”‚  Making     â”‚ â”‚  Updates    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚             â”‚             â”‚             â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Sandbox-RLX Manager                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ ç”¨æˆ·è¾“å…¥ï¼šç¯å¢ƒå­é›†å®šä¹‰å’Œä¼˜åŒ–ç›®æ ‡                          â”‚
â”‚  â€¢ å·¥ä½œæµï¼šDAGå›¾æ„å»ºä¸æ‰§è¡Œç®¡ç†                              â”‚
â”‚  â€¢ ä¼˜åŒ–ï¼šLLMå†³ç­–ä¼˜åŒ–ä¸RLæƒé‡æ›´æ–°                            â”‚
â”‚  â€¢ èµ„æºï¼šå…¨å±€èµ„æºç®¡ç†ä¸SandBoxéš”ç¦»                          â”‚
â”‚  â€¢ ç›‘æ§ï¼šæ‰§è¡ŒçŠ¶æ€è¿½è¸ªä¸æ€§èƒ½åˆ†æ                              â”‚
â”‚  â€¢ æ‰©å±•ï¼šæ”¯æŒè‡ªå®šä¹‰èŠ‚ç‚¹å’Œä¼˜åŒ–ç­–ç•¥                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®šä¹‰ç¯å¢ƒå­é›†
```python
from sandgraph import SandBox

class MyEnvironment(SandBox):
    def __init__(self):
        super().__init__()
        self.state_space = {...}  # å®šä¹‰çŠ¶æ€ç©ºé—´
        self.action_space = {...}  # å®šä¹‰åŠ¨ä½œç©ºé—´
    
    def execute(self, action):
        # å®ç°ç¯å¢ƒæ‰§è¡Œé€»è¾‘
        return next_state, reward, done
    
    def get_state(self):
        # è¿”å›å½“å‰çŠ¶æ€
        return self.current_state
```

### 2. å®šä¹‰ä¼˜åŒ–ç›®æ ‡
```python
def optimization_goal(state, action, next_state):
    # å®ç°ä¼˜åŒ–ç›®æ ‡å‡½æ•°
    score = calculate_score(state, action, next_state)
    return score
```

### 3. åˆ›å»ºå·¥ä½œæµ
```python
from sandbox_rl.core.llm_interface import create_shared_llm_manager
from sandbox_rl.core.sg_workflow import SG_Workflow, WorkflowMode
from sandbox_rl.core.rl_algorithms import RLTrainer, RLConfig

# åˆ›å»ºLLMç®¡ç†å™¨ï¼ˆé»˜è®¤ä½¿ç”¨Mistral-7Bï¼‰
llm_manager = create_shared_llm_manager("mistralai/Mistral-7B-Instruct-v0.2")

# åˆ›å»ºå·¥ä½œæµ
workflow = SG_Workflow("my_workflow", WorkflowMode.TRADITIONAL, llm_manager)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node(NodeType.SANDBOX, "env", {"sandbox": MyEnvironment()})
workflow.add_node(NodeType.LLM, "decision", {"role": "å†³ç­–å™¨"})
workflow.add_node(NodeType.RL, "optimizer", {"algorithm": "PPO"})

# è¿æ¥èŠ‚ç‚¹
workflow.add_edge("env", "decision")
workflow.add_edge("decision", "optimizer")
workflow.add_edge("optimizer", "env")

# æ‰§è¡Œå·¥ä½œæµ
result = workflow.execute_full_workflow()
```

## ğŸ“¦ å®‰è£…

### ä½¿ç”¨ Conda å®‰è£…ï¼ˆæ¨èï¼‰

```bash
# 1. åˆ›å»ºæ–°çš„ conda ç¯å¢ƒ
conda create -n sandgraph python=3.11
conda activate sandgraph

# 2. å…‹éš†ä»“åº“
git clone https://github.com/NoakLiu/Sandbox-RLX.git
cd Sandbox-RLX

# 3. è¿è¡Œå®‰è£…è„šæœ¬
chmod +x quick_install.sh
./quick_install.sh
```

## ğŸ“– Usage

### System Architecture & API Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Application                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Sandbox-RLX Manager                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Workflow   â”‚   SandBox   â”‚    LLM      â”‚   RL    â”‚  â”‚
â”‚  â”‚   Engine    â”‚  Manager    â”‚  Manager    â”‚ Manager â”‚  â”‚
â”‚  â”‚ (sg_workflowâ”‚ (sandbox.py)â”‚(llm_interfaceâ”‚(rl_algorithmsâ”‚
â”‚  â”‚    .py)     â”‚             â”‚    .py)     â”‚   .py)  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚             â”‚             â”‚           â”‚       â”‚
â”‚         â–¼             â–¼             â–¼           â–¼       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  DAG Nodes  â”‚ â”‚ Environment â”‚ â”‚ Decisionâ”‚ â”‚Weight â”‚  â”‚
â”‚  â”‚             â”‚ â”‚  Subsets    â”‚ â”‚ Making  â”‚ â”‚Updatesâ”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Execution Results                     â”‚
â”‚  â€¢ Performance Metrics                                  â”‚
â”‚  â€¢ Optimization Statistics                              â”‚
â”‚  â€¢ State Updates                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core API Usage

```python
from sandbox_rl.core.llm_interface import create_shared_llm_manager
from sandbox_rl.core.sg_workflow import SG_Workflow, WorkflowMode
from sandbox_rl.core.rl_algorithms import RLTrainer, RLConfig

# 1. Initialize Core Components (é»˜è®¤ä½¿ç”¨Mistral-7B)
llm_manager = create_shared_llm_manager(
    model_name="mistralai/Mistral-7B-Instruct-v0.2",  # é»˜è®¤æ¨¡å‹
    backend="huggingface",
    temperature=0.7
)

# 2. Create Workflow & RL Trainer
workflow = SG_Workflow("my_workflow", WorkflowMode.TRADITIONAL, llm_manager)
rl_trainer = RLTrainer(RLConfig(algorithm="PPO"), llm_manager)

# 3. Add Environment & Decision Nodes
workflow.add_node(NodeType.SANDBOX, "environment", {"sandbox": MySandbox()})
workflow.add_node(NodeType.LLM, "decision", {"role": "å†³ç­–å™¨"})

# 4. Execute & Optimize
result = workflow.execute_full_workflow()
rl_trainer.update_policy()
```

### Example 1: Trading System

**Input**: Market data, portfolio state, trading parameters  
**Process**: LLM analyzes market â†’ generates trading decisions â†’ RL optimizes strategy  
**Output**: Trading actions, performance metrics, optimized weights

```python
# Run trading demo
python demo/trading_demo.py --strategy simulated --steps 5
```

### Example 2: Social Network Analysis

**Input**: Network topology, user interactions, content data  
**Process**: LLM analyzes patterns â†’ generates insights â†’ RL optimizes recommendations  
**Output**: Network insights, user recommendations, engagement metrics

```python
# Run social network demo
python demo/social_network_demo.py --steps 10
```

### Example 3: Misinformation Spread Analysis

**Input**: Social network data, user beliefs, information content  
**Process**: LLM analyzes misinformation patterns â†’ generates intervention strategies â†’ RL optimizes intervention effectiveness  
**Output**: Intervention actions, belief change metrics, spread reduction statistics

```python
# Run misinformation spread demo
python demo/misinformation_spread_demo.py --steps 5
```

### Example 4: OASIS Social Network Simulation

**Input**: User profiles, social network topology, content data  
**Process**: LLM analyzes social dynamics â†’ generates user behaviors â†’ RL optimizes engagement strategies  
**Output**: Social interactions, network growth metrics, engagement optimization

```python
# Run OASIS social network demo
python demo/oasis_social_demo.py --steps 5
```

## ğŸ”¥ LLMæ¨¡å‹æ”¯æŒ

Sandbox-RLæ”¯æŒå¤šç§ä¸»æµå¤§è¯­è¨€æ¨¡å‹ï¼Œä»¥ä¸‹æ˜¯æ”¯æŒçš„æ¨¡å‹å’ŒåŸºæœ¬ä½¿ç”¨æ–¹æ³•ï¼š

### æ”¯æŒçš„æ¨¡å‹

| æ¨¡å‹ç±»å‹ | æ¨èæ¨¡å‹ | å‚æ•°å¤§å° | å†…å­˜éœ€æ±‚ |
|---------|---------|---------|---------|
| **é»˜è®¤æ¨è** | **Mistral-7B** | 7B | 8-16GB |
| **ä¸­æ–‡æ¨¡å‹** | Qwen-7B, Yi-6B, ChatGLM3 | 6-7B | 8-16GB |
| **ä»£ç æ¨¡å‹** | CodeLLaMA, StarCoder | 7-15B | 8-16GB |
| **è½»é‡çº§** | Phi-2, Gemma-2B | 2-3B | 2-4GB |
| **é«˜æ€§èƒ½** | LLaMA2-13B | 13B | 16-32GB |
| **å¼€æºæ›¿ä»£** | GPT-2, Falcon | 1-7B | 2-16GB |


<!-- è®¾è®¡æ›´å¤šçš„æŒ‡æ ‡å’Œæ¥å£ (Social Network) - ç”¨æˆ·è¿‡ç¨‹æŸ¥çœ‹ (WanDB, TensorBoard)
LLMs frozen & adaptive update
Demoçš„æœ€ç»ˆç›®çš„è®¾è®¡ï¼ŒSandbox-RL LLMè¦ beatæ™®é€šçš„è§„åˆ™å’Œäººç±»ç”¨æˆ·ï¼Œæœ€åçš„ç»“æœåº”è¯¥æ˜¯misinformation spread over large percent of graph. -->

## ğŸ“„ è®¸å¯è¯

MIT License

## ğŸ¤ è”ç³»æ–¹å¼

- é‚®ä»¶è”ç³» - dong.liu.dl2367@yale.edu 

## ğŸ§ª å…¸å‹æ¡ˆä¾‹ï¼šè™šå‡ä¿¡æ¯ä¼ æ’­å¯¹æŠ—ä»¿çœŸ

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªåŸºäº Sandbox-RL + OASIS çš„ misinformation ä¼ æ’­å¯¹æŠ—å®ä¾‹ï¼Œæ¨¡æ‹Ÿäº†ä¸¤ç»„ç”¨æˆ·ï¼ˆå¦‚â€œç‰¹æœ—æ™®æ€»ç»Ÿæ”¯æŒè€…â€ vs â€œæ‹œç™»æ€»ç»Ÿæ”¯æŒè€…â€ï¼‰åœ¨ç¤¾äº¤ç½‘ç»œä¸­çš„é”™è¯¯ä¿¡æ¯ä¼ æ’­ç«äº‰ã€‚ä½ å¯ä»¥é€šè¿‡å¦‚ä¸‹æ–¹å¼è¿è¡Œï¼š

1. è¿›å…¥ scripts ç›®å½•ï¼Œè¿è¡Œä»¿çœŸè„šæœ¬ï¼š

```bash
cd demo/scripts
python misinformation_spread_demo.py
```

2. è¯¥è„šæœ¬ä¼šè‡ªåŠ¨æ¨¡æ‹Ÿä¸¤ç»„ç”¨æˆ·çš„è§‚ç‚¹ä¼ æ’­ï¼Œå¹¶å¯è§†åŒ–æ¯è½®â€œç‰¹æœ—æ™®/æ‹œç™»â€è§‚ç‚¹çš„å æ¯”å˜åŒ–ã€‚

3. è¯¦ç»†ç”¨æ³•ã€å‚æ•°é…ç½®å’Œé«˜çº§åŠŸèƒ½ï¼ˆå¦‚ RL ç­–ç•¥ã€LLM frozen/adaptiveã€å¹²é¢„æœºåˆ¶ç­‰ï¼‰è¯·å‚è€ƒ OASIS æ–‡æ¡£ï¼š

ğŸ‘‰ [OASIS Misinformation Spread Demo ä½¿ç”¨è¯´æ˜](demo/oasis/docs/misinformation_spread_demo.md)

--- 