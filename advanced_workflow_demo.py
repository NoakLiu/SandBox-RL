#!/usr/bin/env python3
"""
é«˜çº§DAGå·¥ä½œæµç³»ç»Ÿæ¼”ç¤º

å±•ç¤ºSandGraphé«˜çº§å·¥ä½œæµç³»ç»Ÿçš„å®Œæ•´åŠŸèƒ½ï¼š
- ç¯è·¯æ£€æµ‹å’Œæ‹“æ‰‘æ’åº
- å¤æ‚æ§åˆ¶æµï¼ˆæ¡ä»¶ã€å¾ªç¯ã€å¹¶è¡Œï¼‰
- å¤šç§åœæ­¢æ¡ä»¶
- é”™è¯¯å¤„ç†å’Œæ¢å¤ç­–ç•¥
- çŠ¶æ€ç®¡ç†å’Œæ•°æ®æµæ§åˆ¶
- æ‰§è¡Œç›‘æ§å’Œè°ƒè¯•

è¿è¡Œæ–¹å¼ï¼š
python advanced_workflow_demo.py
"""

import asyncio
import sys
import time
import random
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '.')

try:
    from sandgraph.core.dag_manager import (
        DAG_Manager, create_dag_manager, ExecutionContext,
        NodeType, ExecutionStatus, StopConditionType,
        AdvancedWorkflowNode, StopCondition
    )
    from sandgraph import Game24Sandbox
    SANDGRAPH_AVAILABLE = True
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿SandGraphå·²æ­£ç¡®å®‰è£…")
    sys.exit(1)


def print_separator(title: str, width: int = 80):
    """æ‰“å°åˆ†éš”çº¿"""
    print("\n" + "=" * width)
    print(f" {title} ".center(width))
    print("=" * width + "\n")


async def demo_basic_dag():
    """æ¼”ç¤ºåŸºç¡€DAGå·¥ä½œæµ"""
    print_separator("åŸºç¡€DAGå·¥ä½œæµæ¼”ç¤º")
    
    # åˆ›å»ºç®€å•çš„ä»»åŠ¡å‡½æ•°
    def task_a(context: ExecutionContext, input_data: Any) -> str:
        print("  æ‰§è¡Œä»»åŠ¡A")
        time.sleep(0.1)
        return "result_A"
    
    def task_b(context: ExecutionContext, input_data: Any) -> str:
        print("  æ‰§è¡Œä»»åŠ¡Bï¼Œä¾èµ–Açš„ç»“æœ:", input_data.get('task_a', 'N/A'))
        time.sleep(0.1)
        return "result_B"
    
    def task_c(context: ExecutionContext, input_data: Any) -> str:
        print("  æ‰§è¡Œä»»åŠ¡Cï¼Œä¾èµ–Açš„ç»“æœ:", input_data.get('task_a', 'N/A'))
        time.sleep(0.1) 
        return "result_C"
    
    def task_d(context: ExecutionContext, input_data: Any) -> str:
        print("  æ‰§è¡Œä»»åŠ¡Dï¼Œä¾èµ–Bå’ŒCçš„ç»“æœ")
        print(f"    Bç»“æœ: {input_data.get('task_b', 'N/A')}")
        print(f"    Cç»“æœ: {input_data.get('task_c', 'N/A')}")
        return "result_D"
    
    # ä½¿ç”¨æ„å»ºå™¨åˆ›å»ºå·¥ä½œæµ
    workflow = (create_dag_manager("basic_dag", "åŸºç¡€DAGæ¼”ç¤º")
                .add_task_node("task_a", "ä»»åŠ¡A", task_a)
                .add_task_node("task_b", "ä»»åŠ¡B", task_b)
                .add_task_node("task_c", "ä»»åŠ¡C", task_c)
                .add_task_node("task_d", "ä»»åŠ¡D", task_d)
                .connect("task_a", "task_b")
                .connect("task_a", "task_c")
                .connect("task_b", "task_d")
                .connect("task_c", "task_d")
                .build())
    
    print("ğŸ“Š å·¥ä½œæµæ‹“æ‰‘æ’åº:", workflow.topological_sort())
    
    # æ‰§è¡Œå·¥ä½œæµ
    context = await workflow.execute({"initial_value": "start"})
    
    print("\nğŸ“ˆ æ‰§è¡Œæ‘˜è¦:")
    summary = workflow.get_execution_summary()
    for key, value in summary.items():
        if key != "node_status":
            print(f"  {key}: {value}")
    
    print("\nğŸ” èŠ‚ç‚¹æ‰§è¡ŒçŠ¶æ€:")
    for node_id, status in summary["node_status"].items():
        print(f"  {node_id}: {status['status']} (è€—æ—¶: {status['duration']:.3f}s)")
    
    return workflow


async def demo_cycle_detection():
    """æ¼”ç¤ºç¯è·¯æ£€æµ‹åŠŸèƒ½"""
    print_separator("ç¯è·¯æ£€æµ‹æ¼”ç¤º")
    
    def dummy_task(context: ExecutionContext, input_data: Any) -> str:
        return "dummy"
    
    workflow = create_dag_manager("cycle_test", "ç¯è·¯æ£€æµ‹æµ‹è¯•")
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_task_node("node1", "èŠ‚ç‚¹1", dummy_task)
    workflow.add_task_node("node2", "èŠ‚ç‚¹2", dummy_task)
    workflow.add_task_node("node3", "èŠ‚ç‚¹3", dummy_task)
    
    # æ·»åŠ æ­£å¸¸è¾¹
    workflow.connect("node1", "node2")
    workflow.connect("node2", "node3")
    
    print("âœ… æˆåŠŸæ·»åŠ è¾¹: node1 -> node2 -> node3")
    
    # å°è¯•æ·»åŠ å½¢æˆç¯è·¯çš„è¾¹
    try:
        workflow.connect("node3", "node1")  # è¿™ä¼šå½¢æˆç¯è·¯
        print("âŒ ç¯è·¯æ£€æµ‹å¤±è´¥ï¼")
    except ValueError as e:
        print(f"âœ… æˆåŠŸæ£€æµ‹åˆ°ç¯è·¯: {e}")
    
    # éªŒè¯å›¾ä»ç„¶æœ‰æ•ˆ
    topo_order = workflow.build().topological_sort()
    print(f"ğŸ“Š æ‹“æ‰‘æ’åº: {topo_order}")


async def demo_condition_workflow():
    """æ¼”ç¤ºæ¡ä»¶åˆ†æ”¯å·¥ä½œæµ"""
    print_separator("æ¡ä»¶åˆ†æ”¯å·¥ä½œæµæ¼”ç¤º")
    
    def generate_number(context: ExecutionContext, input_data: Any) -> int:
        number = random.randint(1, 100)
        print(f"  ç”Ÿæˆéšæœºæ•°: {number}")
        context.global_state["random_number"] = number
        return number
    
    def check_even(context: ExecutionContext, input_data: Any) -> bool:
        number = context.global_state.get("random_number", 0)
        is_even = number % 2 == 0
        print(f"  æ£€æŸ¥ {number} æ˜¯å¦ä¸ºå¶æ•°: {is_even}")
        return is_even
    
    def process_even(context: ExecutionContext, input_data: Any) -> str:
        print("  å¤„ç†å¶æ•°")
        return "even_processed"
    
    def process_odd(context: ExecutionContext, input_data: Any) -> str:
        print("  å¤„ç†å¥‡æ•°")
        return "odd_processed"
    
    def final_task(context: ExecutionContext, input_data: Any) -> str:
        print("  æ‰§è¡Œæœ€ç»ˆä»»åŠ¡")
        return "completed"
    
    # åˆ›å»ºæ¡ä»¶å·¥ä½œæµ
    workflow = (create_dag_manager("condition_flow", "æ¡ä»¶åˆ†æ”¯æ¼”ç¤º")
                .add_task_node("generate", "ç”Ÿæˆæ•°å­—", generate_number)
                .add_condition_node("check_even", "æ£€æŸ¥å¶æ•°", check_even, 
                                  true_branch="process_even", false_branch="process_odd")
                .add_task_node("process_even", "å¤„ç†å¶æ•°", process_even)
                .add_task_node("process_odd", "å¤„ç†å¥‡æ•°", process_odd)
                .add_task_node("final", "æœ€ç»ˆä»»åŠ¡", final_task)
                .connect("generate", "check_even")
                .connect("check_even", "process_even")  # æ¡ä»¶ä¸ºçœŸæ—¶æ‰§è¡Œ
                .connect("check_even", "process_odd")   # æ¡ä»¶ä¸ºå‡æ—¶æ‰§è¡Œ
                .connect("process_even", "final")
                .connect("process_odd", "final")
                .build())
    
    # æ‰§è¡Œå·¥ä½œæµ
    context = await workflow.execute()
    
    print(f"\nğŸ¯ æ¡ä»¶åˆ†æ”¯ç»“æœ:")
    for node_id, node_state in context.node_states.items():
        if node_state:
            print(f"  {node_id}: {node_state}")
    
    return workflow


async def demo_loop_workflow():
    """æ¼”ç¤ºå¾ªç¯å·¥ä½œæµ"""
    print_separator("å¾ªç¯å·¥ä½œæµæ¼”ç¤º")
    
    def initialize_counter(context: ExecutionContext, input_data: Any) -> int:
        context.global_state["counter"] = 0
        print("  åˆå§‹åŒ–è®¡æ•°å™¨: 0")
        return 0
    
    def increment_counter(context: ExecutionContext, input_data: Any) -> int:
        current = context.global_state.get("counter", 0)
        current += 1
        context.global_state["counter"] = current
        print(f"  è®¡æ•°å™¨é€’å¢: {current}")
        return current
    
    def loop_condition(context: ExecutionContext, input_data: Any, iteration: int) -> bool:
        counter = context.global_state.get("counter", 0)
        should_continue = counter < 5
        print(f"  å¾ªç¯æ¡ä»¶æ£€æŸ¥ (è¿­ä»£ {iteration}): counter={counter}, ç»§ç»­={should_continue}")
        return should_continue
    
    def finalize_result(context: ExecutionContext, input_data: Any) -> str:
        final_count = context.global_state.get("counter", 0)
        print(f"  å¾ªç¯å®Œæˆï¼Œæœ€ç»ˆè®¡æ•°: {final_count}")
        return f"loop_completed_{final_count}"
    
    # åˆ›å»ºå¾ªç¯å·¥ä½œæµ
    workflow = (create_dag_manager("loop_flow", "å¾ªç¯æ¼”ç¤º")
                .add_task_node("init", "åˆå§‹åŒ–", initialize_counter)
                .add_loop_node("loop_increment", "é€’å¢å¾ªç¯", increment_counter, 
                              loop_condition, max_iterations=10)
                .add_task_node("finalize", "å®Œæˆ", finalize_result)
                .connect("init", "loop_increment")
                .connect("loop_increment", "finalize")
                .build())
    
    # æ‰§è¡Œå·¥ä½œæµ
    context = await workflow.execute()
    
    print(f"\nğŸ”„ å¾ªç¯æ‰§è¡Œç»“æœ:")
    loop_node = workflow.nodes["loop_increment"]
    print(f"  å¾ªç¯æ¬¡æ•°: {len(loop_node.result) if loop_node.result else 0}")
    print(f"  æœ€ç»ˆçŠ¶æ€: {context.global_state}")
    
    return workflow


async def demo_parallel_workflow():
    """æ¼”ç¤ºå¹¶è¡Œæ‰§è¡Œå·¥ä½œæµ"""
    print_separator("å¹¶è¡Œæ‰§è¡Œå·¥ä½œæµæ¼”ç¤º")
    
    def prepare_data(context: ExecutionContext, input_data: Any) -> List[int]:
        data = [1, 2, 3, 4, 5]
        print(f"  å‡†å¤‡æ•°æ®: {data}")
        return data
    
    def parallel_task_1(context: ExecutionContext, input_data: Any) -> str:
        print("  å¹¶è¡Œä»»åŠ¡1å¼€å§‹æ‰§è¡Œ")
        time.sleep(0.2)  # æ¨¡æ‹Ÿè€—æ—¶æ“ä½œ
        result = "task1_completed"
        print(f"  å¹¶è¡Œä»»åŠ¡1å®Œæˆ: {result}")
        return result
    
    def parallel_task_2(context: ExecutionContext, input_data: Any) -> str:
        print("  å¹¶è¡Œä»»åŠ¡2å¼€å§‹æ‰§è¡Œ")
        time.sleep(0.15)  # æ¨¡æ‹Ÿè€—æ—¶æ“ä½œ
        result = "task2_completed"
        print(f"  å¹¶è¡Œä»»åŠ¡2å®Œæˆ: {result}")
        return result
    
    def parallel_task_3(context: ExecutionContext, input_data: Any) -> str:
        print("  å¹¶è¡Œä»»åŠ¡3å¼€å§‹æ‰§è¡Œ")
        time.sleep(0.1)  # æ¨¡æ‹Ÿè€—æ—¶æ“ä½œ
        result = "task3_completed"
        print(f"  å¹¶è¡Œä»»åŠ¡3å®Œæˆ: {result}")
        return result
    
    def aggregate_results(context: ExecutionContext, input_data: Any) -> str:
        print("  èšåˆå¹¶è¡Œä»»åŠ¡ç»“æœ")
        parallel_results = input_data.get("parallel_tasks", [])
        print(f"  å¹¶è¡Œä»»åŠ¡ç»“æœ: {parallel_results}")
        return f"aggregated_{len(parallel_results)}_results"
    
    # åˆ›å»ºå¹¶è¡Œå·¥ä½œæµ
    workflow = (create_dag_manager("parallel_flow", "å¹¶è¡Œæ‰§è¡Œæ¼”ç¤º")
                .add_task_node("prepare", "å‡†å¤‡æ•°æ®", prepare_data)
                .add_parallel_node("parallel_tasks", "å¹¶è¡Œä»»åŠ¡", 
                                 [parallel_task_1, parallel_task_2, parallel_task_3])
                .add_task_node("aggregate", "èšåˆç»“æœ", aggregate_results)
                .connect("prepare", "parallel_tasks")
                .connect("parallel_tasks", "aggregate")
                .build())
    
    # æ‰§è¡Œå·¥ä½œæµ
    start_time = time.time()
    context = await workflow.execute()
    end_time = time.time()
    
    print(f"\nâš¡ å¹¶è¡Œæ‰§è¡Œæ•ˆæœ:")
    print(f"  æ€»è€—æ—¶: {end_time - start_time:.3f}ç§’")
    print(f"  å¦‚æœä¸²è¡Œæ‰§è¡Œé¢„è®¡éœ€è¦: 0.45ç§’ (0.2+0.15+0.1)")
    
    return workflow


async def demo_stop_conditions():
    """æ¼”ç¤ºåœæ­¢æ¡ä»¶"""
    print_separator("åœæ­¢æ¡ä»¶æ¼”ç¤º")
    
    def long_running_task(context: ExecutionContext, input_data: Any) -> str:
        iteration = context.current_iteration
        print(f"  é•¿æ—¶é—´ä»»åŠ¡æ‰§è¡Œä¸­... (è¿­ä»£ {iteration})")
        time.sleep(0.1)
        return f"iteration_{iteration}"
    
    # æ¼”ç¤º1: æœ€å¤§è¿­ä»£æ¬¡æ•°åœæ­¢
    print("ğŸ”„ æ¼”ç¤º1: æœ€å¤§è¿­ä»£æ¬¡æ•°åœæ­¢æ¡ä»¶")
    workflow1 = (create_dag_manager("max_iter_test", "æœ€å¤§è¿­ä»£æµ‹è¯•")
                 .add_task_node("task", "é•¿æ—¶é—´ä»»åŠ¡", long_running_task)
                 .add_stop_condition(StopConditionType.MAX_ITERATIONS, 5)
                 .build())
    
    context1 = await workflow1.execute()
    print(f"  åœæ­¢åŸå› : {context1.stop_reason}")
    print(f"  æ‰§è¡Œè¿­ä»£æ•°: {context1.current_iteration}")
    
    # æ¼”ç¤º2: æ—¶é—´é™åˆ¶åœæ­¢
    print("\nâ° æ¼”ç¤º2: æ—¶é—´é™åˆ¶åœæ­¢æ¡ä»¶")
    workflow2 = (create_dag_manager("time_limit_test", "æ—¶é—´é™åˆ¶æµ‹è¯•")
                 .add_task_node("task", "é•¿æ—¶é—´ä»»åŠ¡", long_running_task)
                 .add_stop_condition(StopConditionType.TIME_LIMIT, 0.5)  # 0.5ç§’
                 .build())
    
    context2 = await workflow2.execute()
    print(f"  åœæ­¢åŸå› : {context2.stop_reason}")
    print(f"  æ‰§è¡Œæ—¶é—´: {time.time() - context2.start_time:.3f}ç§’")
    
    # æ¼”ç¤º3: è‡ªå®šä¹‰æ¡ä»¶åœæ­¢
    print("\nğŸ¯ æ¼”ç¤º3: è‡ªå®šä¹‰æ¡ä»¶åœæ­¢")
    def custom_stop_condition(context: ExecutionContext) -> bool:
        return context.current_iteration >= 3
    
    workflow3 = (create_dag_manager("custom_condition_test", "è‡ªå®šä¹‰æ¡ä»¶æµ‹è¯•")
                 .add_task_node("task", "é•¿æ—¶é—´ä»»åŠ¡", long_running_task)
                 .add_stop_condition(StopConditionType.CONDITION_MET, custom_stop_condition)
                 .build())
    
    context3 = await workflow3.execute()
    print(f"  åœæ­¢åŸå› : {context3.stop_reason}")
    print(f"  æ‰§è¡Œè¿­ä»£æ•°: {context3.current_iteration}")


async def demo_error_handling():
    """æ¼”ç¤ºé”™è¯¯å¤„ç†å’Œæ¢å¤"""
    print_separator("é”™è¯¯å¤„ç†å’Œæ¢å¤æ¼”ç¤º")
    
    def stable_task(context: ExecutionContext, input_data: Any) -> str:
        print("  ç¨³å®šä»»åŠ¡æ‰§è¡ŒæˆåŠŸ")
        return "stable_result"
    
    def unreliable_task(context: ExecutionContext, input_data: Any) -> str:
        # æ¨¡æ‹Ÿä¸ç¨³å®šçš„ä»»åŠ¡
        if random.random() < 0.7:  # 70%æ¦‚ç‡å¤±è´¥
            raise Exception("æ¨¡æ‹Ÿä»»åŠ¡å¤±è´¥")
        print("  ä¸ç¨³å®šä»»åŠ¡æ„å¤–æˆåŠŸ")
        return "unreliable_success"
    
    def cleanup_task(context: ExecutionContext, input_data: Any) -> str:
        print("  æ‰§è¡Œæ¸…ç†ä»»åŠ¡")
        return "cleanup_done"
    
    # æ¼”ç¤º1: é‡è¯•æœºåˆ¶
    print("ğŸ”„ æ¼”ç¤º1: é‡è¯•æœºåˆ¶")
    workflow1 = (create_dag_manager("retry_test", "é‡è¯•æµ‹è¯•")
                 .add_task_node("stable", "ç¨³å®šä»»åŠ¡", stable_task)
                 .add_task_node("unreliable", "ä¸ç¨³å®šä»»åŠ¡", unreliable_task, 
                               retry_count=3, retry_delay=0.1)
                 .add_task_node("cleanup", "æ¸…ç†ä»»åŠ¡", cleanup_task)
                 .connect("stable", "unreliable")
                 .connect("unreliable", "cleanup")
                 .build())
    
    try:
        context1 = await workflow1.execute()
        print("  å·¥ä½œæµæ‰§è¡Œå®Œæˆ")
    except Exception as e:
        print(f"  å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
    
    # æ¼”ç¤º2: è·³è¿‡å¤±è´¥èŠ‚ç‚¹
    print("\nâ­ï¸ æ¼”ç¤º2: è·³è¿‡å¤±è´¥èŠ‚ç‚¹")
    workflow2 = (create_dag_manager("skip_test", "è·³è¿‡æµ‹è¯•")
                 .add_task_node("stable", "ç¨³å®šä»»åŠ¡", stable_task)
                 .add_task_node("unreliable", "ä¸ç¨³å®šä»»åŠ¡", unreliable_task, 
                               skip_on_failure=True)
                 .add_task_node("cleanup", "æ¸…ç†ä»»åŠ¡", cleanup_task)
                 .connect("stable", "unreliable")
                 .connect("unreliable", "cleanup")
                 .build())
    
    context2 = await workflow2.execute()
    
    print("\nğŸ“Š èŠ‚ç‚¹æ‰§è¡ŒçŠ¶æ€:")
    for node_id, node in workflow2.nodes.items():
        print(f"  {node_id}: {node.status.value}")


async def demo_sandgraph_integration():
    """æ¼”ç¤ºä¸SandGraphæ²™ç›’çš„é›†æˆ"""
    print_separator("SandGraphæ²™ç›’é›†æˆæ¼”ç¤º")
    
    def create_game24_task(context: ExecutionContext, input_data: Any) -> Dict[str, Any]:
        sandbox = Game24Sandbox()
        case = sandbox.case_generator()
        print(f"  ç”ŸæˆGame24é¢˜ç›®: {case}")
        context.global_state["game24_case"] = case
        return case
    
    def solve_game24(context: ExecutionContext, input_data: Any) -> str:
        case = context.global_state.get("game24_case", {})
        # æ¨¡æ‹ŸLLMæ±‚è§£
        nums = case.get("puzzle", [6, 6, 6, 6])
        mock_solution = f"({nums[0]}+{nums[1]})+({nums[2]}+{nums[3]})"
        print(f"  æ¨¡æ‹Ÿæ±‚è§£: {mock_solution}")
        return mock_solution
    
    def verify_solution(context: ExecutionContext, input_data: Any) -> bool:
        solution = input_data.get("solve_game24", "")
        case = context.global_state.get("game24_case", {})
        
        # ç®€å•éªŒè¯ï¼ˆå®é™…åº”è¯¥ä½¿ç”¨æ²™ç›’çš„éªŒè¯æ–¹æ³•ï¼‰
        is_valid = len(solution) > 0 and "+" in solution
        print(f"  éªŒè¯ç»“æœ: {'âœ… æœ‰æ•ˆ' if is_valid else 'âŒ æ— æ•ˆ'}")
        return is_valid
    
    def report_result(context: ExecutionContext, input_data: Any) -> str:
        verification = input_data.get("verify", False)
        result = "æˆåŠŸ" if verification else "å¤±è´¥"
        print(f"  æœ€ç»ˆæŠ¥å‘Š: Game24æ±‚è§£{result}")
        return f"game24_{result}"
    
    # åˆ›å»ºé›†æˆå·¥ä½œæµ
    workflow = (create_dag_manager("sandgraph_integration", "SandGraphé›†æˆæ¼”ç¤º")
                .add_task_node("create_task", "åˆ›å»ºä»»åŠ¡", create_game24_task)
                .add_task_node("solve_game24", "æ±‚è§£Game24", solve_game24)
                .add_task_node("verify", "éªŒè¯è§£ç­”", verify_solution)
                .add_task_node("report", "æŠ¥å‘Šç»“æœ", report_result)
                .connect("create_task", "solve_game24")
                .connect("solve_game24", "verify")
                .connect("verify", "report")
                .build())
    
    # æ·»åŠ æ‰§è¡Œç›‘å¬å™¨
    def execution_listener(node_id: str, status: ExecutionStatus, context: ExecutionContext):
        print(f"  ğŸ”” ç›‘å¬å™¨: èŠ‚ç‚¹ {node_id} çŠ¶æ€å˜æ›´ä¸º {status.value}")
    
    workflow.add_execution_listener(execution_listener)
    
    # æ‰§è¡Œå·¥ä½œæµ
    context = await workflow.execute()
    
    print(f"\nğŸ“ˆ å·¥ä½œæµæ‰§è¡Œæ‘˜è¦:")
    summary = workflow.get_execution_summary()
    print(f"  æˆåŠŸèŠ‚ç‚¹: {len([n for n in workflow.nodes.values() if n.status == ExecutionStatus.SUCCESS])}")
    print(f"  å¤±è´¥èŠ‚ç‚¹: {len([n for n in workflow.nodes.values() if n.status == ExecutionStatus.FAILED])}")
    print(f"  æ€»æ‰§è¡Œæ—¶é—´: {summary['total_time']:.3f}ç§’")
    
    return workflow


async def demo_workflow_visualization():
    """æ¼”ç¤ºå·¥ä½œæµå¯è§†åŒ–"""
    print_separator("å·¥ä½œæµå¯è§†åŒ–æ¼”ç¤º")
    
    # åˆ›å»ºä¸€ä¸ªå¤æ‚çš„å·¥ä½œæµç”¨äºå¯è§†åŒ–
    def dummy_task(context: ExecutionContext, input_data: Any) -> str:
        return "dummy"
    
    workflow = (create_dag_manager("visualization_test", "å¯è§†åŒ–æ¼”ç¤º")
                .add_task_node("start", "å¼€å§‹ä»»åŠ¡", dummy_task)
                .add_condition_node("check", "æ¡ä»¶æ£€æŸ¥", lambda c, d: True)
                .add_parallel_node("parallel", "å¹¶è¡Œå¤„ç†", [dummy_task, dummy_task])
                .add_loop_node("loop", "å¾ªç¯ä»»åŠ¡", dummy_task, lambda c, d, i: i < 2)
                .add_task_node("end", "ç»“æŸä»»åŠ¡", dummy_task)
                .connect("start", "check")
                .connect("check", "parallel")
                .connect("parallel", "loop")
                .connect("loop", "end")
                .build())
    
    # ç”Ÿæˆå¯è§†åŒ–JSON
    visualization = workflow.visualize_graph()
    print("ğŸ¨ å·¥ä½œæµå›¾ç»“æ„:")
    print(visualization)
    
    return workflow


async def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ é«˜çº§DAGå·¥ä½œæµç³»ç»Ÿå®Œæ•´æ¼”ç¤º")
    print("=" * 80)
    
    demos = [
        ("åŸºç¡€DAGå·¥ä½œæµ", demo_basic_dag),
        ("ç¯è·¯æ£€æµ‹", demo_cycle_detection),
        ("æ¡ä»¶åˆ†æ”¯å·¥ä½œæµ", demo_condition_workflow),
        ("å¾ªç¯å·¥ä½œæµ", demo_loop_workflow),
        ("å¹¶è¡Œæ‰§è¡Œå·¥ä½œæµ", demo_parallel_workflow),
        ("åœæ­¢æ¡ä»¶", demo_stop_conditions),
        ("é”™è¯¯å¤„ç†å’Œæ¢å¤", demo_error_handling),
        ("SandGraphæ²™ç›’é›†æˆ", demo_sandgraph_integration),
        ("å·¥ä½œæµå¯è§†åŒ–", demo_workflow_visualization),
    ]
    
    results = {}
    
    for demo_name, demo_func in demos:
        try:
            print(f"\nğŸ“ å¼€å§‹æ¼”ç¤º: {demo_name}")
            result = await demo_func()
            results[demo_name] = {"status": "âœ… æˆåŠŸ", "result": result}
            print(f"âœ… {demo_name} æ¼”ç¤ºå®Œæˆ")
        except Exception as e:
            results[demo_name] = {"status": "âŒ å¤±è´¥", "error": str(e)}
            print(f"âŒ {demo_name} æ¼”ç¤ºå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # æ¼”ç¤ºæ€»ç»“
    print_separator("æ¼”ç¤ºæ€»ç»“")
    
    print("ğŸ“Š æ¼”ç¤ºç»“æœ:")
    success_count = 0
    for demo_name, result in results.items():
        print(f"  {result['status']} {demo_name}")
        if "æˆåŠŸ" in result['status']:
            success_count += 1
    
    print(f"\nğŸ¯ æˆåŠŸç‡: {success_count}/{len(demos)} ({success_count/len(demos)*100:.1f}%)")
    
    print("\nğŸ’¡ é«˜çº§DAGå·¥ä½œæµç³»ç»Ÿç‰¹æ€§æ€»ç»“:")
    features = [
        "âœ… ç¯è·¯æ£€æµ‹å’Œæ‹“æ‰‘æ’åº",
        "âœ… æ¡ä»¶åˆ†æ”¯å’ŒåŠ¨æ€è·¯å¾„é€‰æ‹©",
        "âœ… å¾ªç¯æ§åˆ¶å’Œè¿­ä»£æ‰§è¡Œ",
        "âœ… å¹¶è¡Œä»»åŠ¡æ‰§è¡Œ",
        "âœ… å¤šç§åœæ­¢æ¡ä»¶ï¼ˆæ—¶é—´ã€è¿­ä»£ã€è‡ªå®šä¹‰ï¼‰",
        "âœ… é‡è¯•æœºåˆ¶å’Œé”™è¯¯æ¢å¤",
        "âœ… è·³è¿‡å¤±è´¥èŠ‚ç‚¹ç­–ç•¥",
        "âœ… æ‰§è¡Œç›‘å¬å’ŒçŠ¶æ€è·Ÿè¸ª",
        "âœ… æ•°æ®æµç®¡ç†å’ŒçŠ¶æ€å…±äº«",
        "âœ… å·¥ä½œæµå¯è§†åŒ–å’Œè°ƒè¯•",
        "âœ… ä¸SandGraphæ²™ç›’æ— ç¼é›†æˆ"
    ]
    
    for feature in features:
        print(f"  {feature}")
    
    print("\nğŸ”§ å®ç”¨å»ºè®®:")
    print("  â€¢ ä½¿ç”¨WorkflowBuilderæ„å»ºå¤æ‚å·¥ä½œæµ")
    print("  â€¢ è®¾ç½®åˆé€‚çš„åœæ­¢æ¡ä»¶é¿å…æ— é™æ‰§è¡Œ")
    print("  â€¢ åˆ©ç”¨å¹¶è¡Œæ‰§è¡Œæé«˜æ€§èƒ½")
    print("  â€¢ æ·»åŠ é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶")
    print("  â€¢ ä½¿ç”¨æ‰§è¡Œç›‘å¬å™¨è¿›è¡Œè°ƒè¯•å’Œç›‘æ§")
    print("  â€¢ é›†æˆåˆ°MCPå®¢æˆ·ç«¯å®ç°æ™ºèƒ½å·¥ä½œæµ")
    
    print("\nğŸ‰ é«˜çº§DAGå·¥ä½œæµç³»ç»Ÿæ¼”ç¤ºå®Œæˆï¼")


if __name__ == "__main__":
    asyncio.run(main()) 