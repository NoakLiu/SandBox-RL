#!/usr/bin/env python3
"""
Enhanced AReaL Integration Demo for SandGraphX
=============================================

This demo showcases deep integration with the AReaL framework, reusing its core components:
1. Advanced caching system with multiple backends
2. Distributed processing and task scheduling
3. Real-time metrics collection and monitoring
4. Adaptive resource management
5. High-performance data structures
6. Fault tolerance and recovery mechanisms

Based on AReaL: https://github.com/inclusionAI/AReaL
"""

import sys
import os
import time
import json
import random
import argparse
import threading
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta

# Add the parent directory to the path to import sandgraph modules
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from sandgraph.core.areal_integration import (
    create_areal_integration,
    IntegrationLevel,
    get_areal_status
)


def demonstrate_basic_integration():
    """æ¼”ç¤ºåŸºç¡€AReaLé›†æˆ"""
    print("ğŸ”§ Basic AReaL Integration Demo")
    print("=" * 50)
    
    # åˆ›å»ºåŸºç¡€é›†æˆ
    areal_manager = create_areal_integration(
        integration_level=IntegrationLevel.BASIC,
        cache_size=5000,
        max_memory_gb=4.0
    )
    
    print("âœ… AReaL integration manager created")
    
    # è·å–çŠ¶æ€ä¿¡æ¯
    status = get_areal_status()
    print(f"\nğŸ“Š AReaL Status:")
    print(f"  - AReaL Available: {status['areal_available']}")
    print(f"  - NumPy Available: {status['numpy_available']}")
    print(f"  - PyTorch Available: {status['torch_available']}")
    print(f"  - Version: {status['version']}")
    
    # æµ‹è¯•ç¼“å­˜åŠŸèƒ½
    cache = areal_manager.get_cache()
    if cache:
        print("\nğŸ§ª Testing Cache Functionality:")
        
        # å­˜å‚¨æ•°æ®
        test_data = {
            "user_id": 12345,
            "preferences": {"theme": "dark", "language": "zh"},
            "last_activity": datetime.now().isoformat()
        }
        
        cache.put("user:12345", test_data)
        print("  âœ… Data stored in cache")
        
        # è·å–æ•°æ®
        retrieved_data = cache.get("user:12345")
        if retrieved_data:
            print("  âœ… Data retrieved from cache")
            print(f"  ğŸ“ Retrieved: {retrieved_data}")
        
        # è·å–ç¼“å­˜ç»Ÿè®¡
        cache_stats = cache.get_stats()
        print(f"  ğŸ“Š Cache Stats: {cache_stats}")
    
    # æµ‹è¯•æŒ‡æ ‡æ”¶é›†
    metrics = areal_manager.get_metrics()
    if metrics:
        print("\nğŸ“ˆ Testing Metrics Collection:")
        
        # è®°å½•ä¸€äº›æŒ‡æ ‡
        metrics.record_metric("demo.request_count", 1.0, {"demo": "basic"})
        metrics.record_metric("demo.response_time", 0.15, {"demo": "basic"})
        metrics.record_metric("demo.error_rate", 0.0, {"demo": "basic"})
        
        print("  âœ… Metrics recorded")
        
        # è·å–æŒ‡æ ‡
        recent_metrics = metrics.get_metrics(tags={"demo": "basic"})
        print(f"  ğŸ“Š Recent Metrics: {len(recent_metrics)} records")
        
        # èšåˆæŒ‡æ ‡
        avg_response_time = metrics.aggregate_metrics("demo.response_time", "avg")
        print(f"  ğŸ“ˆ Average Response Time: {avg_response_time:.3f}s")
    
    # è·å–é›†æˆç»Ÿè®¡
    integration_stats = areal_manager.get_stats()
    print(f"\nğŸ“Š Integration Stats:")
    print(f"  - Integration Level: {integration_stats['integration_level']}")
    print(f"  - Components Active: {integration_stats['components']}")
    
    return areal_manager


def demonstrate_advanced_integration():
    """æ¼”ç¤ºé«˜çº§AReaLé›†æˆ"""
    print("\nğŸš€ Advanced AReaL Integration Demo")
    print("=" * 50)
    
    # åˆ›å»ºé«˜çº§é›†æˆ
    areal_manager = create_areal_integration(
        integration_level=IntegrationLevel.ADVANCED,
        cache_size=10000,
        max_memory_gb=8.0,
        enable_optimization=True
    )
    
    print("âœ… Advanced AReaL integration manager created")
    
    # æµ‹è¯•ä»»åŠ¡è°ƒåº¦å™¨
    scheduler = areal_manager.get_scheduler()
    if scheduler:
        print("\nâš¡ Testing Task Scheduler:")
        
        # å®šä¹‰ä¸€äº›æµ‹è¯•ä»»åŠ¡
        def task_1():
            time.sleep(0.1)
            return {"result": "Task 1 completed", "timestamp": datetime.now().isoformat()}
        
        def task_2():
            time.sleep(0.2)
            return {"result": "Task 2 completed", "timestamp": datetime.now().isoformat()}
        
        def task_3():
            time.sleep(0.05)
            return {"result": "Task 3 completed", "timestamp": datetime.now().isoformat()}
        
        # æäº¤ä»»åŠ¡
        task_ids = []
        for i, task_func in enumerate([task_1, task_2, task_3]):
            task_id = f"demo_task_{i+1}"
            scheduler.submit_task(task_id, task_func, priority="normal")
            task_ids.append(task_id)
            print(f"  ğŸ“ Submitted task: {task_id}")
        
        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        time.sleep(0.5)
        
        # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€å’Œç»“æœ
        for task_id in task_ids:
            status = scheduler.get_task_status(task_id)
            result = scheduler.get_task_result(task_id)
            print(f"  ğŸ“Š Task {task_id}: {status}")
            if result:
                print(f"    Result: {result}")
    
    # æµ‹è¯•ä¼˜åŒ–å™¨
    optimizer = areal_manager.get_optimizer()
    if optimizer:
        print("\nğŸ¯ Testing Optimizer:")
        
        # æ¨¡æ‹Ÿç¼“å­˜ç»Ÿè®¡
        cache_stats = {
            "hit_rate": 0.75,
            "size": 5000,
            "evictions": 100
        }
        
        # æ¨¡æ‹Ÿèµ„æºä½¿ç”¨æƒ…å†µ
        resource_usage = {
            "cpu_percent": 65.0,
            "memory_percent": 45.0,
            "disk_percent": 30.0
        }
        
        # æ¨¡æ‹Ÿæ€§èƒ½æŒ‡æ ‡
        performance_metrics = {
            "avg_response_time": 0.8,
            "throughput": 1000.0,
            "error_rate": 0.02
        }
        
        # è¿è¡Œä¼˜åŒ–
        optimal_policy = optimizer.optimize_cache_policy(cache_stats)
        optimal_allocation = optimizer.optimize_resource_allocation(resource_usage)
        optimal_batch_size = optimizer.optimize_batch_size(performance_metrics)
        
        print(f"  ğŸ¯ Optimal Cache Policy: {optimal_policy}")
        print(f"  ğŸ¯ Optimal Resource Allocation: {optimal_allocation}")
        print(f"  ğŸ¯ Optimal Batch Size: {optimal_batch_size}")
    
    return areal_manager


def demonstrate_full_integration():
    """æ¼”ç¤ºå®Œæ•´AReaLé›†æˆ"""
    print("\nğŸŒŸ Full AReaL Integration Demo")
    print("=" * 50)
    
    # åˆ›å»ºå®Œæ•´é›†æˆ
    areal_manager = create_areal_integration(
        integration_level=IntegrationLevel.FULL,
        cache_size=20000,
        max_memory_gb=16.0,
        enable_distributed=True,
        enable_optimization=True
    )
    
    print("âœ… Full AReaL integration manager created")
    
    # æµ‹è¯•åˆ†å¸ƒå¼ç®¡ç†å™¨
    distributed_manager = areal_manager.get_distributed_manager()
    if distributed_manager:
        print("\nğŸŒ Testing Distributed Manager:")
        
        # æ³¨å†ŒèŠ‚ç‚¹
        node_configs = [
            {"cpu_cores": 8, "memory_gb": 16, "gpu_count": 1},
            {"cpu_cores": 4, "memory_gb": 8, "gpu_count": 0},
            {"cpu_cores": 16, "memory_gb": 32, "gpu_count": 2}
        ]
        
        for i, config in enumerate(node_configs):
            node_id = f"node_{i+1}"
            success = distributed_manager.register_node(node_id, config)
            print(f"  ğŸ“ Registered node {node_id}: {'âœ…' if success else 'âŒ'}")
        
        # åˆ†å‘ä»»åŠ¡
        task_data = {
            "type": "computation",
            "parameters": {"iterations": 1000, "complexity": "high"},
            "priority": "high"
        }
        
        task_ids = distributed_manager.distribute_task("distributed_task_1", task_data)
        print(f"  ğŸ“¤ Distributed task: {task_ids}")
        
        # æ”¶é›†ç»“æœ
        results = distributed_manager.collect_results(task_ids)
        print(f"  ğŸ“¥ Collected results: {results}")
    
    # æ¨¡æ‹Ÿé•¿æ—¶é—´è¿è¡Œçš„ç³»ç»Ÿ
    print("\nâ±ï¸  Simulating Long-Running System:")
    
    # è®°å½•æŒç»­æŒ‡æ ‡
    metrics = areal_manager.get_metrics()
    if metrics:
        for i in range(10):
            # æ¨¡æ‹Ÿç³»ç»Ÿè´Ÿè½½
            cpu_usage = random.uniform(20.0, 80.0)
            memory_usage = random.uniform(30.0, 70.0)
            response_time = random.uniform(0.1, 2.0)
            
            # è®°å½•æŒ‡æ ‡
            metrics.record_metric("system.cpu_usage", cpu_usage, {"phase": "simulation"})
            metrics.record_metric("system.memory_usage", memory_usage, {"phase": "simulation"})
            metrics.record_metric("system.response_time", response_time, {"phase": "simulation"})
            
            print(f"  ğŸ“Š Step {i+1}: CPU={cpu_usage:.1f}%, Memory={memory_usage:.1f}%, Response={response_time:.3f}s")
            time.sleep(0.1)
    
    return areal_manager


def demonstrate_performance_comparison():
    """æ¼”ç¤ºæ€§èƒ½å¯¹æ¯”"""
    print("\nğŸ“Š Performance Comparison Demo")
    print("=" * 50)
    
    # æµ‹è¯•ä¸åŒé›†æˆçº§åˆ«çš„æ€§èƒ½
    integration_levels = [
        (IntegrationLevel.BASIC, "Basic"),
        (IntegrationLevel.ADVANCED, "Advanced"),
        (IntegrationLevel.FULL, "Full")
    ]
    
    results = {}
    
    for level, name in integration_levels:
        print(f"\nğŸ§ª Testing {name} Integration:")
        
        start_time = time.time()
        
        # åˆ›å»ºé›†æˆç®¡ç†å™¨
        areal_manager = create_areal_integration(
            integration_level=level,
            cache_size=5000,
            max_memory_gb=4.0
        )
        
        # æ‰§è¡Œæ€§èƒ½æµ‹è¯•
        cache = areal_manager.get_cache()
        metrics = areal_manager.get_metrics()
        
        if cache and metrics:
            # ç¼“å­˜æ€§èƒ½æµ‹è¯•
            cache_start = time.time()
            for i in range(1000):
                key = f"test_key_{i}"
                value = {"data": f"value_{i}", "timestamp": time.time()}
                cache.put(key, value)
            
            for i in range(1000):
                key = f"test_key_{i}"
                cache.get(key)
            
            cache_time = time.time() - cache_start
            
            # æŒ‡æ ‡æ”¶é›†æ€§èƒ½æµ‹è¯•
            metrics_start = time.time()
            for i in range(1000):
                metrics.record_metric("perf_test", i, {"test": "performance"})
            
            metrics_time = time.time() - metrics_start
        
        total_time = time.time() - start_time
        
        results[name] = {
            "total_time": total_time,
            "cache_time": cache_time if cache and metrics else 0,
            "metrics_time": metrics_time if cache and metrics else 0
        }
        
        print(f"  â±ï¸  Total Time: {total_time:.3f}s")
        print(f"  â±ï¸  Cache Time: {cache_time:.3f}s")
        print(f"  â±ï¸  Metrics Time: {metrics_time:.3f}s")
    
    # æ˜¾ç¤ºæ€§èƒ½å¯¹æ¯”
    print(f"\nğŸ“ˆ Performance Comparison Summary:")
    print(f"{'Integration':<12} {'Total Time':<12} {'Cache Time':<12} {'Metrics Time':<12}")
    print("-" * 50)
    
    for name, result in results.items():
        print(f"{name:<12} {result['total_time']:<12.3f} {result['cache_time']:<12.3f} {result['metrics_time']:<12.3f}")


def demonstrate_fault_tolerance():
    """æ¼”ç¤ºå®¹é”™æœºåˆ¶"""
    print("\nğŸ›¡ï¸  Fault Tolerance Demo")
    print("=" * 50)
    
    # åˆ›å»ºé›†æˆç®¡ç†å™¨
    areal_manager = create_areal_integration(
        integration_level=IntegrationLevel.ADVANCED,
        cache_size=1000,
        max_memory_gb=2.0
    )
    
    print("âœ… AReaL integration manager created")
    
    # æµ‹è¯•ç¼“å­˜å®¹é”™
    cache = areal_manager.get_cache()
    if cache:
        print("\nğŸ§ª Testing Cache Fault Tolerance:")
        
        # æ­£å¸¸æ“ä½œ
        cache.put("normal_key", "normal_value")
        result = cache.get("normal_key")
        print(f"  âœ… Normal operation: {result}")
        
        # æ¨¡æ‹Ÿé”™è¯¯æƒ…å†µ
        try:
            # å°è¯•å­˜å‚¨æ— æ•ˆæ•°æ®
            cache.put("invalid_key", None)
            print("  âœ… Handled invalid data gracefully")
        except Exception as e:
            print(f"  âŒ Error handling invalid data: {e}")
        
        # æµ‹è¯•ç¼“å­˜æ»¡çš„æƒ…å†µ
        print("  ğŸ“Š Testing cache overflow...")
        for i in range(2000):  # è¶…è¿‡ç¼“å­˜å¤§å°
            cache.put(f"overflow_key_{i}", f"value_{i}")
        
        cache_stats = cache.get_stats()
        print(f"  ğŸ“Š Cache stats after overflow: {cache_stats}")
    
    # æµ‹è¯•æŒ‡æ ‡æ”¶é›†å®¹é”™
    metrics = areal_manager.get_metrics()
    if metrics:
        print("\nğŸ“ˆ Testing Metrics Fault Tolerance:")
        
        # æ­£å¸¸æŒ‡æ ‡è®°å½•
        metrics.record_metric("normal_metric", 100.0)
        print("  âœ… Normal metric recorded")
        
        # å¼‚å¸¸æŒ‡æ ‡å¤„ç†
        try:
            metrics.record_metric("invalid_metric", float('inf'))
            print("  âœ… Handled infinite value gracefully")
        except Exception as e:
            print(f"  âŒ Error handling infinite value: {e}")
        
        try:
            metrics.record_metric("nan_metric", float('nan'))
            print("  âœ… Handled NaN value gracefully")
        except Exception as e:
            print(f"  âŒ Error handling NaN value: {e}")
    
    # æµ‹è¯•ä»»åŠ¡è°ƒåº¦å™¨å®¹é”™
    scheduler = areal_manager.get_scheduler()
    if scheduler:
        print("\nâš¡ Testing Scheduler Fault Tolerance:")
        
        # æ­£å¸¸ä»»åŠ¡
        def normal_task():
            return "Normal task completed"
        
        # å¼‚å¸¸ä»»åŠ¡
        def error_task():
            raise ValueError("Simulated error")
        
        # æäº¤ä»»åŠ¡
        normal_id = scheduler.submit_task("normal_task", normal_task)
        error_id = scheduler.submit_task("error_task", error_task)
        
        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        time.sleep(0.2)
        
        # æ£€æŸ¥ç»“æœ
        normal_status = scheduler.get_task_status(normal_id)
        normal_result = scheduler.get_task_result(normal_id)
        print(f"  ğŸ“Š Normal task: {normal_status} - {normal_result}")
        
        error_status = scheduler.get_task_status(error_id)
        print(f"  ğŸ“Š Error task: {error_status}")
    
    return areal_manager


def demonstrate_resource_management():
    """æ¼”ç¤ºèµ„æºç®¡ç†"""
    print("\nğŸ’¾ Resource Management Demo")
    print("=" * 50)
    
    # åˆ›å»ºé›†æˆç®¡ç†å™¨
    areal_manager = create_areal_integration(
        integration_level=IntegrationLevel.ADVANCED,
        cache_size=5000,
        max_memory_gb=4.0,
        enable_optimization=True
    )
    
    print("âœ… AReaL integration manager created")
    
    # ç›‘æ§èµ„æºä½¿ç”¨
    print("\nğŸ“Š Monitoring Resource Usage:")
    
    for i in range(10):
        # è·å–å½“å‰ç»Ÿè®¡
        stats = areal_manager.get_stats()
        
        # æ˜¾ç¤ºèµ„æºä½¿ç”¨æƒ…å†µ
        cache_stats = stats.get("cache_stats", {})
        metrics_summary = stats.get("metrics_summary", {})
        
        print(f"  ğŸ“Š Step {i+1}:")
        print(f"    Cache Size: {cache_stats.get('size', 0)}")
        print(f"    Cache Hit Rate: {cache_stats.get('hit_rate', 0.0):.3f}")
        print(f"    Memory Usage: {cache_stats.get('memory_usage', 0):.2f} MB")
        print(f"    Total Metrics: {metrics_summary.get('total_metrics', 0)}")
        
        # æ¨¡æ‹Ÿè´Ÿè½½
        cache = areal_manager.get_cache()
        metrics = areal_manager.get_metrics()
        
        if cache and metrics:
            # æ·»åŠ ä¸€äº›æ•°æ®
            for j in range(100):
                cache.put(f"resource_test_{i}_{j}", f"data_{j}")
                metrics.record_metric("resource_test", j, {"step": str(i)})
        
        time.sleep(0.1)
    
    # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
    final_stats = areal_manager.get_stats()
    print(f"\nğŸ“ˆ Final Resource Statistics:")
    print(f"  - Integration Level: {final_stats['integration_level']}")
    print(f"  - Components Active: {final_stats['components']}")
    print(f"  - Cache Statistics: {final_stats.get('cache_stats', {})}")
    print(f"  - Metrics Summary: {final_stats.get('metrics_summary', {})}")
    
    return areal_manager


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Enhanced AReaL Integration Demo")
    parser.add_argument("--demo", choices=["basic", "advanced", "full", "performance", "fault_tolerance", "resource", "all"], 
                       default="all", help="Demo to run")
    parser.add_argument("--cache-size", type=int, default=10000, help="Cache size")
    parser.add_argument("--max-memory", type=float, default=8.0, help="Max memory in GB")
    
    args = parser.parse_args()
    
    print("ğŸš€ Enhanced AReaL Integration Demo for SandGraphX")
    print("=" * 60)
    print(f"Demo: {args.demo}")
    print(f"Cache Size: {args.cache_size}")
    print(f"Max Memory: {args.max_memory} GB")
    print("=" * 60)
    
    managers = []
    
    try:
        if args.demo == "basic" or args.demo == "all":
            manager = demonstrate_basic_integration()
            managers.append(manager)
        
        if args.demo == "advanced" or args.demo == "all":
            manager = demonstrate_advanced_integration()
            managers.append(manager)
        
        if args.demo == "full" or args.demo == "all":
            manager = demonstrate_full_integration()
            managers.append(manager)
        
        if args.demo == "performance" or args.demo == "all":
            demonstrate_performance_comparison()
        
        if args.demo == "fault_tolerance" or args.demo == "all":
            manager = demonstrate_fault_tolerance()
            managers.append(manager)
        
        if args.demo == "resource" or args.demo == "all":
            manager = demonstrate_resource_management()
            managers.append(manager)
        
        print(f"\nğŸ‰ Enhanced AReaL Integration Demo completed successfully!")
        print("ğŸ“ Check the areal_state/ directory for persistent data.")
        
        # æ˜¾ç¤ºæœ€ç»ˆçŠ¶æ€
        if managers:
            print(f"\nğŸ“Š Final Integration Status:")
            for i, manager in enumerate(managers):
                stats = manager.get_stats()
                print(f"  Manager {i+1}: {stats['integration_level']} level")
                print(f"    Components: {stats['components']}")
        
    except Exception as e:
        print(f"\nâŒ Demo failed: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # æ¸…ç†èµ„æº
        for manager in managers:
            try:
                manager.shutdown()
            except Exception as e:
                print(f"Warning: Error shutting down manager: {e}")


if __name__ == "__main__":
    main() 