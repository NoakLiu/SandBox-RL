#!/usr/bin/env python3
"""
æµ‹è¯•Camel VLLMæ¨¡å‹çš„API
"""

import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

async def test_camel_vllm_api():
    """æµ‹è¯•Camel VLLMæ¨¡å‹çš„API"""
    print("ğŸ§ª æµ‹è¯•Camel VLLMæ¨¡å‹API...")
    
    try:
        # å¯¼å…¥Camelæ¨¡å—
        from camel.models import ModelFactory
        from camel.types import ModelPlatformType
        
        print("âœ… æˆåŠŸå¯¼å…¥Camelæ¨¡å—")
        
        # åˆ›å»ºVLLMæ¨¡å‹
        print("\nğŸ”§ åˆ›å»ºVLLMæ¨¡å‹...")
        vllm_model = ModelFactory.create(
            model_platform=ModelPlatformType.VLLM,
            model_type="qwen-2",
            url="http://localhost:8001/v1",
        )
        
        print(f"âœ… åˆ›å»ºVLLMæ¨¡å‹: {vllm_model}")
        print(f"æ¨¡å‹ç±»å‹: {type(vllm_model)}")
        
        # æ£€æŸ¥æ¨¡å‹å¯¹è±¡çš„å¯ç”¨æ–¹æ³•
        print("\nğŸ” æ£€æŸ¥æ¨¡å‹å¯¹è±¡çš„å¯ç”¨æ–¹æ³•:")
        available_methods = []
        for method_name in dir(vllm_model):
            if not method_name.startswith('_'):
                method = getattr(vllm_model, method_name)
                if callable(method):
                    available_methods.append(method_name)
                    print(f"  - {method_name}: {method}")
        
        print(f"\nğŸ“‹ å¯ç”¨æ–¹æ³•åˆ—è¡¨: {available_methods}")
        
        # æµ‹è¯•ä¸åŒçš„è°ƒç”¨æ–¹å¼
        test_prompt = "Hello, how are you?"
        print(f"\nğŸ§ª æµ‹è¯•æç¤ºè¯: {test_prompt}")
        
        # æ–¹å¼1: generateæ–¹æ³•
        if 'generate' in available_methods:
            try:
                print("  æµ‹è¯• generate æ–¹æ³•...")
                response = await vllm_model.generate(test_prompt)
                print(f"  âœ… generate æ–¹æ³•æˆåŠŸ: {response[:50]}...")
            except Exception as e:
                print(f"  âŒ generate æ–¹æ³•å¤±è´¥: {e}")
        
        # æ–¹å¼2: chatæ–¹æ³•
        if 'chat' in available_methods:
            try:
                print("  æµ‹è¯• chat æ–¹æ³•...")
                response = await vllm_model.chat(test_prompt)
                print(f"  âœ… chat æ–¹æ³•æˆåŠŸ: {response[:50]}...")
            except Exception as e:
                print(f"  âŒ chat æ–¹æ³•å¤±è´¥: {e}")
        
        # æ–¹å¼3: completionæ–¹æ³•
        if 'completion' in available_methods:
            try:
                print("  æµ‹è¯• completion æ–¹æ³•...")
                response = await vllm_model.completion(test_prompt)
                print(f"  âœ… completion æ–¹æ³•æˆåŠŸ: {response[:50]}...")
            except Exception as e:
                print(f"  âŒ completion æ–¹æ³•å¤±è´¥: {e}")
        
        # æ–¹å¼4: __call__æ–¹æ³•
        try:
            print("  æµ‹è¯• __call__ æ–¹æ³•...")
            response = await vllm_model(test_prompt)
            print(f"  âœ… __call__ æ–¹æ³•æˆåŠŸ: {response[:50]}...")
        except Exception as e:
            print(f"  âŒ __call__ æ–¹æ³•å¤±è´¥: {e}")
        
        # æ–¹å¼5: æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–ç”Ÿæˆç›¸å…³çš„æ–¹æ³•
        generation_methods = [method for method in available_methods 
                            if any(keyword in method.lower() for keyword in 
                                  ['generate', 'chat', 'completion', 'predict', 'infer'])]
        
        print(f"\nğŸ” å¯èƒ½çš„ç”Ÿæˆæ–¹æ³•: {generation_methods}")
        
        for method_name in generation_methods:
            try:
                print(f"  æµ‹è¯• {method_name} æ–¹æ³•...")
                method = getattr(vllm_model, method_name)
                response = await method(test_prompt)
                print(f"  âœ… {method_name} æ–¹æ³•æˆåŠŸ: {response[:50]}...")
            except Exception as e:
                print(f"  âŒ {method_name} æ–¹æ³•å¤±è´¥: {e}")
        
        # æ£€æŸ¥æ¨¡å‹é…ç½®
        print(f"\nğŸ”§ æ£€æŸ¥æ¨¡å‹é…ç½®:")
        if hasattr(vllm_model, 'model_config'):
            print(f"  - model_config: {vllm_model.model_config}")
        
        if hasattr(vllm_model, 'model_name'):
            print(f"  - model_name: {vllm_model.model_name}")
        
        if hasattr(vllm_model, 'url'):
            print(f"  - url: {vllm_model.url}")
        
        print("\nğŸ‰ Camel VLLM APIæµ‹è¯•å®Œæˆ!")
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
        print("è¯·ç¡®ä¿å·²å®‰è£…Camel: pip install camel-ai")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

async def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ Camel VLLM APIæµ‹è¯•")
    print("=" * 60)
    
    await test_camel_vllm_api()

if __name__ == "__main__":
    asyncio.run(main())
