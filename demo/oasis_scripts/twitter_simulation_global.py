#!/usr/bin/env python3
"""
Twitter Simulation Global - åŸºäº8ä¸ªLoRAæ¨¡å‹çš„å¤šagentè®­ç»ƒç³»ç»Ÿ

è¿™ä¸ªç‰ˆæœ¬ä½¿ç”¨8ä¸ªç‹¬ç«‹çš„LoRAæ¨¡å‹ï¼Œæ¯ä¸ªLoRAåˆ†é…åˆ°å›ºå®šçš„agentç»„ï¼š
- LoRA 1-4: TRUMPç»„ (4ä¸ªLoRA)
- LoRA 5-8: BIDENç»„ (4ä¸ªLoRA)

æ¯ä¸ªLoRAéƒ½æœ‰è‡ªå·±çš„weightæ›´æ–°æœºåˆ¶å’Œrewardè·Ÿè¸ªã€‚
"""

import asyncio
import os
import time
import logging
import random
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass, field
from datetime import datetime
import json

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class LoRAModel:
    """LoRAæ¨¡å‹é…ç½®"""
    lora_id: int
    group: str  # TRUMP or BIDEN
    rank: int = 8
    alpha: float = 16.0
    dropout: float = 0.1
    learning_rate: float = 1e-4
    weights: Dict[str, Any] = field(default_factory=dict)
    performance_history: List[float] = field(default_factory=list)
    reward_history: List[float] = field(default_factory=list)
    total_reward: float = 0.0
    update_count: int = 0
    
    def __post_init__(self):
        """åˆå§‹åŒ–LoRAæƒé‡"""
        # åˆå§‹åŒ–LoRAæƒé‡ (ç®€åŒ–ç‰ˆæœ¬)
        self.weights = {
            'lora_A': [random.uniform(-0.1, 0.1) for _ in range(self.rank)],
            'lora_B': [random.uniform(-0.1, 0.1) for _ in range(self.rank)],
            'scaling': self.alpha / self.rank
        }
    
    def update_weights(self, reward: float, learning_rate: Optional[float] = None):
        """æ›´æ–°LoRAæƒé‡"""
        if learning_rate is None:
            learning_rate = self.learning_rate
        
        # åŸºäºrewardæ›´æ–°æƒé‡
        update_factor = reward * learning_rate
        
        # æ›´æ–°lora_Aæƒé‡
        for i in range(len(self.weights['lora_A'])):
            self.weights['lora_A'][i] += random.uniform(-update_factor, update_factor)
        
        # æ›´æ–°lora_Bæƒé‡
        for i in range(len(self.weights['lora_B'])):
            self.weights['lora_B'][i] += random.uniform(-update_factor, update_factor)
        
        # è®°å½•æ›´æ–°
        self.total_reward += reward
        self.reward_history.append(reward)
        self.update_count += 1
        
        logger.info(f"LoRA {self.lora_id} ({self.group}) æƒé‡æ›´æ–°: reward={reward:.4f}, æ€»reward={self.total_reward:.4f}")
    
    def get_performance(self) -> float:
        """è·å–å½“å‰æ€§èƒ½"""
        if not self.reward_history:
            return 0.0
        return sum(self.reward_history[-10:]) / min(len(self.reward_history), 10)
    
    def get_weight_norm(self) -> float:
        """è·å–æƒé‡èŒƒæ•°"""
        a_norm = sum(x*x for x in self.weights['lora_A']) ** 0.5
        b_norm = sum(x*x for x in self.weights['lora_B']) ** 0.5
        return (a_norm + b_norm) / 2


@dataclass
class Agent:
    """Agenté…ç½®"""
    agent_id: int
    group: str  # TRUMP or BIDEN
    lora_id: int  # åˆ†é…çš„LoRA ID
    belief_strength: float = 0.5
    influence_score: float = 0.5
    recent_actions: List[str] = field(default_factory=list)
    total_reward: float = 0.0
    performance_history: List[float] = field(default_factory=list)


@dataclass
class Post:
    """å¸–å­æ•°æ®ç»“æ„"""
    post_id: int
    agent_id: int
    content: str
    group: str
    created_at: str
    num_likes: int = 0
    num_dislikes: int = 0
    num_reposts: int = 0
    influence_score: float = 0.0


class VLLMClient:
    """VLLMå®¢æˆ·ç«¯ï¼Œä½¿ç”¨Camelå’ŒOasisæ¥å£"""
    
    def __init__(self, url: str = "http://localhost:8001/v1", model_name: str = "qwen-2"):
        self.url = url
        self.model_name = model_name
        self.camel_models = []
        self.connection_available = False
        self.call_count = 0
        
        # åˆå§‹åŒ–Camel VLLMæ¨¡å‹
        self._initialize_camel_models()
    
    def _initialize_camel_models(self):
        """åˆå§‹åŒ–Camel VLLMæ¨¡å‹"""
        try:
            from camel.models import ModelFactory
            from camel.types import ModelPlatformType
            
            # åˆ›å»º8ä¸ªVLLMæ¨¡å‹å®ä¾‹
            for i in range(8):
                vllm_model = ModelFactory.create(
                    model_platform=ModelPlatformType.VLLM,
                    model_type=self.model_name,
                    url=self.url,
                )
                self.camel_models.append(vllm_model)
            
            self.connection_available = True
            print(f"âœ… åˆ›å»ºäº† {len(self.camel_models)} ä¸ªCamel VLLMæ¨¡å‹")
            
        except ImportError:
            print("âš ï¸ Camelæ¨¡å—ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
            self.connection_available = False
        except Exception as e:
            print(f"âš ï¸ Camel VLLMæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self.connection_available = False
    
    async def generate(self, prompt: str, lora_id: Optional[int] = None) -> str:
        """ç”Ÿæˆæ–‡æœ¬å“åº”"""
        self.call_count += 1
        
        if self.camel_models and self.connection_available:
            try:
                # æ ¹æ®lora_idé€‰æ‹©æ¨¡å‹ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šåˆ™éšæœºé€‰æ‹©
                if lora_id is not None and 0 <= lora_id < len(self.camel_models):
                    selected_model = self.camel_models[lora_id]
                else:
                    selected_model = random.choice(self.camel_models)
                
                # ä½¿ç”¨Camel VLLMçš„æ­£ç¡®API: arunæ–¹æ³•
                # æ·»åŠ è¶…æ—¶å’Œé‡è¯•æœºåˆ¶
                import asyncio
                try:
                    # ä½¿ç”¨æ­£ç¡®çš„Camel VLLM APIæ ¼å¼
                    messages = [{"role": "user", "content": prompt}]
                    response = await asyncio.wait_for(
                        selected_model.arun(messages), 
                        timeout=10.0
                    )
                    print(f"ğŸ¤– VLLM (LoRA {lora_id or 'random'}) ç”Ÿæˆ: {response[:50]}...")
                    return response
                except asyncio.TimeoutError:
                    print(f"âš ï¸ VLLM (LoRA {lora_id or 'random'}) è¯·æ±‚è¶…æ—¶ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
                except Exception as e:
                    print(f"âŒ VLLM (LoRA {lora_id or 'random'}) è°ƒç”¨å¤±è´¥: {e}")
                    # å¦‚æœæ˜¯è¿æ¥é”™è¯¯ï¼Œæ ‡è®°è¿æ¥ä¸å¯ç”¨
                    if "Connection" in str(e) or "timeout" in str(e).lower():
                        print("âš ï¸ æ£€æµ‹åˆ°è¿æ¥é—®é¢˜ï¼Œåç»­å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
                        self.connection_available = False
            except Exception as e:
                print(f"âŒ Camel VLLMè°ƒç”¨å¤±è´¥: {e}")
                print("å›é€€åˆ°æ¨¡æ‹Ÿæ¨¡å¼")
        
        # å›é€€åˆ°æ¨¡æ‹Ÿæ¨¡å¼
        return self._generate_mock_response(prompt, lora_id)
    
    def _generate_mock_response(self, prompt: str, lora_id: Optional[int] = None) -> str:
        """ç”Ÿæˆæ¨¡æ‹Ÿå“åº”"""
        prompt_upper = prompt.upper()
        
        # æ ¹æ®LoRA IDè°ƒæ•´å“åº”ç­–ç•¥
        if lora_id is not None:
            if lora_id <= 4:  # TRUMPç»„LoRA
                if "TRUMP" in prompt_upper:
                    return "I strongly support TRUMP and will post/forward TRUMP messages this round."
                else:
                    return "I support TRUMP and will post/forward TRUMP messages this round."
            else:  # BIDENç»„LoRA
                if "BIDEN" in prompt_upper:
                    return "I strongly support BIDEN and will post/forward BIDEN messages this round."
                else:
                    return "I support BIDEN and will post/forward BIDEN messages this round."
        
        # é»˜è®¤å“åº”
        if "TRUMP" in prompt_upper:
            return "I support TRUMP and will post/forward TRUMP messages this round."
        elif "BIDEN" in prompt_upper:
            return "I support BIDEN and will post/forward BIDEN messages this round."
        else:
            return "I will post/forward TRUMP messages this round."


class RewardCalculator:
    """å¥–åŠ±è®¡ç®—å™¨"""
    
    @staticmethod
    def calculate_post_reward(post: Post, agents: List[Agent]) -> float:
        """è®¡ç®—å¸–å­å¥–åŠ±"""
        # åŸºäºäº’åŠ¨æ•°é‡è®¡ç®—å¥–åŠ±
        engagement = post.num_likes + post.num_reposts * 2 - post.num_dislikes
        
        # åŸºäºå½±å“åŠ›è®¡ç®—å¥–åŠ±
        influence_bonus = post.influence_score * 0.5
        
        # åŸºäºç»„åˆ«ä¸€è‡´æ€§è®¡ç®—å¥–åŠ±
        group_consistency = 0.0
        for agent in agents:
            if agent.group == post.group:
                group_consistency += 0.1
        
        total_reward = engagement + influence_bonus + group_consistency
        return max(0.0, total_reward)
    
    @staticmethod
    def calculate_agent_reward(agent: Agent, posts: List[Post]) -> float:
        """è®¡ç®—agentå¥–åŠ±"""
        # åŸºäºagentçš„å¸–å­è¡¨ç°è®¡ç®—å¥–åŠ±
        agent_posts = [p for p in posts if p.agent_id == agent.agent_id]
        
        if not agent_posts:
            return 0.0
        
        total_reward = 0.0
        for post in agent_posts:
            post_reward = RewardCalculator.calculate_post_reward(post, [agent])
            total_reward += post_reward
        
        return total_reward / len(agent_posts)
    
    @staticmethod
    def calculate_lora_reward(lora: LoRAModel, agents: List[Agent], posts: List[Post]) -> float:
        """è®¡ç®—LoRAå¥–åŠ±"""
        # è®¡ç®—ä½¿ç”¨è¯¥LoRAçš„agentsçš„æ€»å¥–åŠ±
        lora_agents = [a for a in agents if a.lora_id == lora.lora_id]
        
        if not lora_agents:
            return 0.0
        
        total_reward = 0.0
        for agent in lora_agents:
            agent_reward = RewardCalculator.calculate_agent_reward(agent, posts)
            total_reward += agent_reward
        
        return total_reward / len(lora_agents)


class TwitterSimulationGlobal:
    """å…¨å±€Twitteræ¨¡æ‹Ÿå™¨ - 8ä¸ªLoRAæ¨¡å‹ç‰ˆæœ¬"""
    
    def __init__(self, num_agents: int = 50, num_steps: int = 50, 
                 vllm_url: str = "http://localhost:8001/v1", 
                 model_name: str = "qwen-2"):
        self.num_agents = num_agents
        self.num_steps = num_steps
        self.current_step = 0
        self.current_post_id = 0
        
        print(f"\nğŸš€ åˆå§‹åŒ–TwitterSimulationGlobal (8 LoRAç‰ˆæœ¬):")
        print(f"   - Agentæ•°é‡: {num_agents}")
        print(f"   - æ—¶é—´æ­¥æ•°: {num_steps}")
        print(f"   - VLLM URL: {vllm_url}")
        print(f"   - æ¨¡å‹åç§°: {model_name}")
        
        # åˆå§‹åŒ–VLLMå®¢æˆ·ç«¯
        self.vllm_client = VLLMClient(vllm_url, model_name)
        
        # åˆå§‹åŒ–8ä¸ªLoRAæ¨¡å‹
        self.lora_models = self._initialize_lora_models()
        
        # åˆå§‹åŒ–agents
        self.agents = self._initialize_agents()
        
        # åˆå§‹åŒ–å¸–å­åˆ—è¡¨
        self.posts = []
        
        # ç»Ÿè®¡æ•°æ®
        self.statistics = {
            'step_rewards': [],  # æ¯æ­¥æ€»å¥–åŠ±
            'lora_rewards': [],  # æ¯æ­¥å„LoRAå¥–åŠ±
            'group_performance': [],  # æ¯æ­¥ç»„åˆ«è¡¨ç°
            'vllm_calls': [],  # VLLMè°ƒç”¨æ¬¡æ•°
            'weight_updates': [],  # æƒé‡æ›´æ–°æ¬¡æ•°
            'belief_changes': [],  # ä¿¡å¿µå˜åŒ–
            'influence_scores': []  # å½±å“åŠ›åˆ†æ•°
        }
        
        print("ğŸ‰ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ!")
    
    def _initialize_lora_models(self) -> List[LoRAModel]:
        """åˆå§‹åŒ–8ä¸ªLoRAæ¨¡å‹"""
        print("\nğŸ”§ åˆå§‹åŒ–8ä¸ªLoRAæ¨¡å‹:")
        
        lora_models = []
        
        # LoRA 1-4: TRUMPç»„
        for i in range(1, 5):
            lora = LoRAModel(
                lora_id=i,
                group="TRUMP",
                rank=8,
                alpha=16.0,
                learning_rate=1e-4
            )
            lora_models.append(lora)
            print(f"   - LoRA {i}: TRUMPç»„, rank={lora.rank}, alpha={lora.alpha}")
        
        # LoRA 5-8: BIDENç»„
        for i in range(5, 9):
            lora = LoRAModel(
                lora_id=i,
                group="BIDEN",
                rank=8,
                alpha=16.0,
                learning_rate=1e-4
            )
            lora_models.append(lora)
            print(f"   - LoRA {i}: BIDENç»„, rank={lora.rank}, alpha={lora.alpha}")
        
        print(f"âœ… åˆ›å»ºäº† {len(lora_models)} ä¸ªLoRAæ¨¡å‹")
        return lora_models
    
    def _initialize_agents(self) -> List[Agent]:
        """åˆå§‹åŒ–agents"""
        print(f"\nğŸ”§ åˆå§‹åŒ– {self.num_agents} ä¸ªagents:")
        
        agents = []
        
        # åˆ†é…agentsåˆ°LoRAæ¨¡å‹
        agents_per_lora = self.num_agents // 8
        remaining_agents = self.num_agents % 8
        
        agent_id = 0
        for lora_id in range(1, 9):
            # è®¡ç®—å½“å‰LoRAåˆ†é…çš„agentæ•°é‡
            current_agents = agents_per_lora
            if remaining_agents > 0:
                current_agents += 1
                remaining_agents -= 1
            
            # åˆ›å»ºagents
            for _ in range(current_agents):
                lora = next(lora for lora in self.lora_models if lora.lora_id == lora_id)
                agent = Agent(
                    agent_id=agent_id,
                    group=lora.group,
                    lora_id=lora_id,
                    belief_strength=random.uniform(0.6, 1.0),
                    influence_score=random.uniform(0.1, 1.0)
                )
                agents.append(agent)
                agent_id += 1
        
        # ç»Ÿè®¡
        trump_agents = [a for a in agents if a.group == "TRUMP"]
        biden_agents = [a for a in agents if a.group == "BIDEN"]
        
        print(f"   - TRUMPç»„: {len(trump_agents)} agents")
        print(f"   - BIDENç»„: {len(biden_agents)} agents")
        
        for lora in self.lora_models:
            lora_agents = [a for a in agents if a.lora_id == lora.lora_id]
            print(f"   - LoRA {lora.lora_id} ({lora.group}): {len(lora_agents)} agents")
        
        print(f"âœ… åˆ›å»ºäº† {len(agents)} ä¸ªagents")
        return agents
    
    async def simulate_step(self):
        """æ¨¡æ‹Ÿä¸€ä¸ªæ—¶é—´æ­¥"""
        self.current_step += 1
        logger.info(f"=== æ—¶é—´æ­¥ {self.current_step} ===")
        
        step_start_time = time.time()
        vllm_calls_this_step = 0
        weight_updates_this_step = 0
        
        # 1. ç”Ÿæˆå¸–å­
        new_posts = []
        for agent in self.agents:
            # å‘å¸–æ¦‚ç‡
            if random.random() < 0.2:  # 20%æ¦‚ç‡å‘å¸–
                # ä½¿ç”¨å¯¹åº”çš„LoRAç”Ÿæˆå¸–å­å†…å®¹
                prompt = (
                    f"You are a {agent.group} supporter using LoRA {agent.lora_id}. "
                    f"Generate a short post (max 100 characters) about your political views. "
                    f"Make it engaging and authentic to your group's perspective."
                )
                
                try:
                    generated_content = await self.vllm_client.generate(prompt, agent.lora_id)
                    vllm_calls_this_step += 1
                    
                    # æ¸…ç†ç”Ÿæˆçš„å†…å®¹
                    clean_content = generated_content[:100].strip()
                    if not clean_content:
                        clean_content = f"{agent.group} supporter post {self.current_post_id}"
                except Exception as e:
                    print(f"VLLM generation failed for agent {agent.agent_id}: {e}")
                    clean_content = f"{agent.group} supporter post {self.current_post_id}"
                
                post = Post(
                    post_id=self.current_post_id,
                    agent_id=agent.agent_id,
                    content=clean_content,
                    group=agent.group,
                    created_at=datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                )
                new_posts.append(post)
                self.current_post_id += 1
                
                # è®°å½•action
                agent.recent_actions.append(f"CREATE_POST:{post.post_id}")
        
        # æ·»åŠ æ–°å¸–å­
        self.posts.extend(new_posts)
        
        # 2. äº’åŠ¨è¡Œä¸º
        for agent in self.agents:
            if random.random() < 0.3:  # 30%æ¦‚ç‡äº’åŠ¨
                # é€‰æ‹©è¦äº’åŠ¨çš„å¸–å­
                available_posts = [p for p in self.posts if p.agent_id != agent.agent_id]
                if available_posts:
                    post = random.choice(available_posts)
                    
                    # ä½¿ç”¨å¯¹åº”çš„LoRAå†³å®šäº’åŠ¨ç±»å‹
                    interaction_prompt = (
                        f"You are a {agent.group} supporter using LoRA {agent.lora_id}. "
                        f"You see a post: '{post.content[:50]}...' "
                        f"from a {post.group} supporter. "
                        f"Will you LIKE, REPOST, or DISLIKE this post? "
                        f"Respond with only one word: LIKE, REPOST, or DISLIKE."
                    )
                    
                    try:
                        interaction_decision = await self.vllm_client.generate(interaction_prompt, agent.lora_id)
                        vllm_calls_this_step += 1
                        
                        action_upper = interaction_decision.upper().strip()
                        
                        if "LIKE" in action_upper:
                            post.num_likes += 1
                            agent.recent_actions.append(f"LIKE_POST:{post.post_id}")
                        elif "REPOST" in action_upper:
                            post.num_reposts += 1
                            agent.recent_actions.append(f"REPOST:{post.post_id}")
                        else:
                            post.num_dislikes += 1
                            agent.recent_actions.append(f"DISLIKE_POST:{post.post_id}")
                            
                    except Exception as e:
                        print(f"VLLM interaction decision failed for agent {agent.agent_id}: {e}")
                        # å›é€€åˆ°åŸºäºä¿¡å¿µçš„å†³ç­–
                        if agent.group == post.group:
                            post.num_likes += 1
                            agent.recent_actions.append(f"LIKE_POST:{post.post_id}")
                        else:
                            post.num_dislikes += 1
                            agent.recent_actions.append(f"DISLIKE_POST:{post.post_id}")
        
        # 3. è®¡ç®—å¥–åŠ±å¹¶æ›´æ–°LoRAæƒé‡
        lora_rewards_this_step = []
        for lora in self.lora_models:
            # è®¡ç®—LoRAå¥–åŠ±
            lora_reward = RewardCalculator.calculate_lora_reward(lora, self.agents, self.posts)
            lora_rewards_this_step.append(lora_reward)
            
            # æ›´æ–°LoRAæƒé‡
            if lora_reward > 0:
                lora.update_weights(lora_reward)
                weight_updates_this_step += 1
        
        # 4. æ›´æ–°agentæ€§èƒ½
        for agent in self.agents:
            agent_reward = RewardCalculator.calculate_agent_reward(agent, self.posts)
            agent.total_reward += agent_reward
            agent.performance_history.append(agent_reward)
        
        # 5. è®°å½•ç»Ÿè®¡ä¿¡æ¯
        step_total_reward = sum(lora_rewards_this_step)
        step_time = time.time() - step_start_time
        
        self.statistics['step_rewards'].append(step_total_reward)
        self.statistics['lora_rewards'].append(lora_rewards_this_step)
        self.statistics['vllm_calls'].append(vllm_calls_this_step)
        self.statistics['weight_updates'].append(weight_updates_this_step)
        
        # 6. è¾“å‡ºæ­¥éª¤ç»Ÿè®¡
        self._print_step_statistics(step_total_reward, lora_rewards_this_step, 
                                  vllm_calls_this_step, weight_updates_this_step, step_time)
    
    def _print_step_statistics(self, total_reward: float, lora_rewards: List[float], 
                             vllm_calls: int, weight_updates: int, step_time: float):
        """æ‰“å°æ­¥éª¤ç»Ÿè®¡ä¿¡æ¯"""
        logger.info(f"ğŸ“Š æ­¥éª¤ {self.current_step} ç»Ÿè®¡:")
        logger.info(f"   - æ€»å¥–åŠ±: {total_reward:.4f}")
        logger.info(f"   - VLLMè°ƒç”¨: {vllm_calls}")
        logger.info(f"   - æƒé‡æ›´æ–°: {weight_updates}")
        logger.info(f"   - æ‰§è¡Œæ—¶é—´: {step_time:.2f}ç§’")
        
        # LoRAå¥–åŠ±è¯¦æƒ…
        logger.info(f"   - LoRAå¥–åŠ±è¯¦æƒ…:")
        for i, reward in enumerate(lora_rewards):
            lora = self.lora_models[i]
            logger.info(f"     * LoRA {lora.lora_id} ({lora.group}): {reward:.4f}")
        
        # ç»„åˆ«è¡¨ç°
        trump_agents = [a for a in self.agents if a.group == "TRUMP"]
        biden_agents = [a for a in self.agents if a.group == "BIDEN"]
        
        trump_reward = sum(lora_rewards[i] for i, lora in enumerate(self.lora_models) if lora.group == "TRUMP")
        biden_reward = sum(lora_rewards[i] for i, lora in enumerate(self.lora_models) if lora.group == "BIDEN")
        
        logger.info(f"   - ç»„åˆ«è¡¨ç°:")
        logger.info(f"     * TRUMPç»„: {trump_reward:.4f} ({len(trump_agents)} agents)")
        logger.info(f"     * BIDENç»„: {biden_reward:.4f} ({len(biden_agents)} agents)")
        
        # å¸–å­ç»Ÿè®¡
        trump_posts = [p for p in self.posts if p.group == "TRUMP"]
        biden_posts = [p for p in self.posts if p.group == "BIDEN"]
        
        logger.info(f"   - å¸–å­ç»Ÿè®¡:")
        logger.info(f"     * TRUMPå¸–å­: {len(trump_posts)}, æ€»ç‚¹èµ: {sum(p.num_likes for p in trump_posts)}")
        logger.info(f"     * BIDENå¸–å­: {len(biden_posts)}, æ€»ç‚¹èµ: {sum(p.num_likes for p in biden_posts)}")
    
    async def run_simulation(self):
        """è¿è¡Œå®Œæ•´æ¨¡æ‹Ÿ"""
        logger.info("å¼€å§‹8 LoRA Twitteræ¨¡æ‹Ÿ...")
        
        # è¿è¡Œæ¨¡æ‹Ÿ
        for step in range(self.num_steps):
            await self.simulate_step()
            
            # æ¯10æ­¥è¾“å‡ºè¯¦ç»†ç»Ÿè®¡
            if (step + 1) % 10 == 0:
                self._print_detailed_statistics()
        
        logger.info("æ¨¡æ‹Ÿå®Œæˆ!")
        self._print_final_statistics()
    
    def _print_detailed_statistics(self):
        """æ‰“å°è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        logger.info("=" * 60)
        logger.info("è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯:")
        
        # LoRAæ€§èƒ½ç»Ÿè®¡
        logger.info("LoRAæ€§èƒ½ç»Ÿè®¡:")
        for lora in self.lora_models:
            performance = lora.get_performance()
            weight_norm = lora.get_weight_norm()
            logger.info(f"  - LoRA {lora.lora_id} ({lora.group}):")
            logger.info(f"    æ€§èƒ½: {performance:.4f}")
            logger.info(f"    æƒé‡èŒƒæ•°: {weight_norm:.4f}")
            logger.info(f"    æ€»å¥–åŠ±: {lora.total_reward:.4f}")
            logger.info(f"    æ›´æ–°æ¬¡æ•°: {lora.update_count}")
        
        # Agentæ€§èƒ½ç»Ÿè®¡
        logger.info("Agentæ€§èƒ½ç»Ÿè®¡:")
        for lora in self.lora_models:
            lora_agents = [a for a in self.agents if a.lora_id == lora.lora_id]
            if lora_agents:
                avg_reward = sum(a.total_reward for a in lora_agents) / len(lora_agents)
                logger.info(f"  - LoRA {lora.lora_id} agents: å¹³å‡å¥–åŠ± {avg_reward:.4f}")
        
        logger.info("=" * 60)
    
    def _print_final_statistics(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        logger.info("=" * 80)
        logger.info("æœ€ç»ˆç»Ÿè®¡ç»“æœ:")
        logger.info("=" * 80)
        
        # æ€»ä½“ç»Ÿè®¡
        total_vllm_calls = sum(self.statistics['vllm_calls'])
        total_weight_updates = sum(self.statistics['weight_updates'])
        total_reward = sum(self.statistics['step_rewards'])
        
        logger.info(f"æ€»ä½“ç»Ÿè®¡:")
        logger.info(f"  - æ€»VLLMè°ƒç”¨: {total_vllm_calls}")
        logger.info(f"  - æ€»æƒé‡æ›´æ–°: {total_weight_updates}")
        logger.info(f"  - æ€»å¥–åŠ±: {total_reward:.4f}")
        logger.info(f"  - å¹³å‡æ¯æ­¥å¥–åŠ±: {total_reward/self.num_steps:.4f}")
        
        # LoRAæœ€ç»ˆæ€§èƒ½
        logger.info(f"LoRAæœ€ç»ˆæ€§èƒ½:")
        for lora in self.lora_models:
            performance = lora.get_performance()
            weight_norm = lora.get_weight_norm()
            logger.info(f"  - LoRA {lora.lora_id} ({lora.group}):")
            logger.info(f"    æœ€ç»ˆæ€§èƒ½: {performance:.4f}")
            logger.info(f"    æœ€ç»ˆæƒé‡èŒƒæ•°: {weight_norm:.4f}")
            logger.info(f"    æ€»å¥–åŠ±: {lora.total_reward:.4f}")
            logger.info(f"    æ›´æ–°æ¬¡æ•°: {lora.update_count}")
        
        # ç»„åˆ«å¯¹æ¯”
        trump_loras = [lora for lora in self.lora_models if lora.group == "TRUMP"]
        biden_loras = [lora for lora in self.lora_models if lora.group == "BIDEN"]
        
        trump_total_reward = sum(lora.total_reward for lora in trump_loras)
        biden_total_reward = sum(lora.total_reward for lora in biden_loras)
        
        logger.info(f"ç»„åˆ«å¯¹æ¯”:")
        logger.info(f"  - TRUMPç»„æ€»å¥–åŠ±: {trump_total_reward:.4f}")
        logger.info(f"  - BIDENç»„æ€»å¥–åŠ±: {biden_total_reward:.4f}")
        logger.info(f"  - èƒœå‡ºç»„: {'TRUMP' if trump_total_reward > biden_total_reward else 'BIDEN'}")
        
        logger.info("=" * 80)
    
    def save_results(self, filename: str = "twitter_simulation_8lora_results.json"):
        """ä¿å­˜æ¨¡æ‹Ÿç»“æœ"""
        results = {
            'simulation_config': {
                'num_agents': self.num_agents,
                'num_steps': self.num_steps
            },
            'lora_models': [
                {
                    'lora_id': lora.lora_id,
                    'group': lora.group,
                    'total_reward': lora.total_reward,
                    'update_count': lora.update_count,
                    'final_performance': lora.get_performance(),
                    'final_weight_norm': lora.get_weight_norm(),
                    'reward_history': lora.reward_history
                }
                for lora in self.lora_models
            ],
            'agents': [
                {
                    'agent_id': agent.agent_id,
                    'group': agent.group,
                    'lora_id': agent.lora_id,
                    'total_reward': agent.total_reward,
                    'belief_strength': agent.belief_strength,
                    'influence_score': agent.influence_score
                }
                for agent in self.agents
            ],
            'posts': [
                {
                    'post_id': post.post_id,
                    'agent_id': post.agent_id,
                    'group': post.group,
                    'num_likes': post.num_likes,
                    'num_reposts': post.num_reposts,
                    'content': post.content
                }
                for post in self.posts
            ],
            'statistics': self.statistics
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ç»“æœå·²ä¿å­˜åˆ° {filename}")


async def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸš€ Twitter Simulation Global - 8 LoRAæ¨¡å‹ç‰ˆæœ¬")
    print("=" * 80)
    
    try:
        # åˆ›å»ºæ¨¡æ‹Ÿå™¨
        print("\nğŸ“‹ åˆ›å»º8 LoRA Twitteræ¨¡æ‹Ÿå™¨...")
        simulation = TwitterSimulationGlobal(num_agents=50, num_steps=30)
        
        # è¿è¡Œæ¨¡æ‹Ÿ
        print("\nğŸ¬ å¼€å§‹8 LoRA Twitteræ¨¡æ‹Ÿ...")
        await simulation.run_simulation()
        
        # ä¿å­˜ç»“æœ
        print("\nğŸ’¾ ä¿å­˜æ¨¡æ‹Ÿç»“æœ...")
        simulation.save_results()
        
        print("\n" + "=" * 80)
        print("ğŸ‰ 8 LoRAæ¨¡æ‹Ÿå®Œæˆï¼")
        print("=" * 80)
        
    except Exception as e:
        print(f"\nâŒ æ¨¡æ‹Ÿè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
