#!/usr/bin/env python3
"""
Twitter Simulation Global - åŸºäºå…¨å±€æ¨èç³»ç»Ÿçš„Twitteræ¨¡æ‹Ÿå™¨

è¿™ä¸ªç‰ˆæœ¬ä½¿ç”¨å…¨å±€è®¡ç®—é€»è¾‘ï¼Œè€Œä¸æ˜¯å±€éƒ¨çš„neighborhoodè®¡ç®—ã€‚
åŸºäºrecsysçš„å…¨å›¾è®¡ç®—é€»è¾‘ï¼ŒåŒ…æ‹¬ï¼š
1. å…¨å±€ç”¨æˆ·-å¸–å­ç›¸ä¼¼åº¦è®¡ç®—
2. å…¨å±€æ¨èçŸ©é˜µç”Ÿæˆ
3. å…¨å±€å½±å“åŠ›ä¼ æ’­
4. å…¨å±€ä¿¡å¿µæ›´æ–°
"""

import asyncio
import os
import time
import logging
import random
from typing import Dict, List, Tuple, Any
from dataclasses import dataclass, field
from datetime import datetime
import json

# Import SandGraph core and architecture modules
try:
    from sandgraph.core.async_architecture import (
        VLLMClient as SandGraphVLLMClient,
        RewardBasedSlotManager,
        OASISSandbox,
        AsyncAgentWorkflow,
        LLMPolicy,
        AgentGraph,
        OASISCorrectSimulation,
        BeliefType,
        AgentState
    )
    from sandgraph.core.self_evolving_oasis import (
        create_self_evolving_oasis, EvolutionStrategy
    )
    from sandgraph.core.areal_integration import (
        create_areal_integration, IntegrationLevel
    )
    from sandgraph.core.llm_frozen_adaptive import (
        create_frozen_adaptive_llm, create_frozen_config, UpdateStrategy
    )
    HAS_SANDGRAPH = True
    print("âœ… SandGraph core modules imported successfully")
except ImportError as e:
    HAS_SANDGRAPH = False
    print(f"âŒ SandGraph core modules not available: {e}")
    print("Will use mock implementations")

# Import camel and oasis related modules
try:
    from camel.models import ModelFactory
    from camel.types import ModelPlatformType
    HAS_CAMEL = True
    print("âœ… Camel modules imported successfully")
except ImportError:
    HAS_CAMEL = False
    print("âŒ Camel modules not available, using mock implementations")

try:
    import oasis
    from oasis import (ActionType, LLMAction, ManualAction,
                      generate_reddit_agent_graph)
    HAS_OASIS = True
    print("âœ… Oasis modules imported successfully")
except ImportError:
    HAS_OASIS = False
    print("âŒ Oasis modules not available, using mock implementations")

# Optional numpy import
try:
    import numpy as np
    HAS_NUMPY = True
except ImportError:
    HAS_NUMPY = False
    # Simple numpy replacement for basic operations
    class SimpleNumpy:
        @staticmethod
        def array(data):
            return data
        
        @staticmethod
        def mean(data):
            return sum(data) / len(data) if data else 0
        
        @staticmethod
        def zeros(shape):
            if isinstance(shape, int):
                return [0.0] * shape
            elif len(shape) == 2:
                return [[0.0] * shape[1] for _ in range(shape[0])]
            return [0.0] * shape[0]
        
        @staticmethod
        def concatenate(arrays, axis=0):
            if axis == 0:
                result = []
                for arr in arrays:
                    result.extend(arr)
                return result
            return arrays
        
        class linalg:
            @staticmethod
            def norm(vector, axis=None, keepdims=False):
                if axis is None:
                    return (sum(x*x for x in vector))**0.5
                return [(sum(x*x for x in row))**0.5 for row in vector]
        
        @staticmethod
        def dot(a, b):
            if isinstance(a[0], (list, tuple)):
                # Matrix multiplication
                result = []
                for i in range(len(a)):
                    row = []
                    for j in range(len(b[0])):
                        sum_val = 0
                        for k in range(len(a[0])):
                            sum_val += a[i][k] * b[k][j]
                        row.append(sum_val)
                    result.append(row)
                return result
            else:
                # Vector dot product
                return sum(x*y for x, y in zip(a, b))
        
        @staticmethod
        def argsort(data):
            return sorted(range(len(data)), key=lambda i: data[i])
        
        @staticmethod
        def nan_to_num(data, nan=0.0):
            return [nan if x != x else x for x in data]  # x != x checks for NaN
    
    np = SimpleNumpy()

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class User:
    """ç”¨æˆ·æ•°æ®ç»“æ„"""
    user_id: int
    agent_id: int
    bio: str
    num_followers: int
    group: str = "NEUTRAL"  # TRUMP, BIDEN, NEUTRAL
    belief_strength: float = 0.5  # ä¿¡å¿µå¼ºåº¦ 0-1
    influence_score: float = 0.5  # å½±å“åŠ›åˆ†æ•°
    recent_posts: List[str] = field(default_factory=list)
    liked_posts: List[int] = field(default_factory=list)
    disliked_posts: List[int] = field(default_factory=list)


@dataclass
class Post:
    """å¸–å­æ•°æ®ç»“æ„"""
    post_id: int
    user_id: int
    content: str
    created_at: str
    num_likes: int = 0
    num_dislikes: int = 0
    num_reposts: int = 0
    group: str = "NEUTRAL"  # TRUMP, BIDEN, NEUTRAL
    influence_score: float = 0.0


@dataclass
class Trace:
    """ç”¨æˆ·è¡Œä¸ºè¿½è¸ª"""
    user_id: int
    post_id: int
    action: str  # LIKE_POST, UNLIKE_POST, REPOST, CREATE_POST
    timestamp: str
    info: str = ""


class VLLMClient:
    """VLLMå®¢æˆ·ç«¯ï¼Œç”¨äºLLMè°ƒç”¨"""
    
    def __init__(self, url: str = "http://localhost:8001/v1", model_name: str = "qwen-2"):
        self.url = url
        self.model_name = model_name
        self.session = None
        self.sandgraph_client = None
        
        # å¦‚æœSandGraphå¯ç”¨ï¼Œå°è¯•ä½¿ç”¨å…¶VLLMå®¢æˆ·ç«¯
        if HAS_SANDGRAPH:
            try:
                self.sandgraph_client = SandGraphVLLMClient(url, model_name)
                print(f"âœ… ä½¿ç”¨SandGraph VLLMå®¢æˆ·ç«¯: {url}")
            except Exception as e:
                print(f"âš ï¸ SandGraph VLLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
                print("å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
    
    async def generate(self, prompt: str) -> str:
        """ç”Ÿæˆæ–‡æœ¬å“åº”"""
        # ä¼˜å…ˆä½¿ç”¨SandGraphçš„VLLMå®¢æˆ·ç«¯
        if self.sandgraph_client and HAS_SANDGRAPH:
            try:
                async with self.sandgraph_client as client:
                    response = await client.generate(prompt)
                    print(f"ğŸ¤– SandGraph VLLMç”Ÿæˆ: {response[:50]}...")
                    return response
            except Exception as e:
                print(f"âŒ SandGraph VLLMè°ƒç”¨å¤±è´¥: {e}")
                print("å›é€€åˆ°æ¨¡æ‹Ÿæ¨¡å¼")
        
        # å›é€€åˆ°æ¨¡æ‹Ÿæ¨¡å¼
        return self._generate_mock_response(prompt)
    
    def _generate_mock_response(self, prompt: str) -> str:
        """ç”Ÿæˆæ¨¡æ‹Ÿå“åº”"""
        prompt_upper = prompt.upper()
        if "TRUMP" in prompt_upper:
            return "I support TRUMP and will post/forward TRUMP messages this round."
        elif "BIDEN" in prompt_upper:
            return "I support BIDEN and will post/forward BIDEN messages this round."
        elif "LIKE" in prompt_upper or "REPOST" in prompt_upper or "DISLIKE" in prompt_upper:
            # äº’åŠ¨å†³ç­–
            if "TRUMP" in prompt_upper:
                return "LIKE" if random.random() > 0.3 else "REPOST"
            elif "BIDEN" in prompt_upper:
                return "LIKE" if random.random() > 0.3 else "REPOST"
            else:
                return "LIKE" if random.random() > 0.5 else "DISLIKE"
        else:
            return "I will post/forward TRUMP messages this round."


class GlobalRecommendationSystem:
    """å…¨å±€æ¨èç³»ç»Ÿ"""
    
    def __init__(self, max_rec_posts: int = 10):
        self.max_rec_posts = max_rec_posts
        self.user_embeddings = {}  # ç”¨æˆ·åµŒå…¥å‘é‡
        self.post_embeddings = {}  # å¸–å­åµŒå…¥å‘é‡
        self.global_similarity_matrix = None  # å…¨å±€ç›¸ä¼¼åº¦çŸ©é˜µ
        
    def generate_user_embedding(self, user: User) -> Any:
        """ç”Ÿæˆç”¨æˆ·åµŒå…¥å‘é‡ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        # åŸºäºç”¨æˆ·bioå’Œgroupç”ŸæˆåµŒå…¥
        bio_vector = self._text_to_vector(user.bio)
        group_vector = self._group_to_vector(user.group)
        belief_vector = np.array([user.belief_strength])
        influence_vector = np.array([user.influence_score])
        
        # ç»„åˆå‘é‡
        embedding = np.concatenate([
            bio_vector, 
            group_vector, 
            belief_vector, 
            influence_vector
        ])
        
        # å½’ä¸€åŒ–
        norm = np.linalg.norm(embedding)
        try:
            if isinstance(norm, (int, float)) and norm > 0:
                if hasattr(embedding, '__truediv__'):
                    embedding = embedding / norm
                else:
                    # å›é€€åˆ°ç®€å•é™¤æ³•
                    embedding = [x / norm for x in embedding] if isinstance(embedding, list) else embedding
        except Exception:
            # å¦‚æœå½’ä¸€åŒ–å¤±è´¥ï¼Œä¿æŒåŸå€¼
            pass
            
        return embedding
    
    def generate_post_embedding(self, post: Post) -> Any:
        """ç”Ÿæˆå¸–å­åµŒå…¥å‘é‡ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        # åŸºäºå¸–å­å†…å®¹å’Œgroupç”ŸæˆåµŒå…¥
        content_vector = self._text_to_vector(post.content)
        group_vector = self._group_to_vector(post.group)
        engagement_vector = np.array([
            post.num_likes / max(post.num_likes + post.num_dislikes, 1),
            post.num_reposts / max(post.num_likes + post.num_dislikes, 1)
        ])
        
        # ç»„åˆå‘é‡
        embedding = np.concatenate([
            content_vector,
            group_vector,
            engagement_vector
        ])
        
        # å½’ä¸€åŒ–
        norm = np.linalg.norm(embedding)
        try:
            if isinstance(norm, (int, float)) and norm > 0:
                if hasattr(embedding, '__truediv__'):
                    embedding = embedding / norm
                else:
                    # å›é€€åˆ°ç®€å•é™¤æ³•
                    embedding = [x / norm for x in embedding] if isinstance(embedding, list) else embedding
        except Exception:
            # å¦‚æœå½’ä¸€åŒ–å¤±è´¥ï¼Œä¿æŒåŸå€¼
            pass
            
        return embedding
    
    def _text_to_vector(self, text: str) -> Any:
        """å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        # ç®€å•çš„è¯é¢‘å‘é‡
        words = text.lower().split()
        word_freq = {}
        for word in words:
            word_freq[word] = word_freq.get(word, 0) + 1
        
        # å›ºå®šé•¿åº¦å‘é‡
        vector = np.zeros(50)
        for i, (word, freq) in enumerate(list(word_freq.items())[:50]):
            vector[i] = freq
            
        return vector
    
    def _group_to_vector(self, group: str) -> Any:
        """å°†ç»„åˆ«è½¬æ¢ä¸ºå‘é‡"""
        if group == "TRUMP":
            return np.array([1, 0, 0])
        elif group == "BIDEN":
            return np.array([0, 1, 0])
        else:
            return np.array([0, 0, 1])
    
    def calculate_global_similarity_matrix(self, users: List[User], posts: List[Post]) -> Any:
        """è®¡ç®—å…¨å±€ç”¨æˆ·-å¸–å­ç›¸ä¼¼åº¦çŸ©é˜µ"""
        logger.info("è®¡ç®—å…¨å±€ç›¸ä¼¼åº¦çŸ©é˜µ...")
        start_time = time.time()
        
        # ç”Ÿæˆæ‰€æœ‰ç”¨æˆ·å’Œå¸–å­çš„åµŒå…¥
        user_embeddings = []
        for user in users:
            embedding = self.generate_user_embedding(user)
            self.user_embeddings[user.user_id] = embedding
            user_embeddings.append(embedding)
        
        post_embeddings = []
        for post in posts:
            embedding = self.generate_post_embedding(post)
            self.post_embeddings[post.post_id] = embedding
            post_embeddings.append(embedding)
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        user_embeddings = np.array(user_embeddings)
        post_embeddings = np.array(post_embeddings)
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦çŸ©é˜µ
        # ä½¿ç”¨çŸ©é˜µä¹˜æ³•è®¡ç®—ç‚¹ç§¯
        dot_product = np.dot(user_embeddings, post_embeddings.T)
        
        # è®¡ç®—èŒƒæ•°
        user_norms = np.linalg.norm(user_embeddings, axis=1, keepdims=True)
        post_norms = np.linalg.norm(post_embeddings, axis=1, keepdims=True)
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        try:
            # å°è¯•ä½¿ç”¨numpyçš„Tå±æ€§
            if hasattr(post_norms, 'T'):
                similarity_matrix = dot_product / (user_norms * post_norms.T)
            else:
                # å›é€€åˆ°ç®€å•è®¡ç®—
                similarity_matrix = dot_product / (user_norms * post_norms)
        except Exception:
            # å¦‚æœè®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨ç®€å•é™¤æ³•
            similarity_matrix = dot_product / (user_norms * post_norms)
        
        # å¤„ç†é™¤é›¶æƒ…å†µ
        similarity_matrix = np.nan_to_num(similarity_matrix, nan=0.0)
        
        self.global_similarity_matrix = similarity_matrix
        
        end_time = time.time()
        logger.info(f"å…¨å±€ç›¸ä¼¼åº¦çŸ©é˜µè®¡ç®—å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")
        
        # å®‰å…¨åœ°è·å–çŸ©é˜µå½¢çŠ¶
        try:
            if hasattr(similarity_matrix, 'shape'):
                logger.info(f"çŸ©é˜µå½¢çŠ¶: {similarity_matrix.shape}")
            else:
                logger.info(f"çŸ©é˜µç±»å‹: {type(similarity_matrix)}")
        except Exception:
            logger.info("çŸ©é˜µå½¢çŠ¶ä¿¡æ¯ä¸å¯ç”¨")
        
        return similarity_matrix
    
    def get_recommendations_for_user(self, user_id: int, posts: List[Post], 
                                   exclude_own_posts: bool = True) -> List[int]:
        """ä¸ºç”¨æˆ·è·å–æ¨èå¸–å­"""
        if self.global_similarity_matrix is None:
            raise ValueError("éœ€è¦å…ˆè®¡ç®—å…¨å±€ç›¸ä¼¼åº¦çŸ©é˜µ")
        
        # è·å–ç”¨æˆ·ç´¢å¼•
        user_index = user_id  # å‡è®¾user_idå°±æ˜¯ç´¢å¼•
        
        # æ£€æŸ¥ç”¨æˆ·ç´¢å¼•æ˜¯å¦æœ‰æ•ˆ
        if user_index >= len(self.global_similarity_matrix):
            logger.warning(f"ç”¨æˆ·ç´¢å¼• {user_index} è¶…å‡ºèŒƒå›´ï¼Œè¿”å›ç©ºæ¨èåˆ—è¡¨")
            return []
        
        # è·å–è¯¥ç”¨æˆ·å¯¹æ‰€æœ‰å¸–å­çš„ç›¸ä¼¼åº¦
        try:
            user_similarities = self.global_similarity_matrix[user_index]
            # å°è¯•åˆ›å»ºå‰¯æœ¬
            if hasattr(user_similarities, 'copy'):
                user_similarities = user_similarities.copy()
            else:
                # å¦‚æœæ²¡æœ‰copyæ–¹æ³•ï¼Œå°è¯•è½¬æ¢ä¸ºåˆ—è¡¨
                user_similarities = list(user_similarities) if user_similarities else []
        except Exception as e:
            logger.warning(f"è·å–ç”¨æˆ·ç›¸ä¼¼åº¦å¤±è´¥: {e}")
            user_similarities = []
        
        # æ’é™¤ç”¨æˆ·è‡ªå·±çš„å¸–å­
        if exclude_own_posts:
            for i, post in enumerate(posts):
                if i < len(user_similarities) and post.user_id == user_id:
                    user_similarities[i] = -1  # è®¾ç½®ä¸ºè´Ÿå€¼ï¼Œç¡®ä¿ä¸ä¼šè¢«æ¨è
        
        # è·å–ç›¸ä¼¼åº¦æœ€é«˜çš„å¸–å­ç´¢å¼•
        try:
            # ç¡®ä¿user_similaritiesæ˜¯åˆ—è¡¨è€Œä¸æ˜¯numpyæ•°ç»„
            if hasattr(user_similarities, 'tolist'):
                user_similarities = user_similarities.tolist()
            
            # åˆ›å»º(ç›¸ä¼¼åº¦, ç´¢å¼•)å¯¹å¹¶æ’åº
            similarity_pairs = [(sim, i) for i, sim in enumerate(user_similarities)]
            similarity_pairs.sort(key=lambda x: x[0], reverse=True)
            
            # è·å–å‰max_rec_postsä¸ªç´¢å¼•
            top_indices = [pair[1] for pair in similarity_pairs[:self.max_rec_posts]]
        except Exception as e:
            logger.error(f"æ’åºå¤±è´¥: {e}")
            return []
        
        # è¿”å›å¸–å­ID
        recommended_post_ids = []
        for idx in top_indices:
            if idx < len(posts) and idx < len(user_similarities) and user_similarities[idx] > 0:
                recommended_post_ids.append(posts[idx].post_id)
        
        return recommended_post_ids


class GlobalInfluenceCalculator:
    """å…¨å±€å½±å“åŠ›è®¡ç®—å™¨"""
    
    def __init__(self):
        self.influence_matrix = None
        self.global_influence_scores = {}
    
    def calculate_global_influence(self, users: List[User], posts: List[Post], 
                                 traces: List[Trace]) -> Dict[int, float]:
        """è®¡ç®—å…¨å±€å½±å“åŠ›åˆ†æ•°"""
        logger.info("è®¡ç®—å…¨å±€å½±å“åŠ›...")
        
        # åˆå§‹åŒ–å½±å“åŠ›åˆ†æ•°
        influence_scores = {user.user_id: user.influence_score for user in users}
        
        # åŸºäºå¸–å­ä¼ æ’­è®¡ç®—å½±å“åŠ›
        for post in posts:
            # è®¡ç®—å¸–å­çš„ä¼ æ’­å½±å“åŠ›
            post_influence = self._calculate_post_influence(post, traces)
            
            # å°†å½±å“åŠ›åˆ†é…ç»™å¸–å­ä½œè€…
            author_id = post.user_id
            if author_id in influence_scores:
                influence_scores[author_id] += post_influence * 0.1  # è¡°å‡å› å­
        
        # åŸºäºç”¨æˆ·äº’åŠ¨è®¡ç®—å½±å“åŠ›
        for trace in traces:
            if trace.action == "LIKE_POST":
                # ç‚¹èµå¢åŠ å½±å“åŠ›
                post_author = next((p.user_id for p in posts if p.post_id == trace.post_id), None)
                if post_author and post_author in influence_scores:
                    influence_scores[post_author] += 0.01
            elif trace.action == "REPOST":
                # è½¬å‘å¤§å¹…å¢åŠ å½±å“åŠ›
                post_author = next((p.user_id for p in posts if p.post_id == trace.post_id), None)
                if post_author and post_author in influence_scores:
                    influence_scores[post_author] += 0.05
        
        # å½’ä¸€åŒ–å½±å“åŠ›åˆ†æ•°
        max_influence = max(influence_scores.values()) if influence_scores else 1.0
        if max_influence > 0:
            for user_id in influence_scores:
                influence_scores[user_id] = min(influence_scores[user_id] / max_influence, 1.0)
        
        self.global_influence_scores = influence_scores
        return influence_scores
    
    def _calculate_post_influence(self, post: Post, traces: List[Trace]) -> float:
        """è®¡ç®—å•ä¸ªå¸–å­çš„å½±å“åŠ›"""
        # åŸºäºäº’åŠ¨æ•°é‡è®¡ç®—å½±å“åŠ›
        engagement = post.num_likes + post.num_dislikes + post.num_reposts * 2
        time_factor = 1.0  # å¯ä»¥åŸºäºæ—¶é—´è¡°å‡
        
        return engagement * time_factor


class GlobalBeliefUpdater:
    """å…¨å±€ä¿¡å¿µæ›´æ–°å™¨"""
    
    def __init__(self, belief_update_rate: float = 0.1):
        self.belief_update_rate = belief_update_rate
    
    def update_global_beliefs(self, users: List[User], posts: List[Post], 
                            traces: List[Trace], rec_system: GlobalRecommendationSystem) -> List[User]:
        """å…¨å±€ä¿¡å¿µæ›´æ–°"""
        logger.info("æ›´æ–°å…¨å±€ä¿¡å¿µ...")
        
        updated_users = []
        
        for user in users:
            # è·å–æ¨èç»™è¯¥ç”¨æˆ·çš„å¸–å­
            recommended_posts = rec_system.get_recommendations_for_user(user.user_id, posts)
            
            # è®¡ç®—æ¨èå¸–å­ä¸­çš„ä¿¡å¿µåˆ†å¸ƒ
            belief_distribution = self._calculate_belief_distribution(recommended_posts, posts)
            
            # æ›´æ–°ç”¨æˆ·ä¿¡å¿µ
            updated_user = self._update_user_belief(user, belief_distribution, traces)
            updated_users.append(updated_user)
        
        return updated_users
    
    def _calculate_belief_distribution(self, post_ids: List[int], posts: List[Post]) -> Dict[str, float]:
        """è®¡ç®—å¸–å­é›†åˆä¸­çš„ä¿¡å¿µåˆ†å¸ƒ"""
        group_counts = {"TRUMP": 0, "BIDEN": 0, "NEUTRAL": 0}
        total_posts = len(post_ids)
        
        if total_posts == 0:
            return {"TRUMP": 0.33, "BIDEN": 0.33, "NEUTRAL": 0.34}
        
        for post_id in post_ids:
            post = next((p for p in posts if p.post_id == post_id), None)
            if post:
                group_counts[post.group] += 1
        
        return {
            group: count / total_posts 
            for group, count in group_counts.items()
        }
    
    def _update_user_belief(self, user: User, belief_distribution: Dict[str, float], 
                           traces: List[Trace]) -> User:
        """æ›´æ–°å•ä¸ªç”¨æˆ·çš„ä¿¡å¿µ"""
        # è®¡ç®—ä¿¡å¿µæ›´æ–°
        current_group = user.group
        current_strength = user.belief_strength
        
        # åŸºäºæ¨èå†…å®¹æ›´æ–°ä¿¡å¿µå¼ºåº¦
        if current_group in belief_distribution:
            group_support = belief_distribution[current_group]
            
            # å¦‚æœæ¨èå†…å®¹æ”¯æŒå½“å‰ä¿¡å¿µï¼Œå¢å¼ºä¿¡å¿µ
            if group_support > 0.5:
                new_strength = min(current_strength + self.belief_update_rate, 1.0)
            else:
                # å¦åˆ™å‡å¼±ä¿¡å¿µ
                new_strength = max(current_strength - self.belief_update_rate, 0.0)
        else:
            new_strength = current_strength
        
        # ä¿¡å¿µè½¬æ¢é€»è¾‘
        new_group = current_group
        if new_strength < 0.3:  # ä¿¡å¿µå¤ªå¼±ï¼Œå¯èƒ½è½¬æ¢
            # é€‰æ‹©ä¿¡å¿µåˆ†å¸ƒä¸­æœ€å¼ºçš„ç»„åˆ«
            strongest_group = max(belief_distribution.items(), key=lambda x: x[1])[0]
            if belief_distribution[strongest_group] > 0.4:  # æœ‰è¶³å¤Ÿå¼ºçš„æ›¿ä»£ä¿¡å¿µ
                new_group = strongest_group
                new_strength = 0.5  # é‡ç½®ä¿¡å¿µå¼ºåº¦
        
        # åˆ›å»ºæ›´æ–°åçš„ç”¨æˆ·
        updated_user = User(
            user_id=user.user_id,
            agent_id=user.agent_id,
            bio=user.bio,
            num_followers=user.num_followers,
            group=new_group,
            belief_strength=new_strength,
            influence_score=user.influence_score,
            recent_posts=user.recent_posts.copy(),
            liked_posts=user.liked_posts.copy(),
            disliked_posts=user.disliked_posts.copy()
        )
        
        return updated_user


class TwitterSimulationGlobal:
    """å…¨å±€Twitteræ¨¡æ‹Ÿå™¨"""
    
    def __init__(self, num_users: int = 100, num_steps: int = 50, 
                 vllm_url: str = "http://localhost:8001/v1", 
                 model_name: str = "qwen-2"):
        self.num_users = num_users
        self.num_steps = num_steps
        self.users = []
        self.posts = []
        self.traces = []
        self.current_post_id = 0
        self.current_time = 0
        
        print(f"\nğŸš€ åˆå§‹åŒ–TwitterSimulationGlobal:")
        print(f"   - ç”¨æˆ·æ•°é‡: {num_users}")
        print(f"   - æ—¶é—´æ­¥æ•°: {num_steps}")
        print(f"   - VLLM URL: {vllm_url}")
        print(f"   - æ¨¡å‹åç§°: {model_name}")
        
        # åˆå§‹åŒ–VLLMå®¢æˆ·ç«¯
        self.vllm_client = VLLMClient(vllm_url, model_name)
        
        # åˆå§‹åŒ–SandGraphç»„ä»¶
        self._initialize_sandgraph_components()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.rec_system = GlobalRecommendationSystem(max_rec_posts=10)
        self.influence_calculator = GlobalInfluenceCalculator()
        self.belief_updater = GlobalBeliefUpdater(belief_update_rate=0.1)
        
        # ç»Ÿè®¡æ•°æ®
        self.statistics = {
            'trump_users': [],
            'biden_users': [],
            'neutral_users': [],
            'total_posts': [],
            'total_likes': [],
            'total_reposts': []
        }
        
        # å°è¯•åˆå§‹åŒ–camelå’Œoasis
        self.agent_graph = None
        self.env = None
        # æ³¨æ„ï¼š_initialize_camel_oasisæ˜¯asyncæ–¹æ³•ï¼Œéœ€è¦åœ¨å¤–éƒ¨è°ƒç”¨
    
    def _initialize_sandgraph_components(self):
        """åˆå§‹åŒ–SandGraphæ ¸å¿ƒç»„ä»¶"""
        print(f"\nğŸ”§ åˆå§‹åŒ–SandGraphç»„ä»¶:")
        
        if HAS_SANDGRAPH:
            try:
                # 1. åˆå§‹åŒ–å¥–åŠ±æ§½ç®¡ç†å™¨
                self.slot_manager = RewardBasedSlotManager(max_slots=20)
                print("   âœ… RewardBasedSlotManager åˆå§‹åŒ–æˆåŠŸ")
                
                # 2. åˆå§‹åŒ–åŸºäºæ€»ç»Ÿä¿¡ä»°çš„OASISæ²™ç›’
                self._initialize_presidential_sandboxes()
                print("   âœ… æ€»ç»Ÿä¿¡ä»°æ²™ç›’ åˆå§‹åŒ–æˆåŠŸ")
                
                # 3. åˆå§‹åŒ–ä»£ç†å›¾
                self.sandgraph_agent_graph = AgentGraph()
                print("   âœ… AgentGraph åˆå§‹åŒ–æˆåŠŸ")
                
                # 4. åˆå§‹åŒ–LLMç­–ç•¥
                self.llm_policy = LLMPolicy(
                    mode='frozen',
                    model_name="qwen-2",
                    url="http://localhost:8001/v1"
                )
                print("   âœ… LLMPolicy åˆå§‹åŒ–æˆåŠŸ")
                
                # 5. åˆå§‹åŒ–å¼‚æ­¥ä»£ç†å·¥ä½œæµ
                self.async_workflow = AsyncAgentWorkflow(
                    self.sandgraph_agent_graph,
                    self.llm_policy,
                    self.slot_manager
                )
                print("   âœ… AsyncAgentWorkflow åˆå§‹åŒ–æˆåŠŸ")
                
                # 6. åˆå§‹åŒ–OASISæ­£ç¡®æ¨¡æ‹Ÿ
                config = {"num_agents": self.num_users, "max_steps": self.num_steps}
                self.oasis_simulation = OASISCorrectSimulation(
                    config, "http://localhost:8001/v1", "qwen-2"
                )
                print("   âœ… OASISCorrectSimulation åˆå§‹åŒ–æˆåŠŸ")
                
                # 7. åˆå§‹åŒ–Frozen Adaptive LLM
                self._initialize_frozen_adaptive_llm()
                print("   âœ… FrozenAdaptiveLLM åˆå§‹åŒ–æˆåŠŸ")
                
                # 8. åˆå§‹åŒ–AReaLé›†æˆ
                self._initialize_areal_integration()
                print("   âœ… AReaLé›†æˆ åˆå§‹åŒ–æˆåŠŸ")
                
                # 9. åˆå§‹åŒ–è‡ªè¿›åŒ–OASIS
                self._initialize_self_evolving_oasis()
                print("   âœ… è‡ªè¿›åŒ–OASIS åˆå§‹åŒ–æˆåŠŸ")
                
                print("   ğŸ‰ æ‰€æœ‰SandGraphç»„ä»¶åˆå§‹åŒ–å®Œæˆ!")
                
            except Exception as e:
                print(f"   âŒ SandGraphç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                self._reset_sandgraph_components()
        else:
            print("   âš ï¸ SandGraphæ¨¡å—ä¸å¯ç”¨ï¼Œè·³è¿‡ç»„ä»¶åˆå§‹åŒ–")
            self._reset_sandgraph_components()
    
    def _reset_sandgraph_components(self):
        """é‡ç½®SandGraphç»„ä»¶"""
        self.slot_manager = None
        self.presidential_sandboxes = {}
        self.sandgraph_agent_graph = None
        self.llm_policy = None
        self.async_workflow = None
        self.oasis_simulation = None
        self.frozen_adaptive_llm = None
        self.areal_integration = None
        self.self_evolving_oasis = None
    
    def _initialize_presidential_sandboxes(self):
        """åˆå§‹åŒ–åŸºäºæ€»ç»Ÿä¿¡ä»°çš„æ²™ç›’"""
        print("     ğŸ›ï¸ åˆå§‹åŒ–æ€»ç»Ÿä¿¡ä»°æ²™ç›’...")
        
        # åˆ›å»ºä¸åŒæ€»ç»Ÿä¿¡ä»°çš„æ²™ç›’
        self.presidential_sandboxes = {
            "TRUMP": OASISSandbox(BeliefType.POSITIVE, []),
            "BIDEN": OASISSandbox(BeliefType.NEGATIVE, []),
            "NEUTRAL": OASISSandbox(BeliefType.NEUTRAL, [])
        }
        
        # ä¸ºæ¯ä¸ªæ²™ç›’æ·»åŠ æè¿°
        sandbox_descriptions = {
            "TRUMP": "æ”¯æŒç‰¹æœ—æ™®çš„é€‰æ°‘æ²™ç›’ - å…³æ³¨MAGAè¿åŠ¨ã€ç»æµæ”¿ç­–ã€è¾¹å¢ƒå®‰å…¨ç­‰è®®é¢˜",
            "BIDEN": "æ”¯æŒæ‹œç™»çš„é€‰æ°‘æ²™ç›’ - å…³æ³¨æ°”å€™å˜åŒ–ã€åŒ»ç–—æ”¹é©ã€ç¤¾ä¼šå…¬å¹³ç­‰è®®é¢˜", 
            "NEUTRAL": "ä¸­ç«‹é€‰æ°‘æ²™ç›’ - å…³æ³¨ä¸¤å…šæ”¿ç­–å¯¹æ¯”ã€ç†æ€§è®¨è®ºã€å¯»æ±‚å…±è¯†"
        }
        
        for president, sandbox in self.presidential_sandboxes.items():
            print(f"       - {president}æ²™ç›’: {sandbox_descriptions[president]}")
    
    def _initialize_frozen_adaptive_llm(self):
        """åˆå§‹åŒ–Frozen Adaptive LLM"""
        print("     ğŸ§Š åˆå§‹åŒ–Frozen Adaptive LLM...")
        
        try:
            # åˆ›å»ºå†»ç»“é…ç½®
            frozen_config = create_frozen_config(
                strategy=UpdateStrategy.ADAPTIVE,
                frozen_layers=["embedding", "layers.0", "layers.1"],
                adaptive_learning_rate=True,
                min_learning_rate=1e-6,
                max_learning_rate=1e-3
            )
            
            # åˆ›å»ºæ¨¡æ‹Ÿçš„base_llmï¼ˆå®é™…ä½¿ç”¨æ—¶éœ€è¦çœŸå®çš„LLMï¼‰
            class MockBaseLLM:
                def __init__(self):
                    self.parameters = {"layer1": [1.0, 2.0], "layer2": [3.0, 4.0]}
                
                def get_parameters(self):
                    return self.parameters
            
            base_llm = MockBaseLLM()
            self.frozen_adaptive_llm = create_frozen_adaptive_llm(base_llm, UpdateStrategy.ADAPTIVE)
            
            print(f"       - ç­–ç•¥: {frozen_config.strategy.value}")
            print(f"       - å†»ç»“å±‚: {frozen_config.frozen_layers}")
            print(f"       - è‡ªé€‚åº”å­¦ä¹ ç‡: {frozen_config.adaptive_learning_rate}")
            
        except Exception as e:
            print(f"       âš ï¸ FrozenAdaptiveLLMåˆå§‹åŒ–å¤±è´¥: {e}")
            self.frozen_adaptive_llm = None
    
    def _initialize_areal_integration(self):
        """åˆå§‹åŒ–AReaLé›†æˆ"""
        print("     ğŸš€ åˆå§‹åŒ–AReaLé›†æˆ...")
        
        try:
            # åˆ›å»ºAReaLé›†æˆç®¡ç†å™¨
            self.areal_integration = create_areal_integration(
                integration_level=IntegrationLevel.ADVANCED,
                cache_size=10000,
                max_memory_gb=8.0,
                enable_distributed=False,
                enable_optimization=True
            )
            
            print(f"       - é›†æˆçº§åˆ«: {IntegrationLevel.ADVANCED.value}")
            print(f"       - ç¼“å­˜å¤§å°: 10000")
            print(f"       - æœ€å¤§å†…å­˜: 8.0GB")
            print(f"       - ä¼˜åŒ–å¯ç”¨: True")
            
        except Exception as e:
            print(f"       âš ï¸ AReaLé›†æˆåˆå§‹åŒ–å¤±è´¥: {e}")
            self.areal_integration = None
    
    def _initialize_self_evolving_oasis(self):
        """åˆå§‹åŒ–è‡ªè¿›åŒ–OASIS"""
        print("     ğŸ§¬ åˆå§‹åŒ–è‡ªè¿›åŒ–OASIS...")
        
        try:
            # åˆ›å»ºè‡ªè¿›åŒ–OASISæ²™ç›’
            self.self_evolving_oasis = create_self_evolving_oasis(
                evolution_strategy=EvolutionStrategy.MULTI_MODEL,
                enable_lora=True,
                enable_kv_cache_compression=True,
                lora_rank=8,
                lora_alpha=16.0,
                evolution_interval=10
            )
            
            print(f"       - è¿›åŒ–ç­–ç•¥: {EvolutionStrategy.MULTI_MODEL.value}")
            print(f"       - LoRAå¯ç”¨: True")
            print(f"       - KVç¼“å­˜å‹ç¼©: True")
            print(f"       - è¿›åŒ–é—´éš”: 10æ­¥")
            
        except Exception as e:
            print(f"       âš ï¸ è‡ªè¿›åŒ–OASISåˆå§‹åŒ–å¤±è´¥: {e}")
            self.self_evolving_oasis = None
    
    async def _initialize_camel_oasis(self):
        """åˆå§‹åŒ–camelå’Œoasisç»„ä»¶"""
        try:
            # åˆ›å»ºVLLMæ¨¡å‹
            vllm_model_1 = ModelFactory.create(
                model_platform=ModelPlatformType.VLLM,
                model_type="qwen-2",
                url="http://localhost:8001/v1",
            )
            vllm_model_2 = ModelFactory.create(
                model_platform=ModelPlatformType.VLLM,
                model_type="qwen-2",
                url="http://localhost:8001/v1",
            )
            models = [vllm_model_1, vllm_model_2]
            
            # å®šä¹‰å¯ç”¨åŠ¨ä½œ
            available_actions = [
                ActionType.CREATE_POST,
                ActionType.LIKE_POST,
                ActionType.REPOST,
                ActionType.FOLLOW,
                ActionType.DO_NOTHING,
                ActionType.QUOTE_POST,
            ]
            
            # ç”Ÿæˆä»£ç†å›¾
            self.agent_graph = await generate_reddit_agent_graph(
                profile_path="user_data_36.json",
                model=models,
                available_actions=available_actions,
            )
            
            # åˆ†é…ç»„åˆ«
            trump_ratio = 0.5
            agent_ids = [id for id, _ in self.agent_graph.get_agents()]
            trump_agents = set(random.sample(agent_ids, int(len(agent_ids) * trump_ratio)))
            for id, agent in self.agent_graph.get_agents():
                agent.group = "TRUMP" if id in trump_agents else "BIDEN"
            
            # åˆ›å»ºç¯å¢ƒ
            db_path = "twitter_simulation_global.db"
            if os.path.exists(db_path):
                os.remove(db_path)
            
            # å°è¯•ä½¿ç”¨oasis.makeï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨å…¶ä»–æ–¹æ³•
            try:
                if hasattr(oasis, 'make'):
                    self.env = oasis.make(
                        agent_graph=self.agent_graph,
                        database_path=db_path,
                    )
                else:
                    # å›é€€åˆ°å…¶ä»–æ–¹æ³•
                    self.env = oasis.Environment(
                        agent_graph=self.agent_graph,
                        database_path=db_path,
                    )
            except Exception as e:
                print(f"Oasisç¯å¢ƒåˆ›å»ºå¤±è´¥: {e}")
                self.env = None
            
            print("Camelå’ŒOasisåˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            print(f"Camelå’ŒOasisåˆå§‹åŒ–å¤±è´¥: {e}")
            self.agent_graph = None
            self.env = None
    
    def initialize_users(self):
        """åˆå§‹åŒ–ç”¨æˆ·"""
        logger.info(f"åˆå§‹åŒ– {self.num_users} ä¸ªç”¨æˆ·...")
        
        # åˆ†é…ç”¨æˆ·ç»„åˆ«
        trump_ratio = 0.4
        biden_ratio = 0.4
        neutral_ratio = 0.2
        
        trump_count = int(self.num_users * trump_ratio)
        biden_count = int(self.num_users * biden_ratio)
        neutral_count = self.num_users - trump_count - biden_count
        
        for i in range(self.num_users):
            if i < trump_count:
                group = "TRUMP"
                belief_strength = random.uniform(0.6, 1.0)
            elif i < trump_count + biden_count:
                group = "BIDEN"
                belief_strength = random.uniform(0.6, 1.0)
            else:
                group = "NEUTRAL"
                belief_strength = random.uniform(0.3, 0.7)
            
            user = User(
                user_id=i,
                agent_id=i,
                bio=f"User {i} - {group} supporter",
                num_followers=random.randint(10, 1000),
                group=group,
                belief_strength=belief_strength,
                influence_score=random.uniform(0.1, 1.0)
            )
            self.users.append(user)
        
        logger.info(f"ç”¨æˆ·åˆå§‹åŒ–å®Œæˆ: TRUMP={trump_count}, BIDEN={biden_count}, NEUTRAL={neutral_count}")
    
    def generate_initial_posts(self):
        """ç”Ÿæˆåˆå§‹å¸–å­"""
        logger.info("ç”Ÿæˆåˆå§‹å¸–å­...")
        
        # ä¸ºæ¯ä¸ªç”¨æˆ·ç”Ÿæˆ1-3ä¸ªåˆå§‹å¸–å­
        for user in self.users:
            num_posts = random.randint(1, 3)
            for _ in range(num_posts):
                post = self._create_post(user)
                self.posts.append(post)
        
        logger.info(f"ç”Ÿæˆäº† {len(self.posts)} ä¸ªåˆå§‹å¸–å­")
    
    def _create_post(self, user: User, content: Optional[str] = None) -> Post:
        """åˆ›å»ºå¸–å­"""
        if content is None:
            if user.group == "TRUMP":
                content = f"TRUMP supporter post {self.current_post_id}: Make America Great Again!"
            elif user.group == "BIDEN":
                content = f"BIDEN supporter post {self.current_post_id}: Build Back Better!"
            else:
                content = f"Neutral post {self.current_post_id}: Let's discuss politics calmly."
        
        post = Post(
            post_id=self.current_post_id,
            user_id=user.user_id,
            content=content,
            created_at=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            group=user.group
        )
        
        self.current_post_id += 1
        return post
    
    async def simulate_step(self):
        """æ¨¡æ‹Ÿä¸€ä¸ªæ—¶é—´æ­¥"""
        logger.info(f"=== æ—¶é—´æ­¥ {self.current_time + 1} ===")
        
        # 1. è®¡ç®—å…¨å±€ç›¸ä¼¼åº¦çŸ©é˜µ
        self.rec_system.calculate_global_similarity_matrix(self.users, self.posts)
        
        # 2. ç”¨æˆ·è¡Œä¸ºæ¨¡æ‹Ÿ
        new_posts = []
        new_traces = []
        
        for user in self.users:
            # ç”¨æˆ·å‘å¸–æ¦‚ç‡
            if random.random() < 0.1:  # 10%æ¦‚ç‡å‘å¸–
                # ä½¿ç”¨VLLMç”Ÿæˆå¸–å­å†…å®¹
                prompt = (
                    f"You are a {user.group} supporter. "
                    f"Generate a short post (max 100 characters) about your political views. "
                    f"Make it engaging and authentic to your group's perspective."
                )
                
                try:
                    generated_content = await self.vllm_client.generate(prompt)
                    # æ¸…ç†ç”Ÿæˆçš„å†…å®¹ï¼Œç¡®ä¿ä¸è¶…è¿‡100å­—ç¬¦
                    clean_content = generated_content[:100].strip()
                    if not clean_content:
                        clean_content = f"{user.group} supporter post {self.current_post_id}"
                except Exception as e:
                    print(f"VLLM generation failed for user {user.user_id}: {e}")
                    clean_content = f"{user.group} supporter post {self.current_post_id}"
                
                post = self._create_post(user, clean_content)
                new_posts.append(post)
                
                # è®°å½•å‘å¸–è¡Œä¸º
                trace = Trace(
                    user_id=user.user_id,
                    post_id=post.post_id,
                    action="CREATE_POST",
                    timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    info=f"Created post: {post.content[:50]}..."
                )
                new_traces.append(trace)
            
            # ç”¨æˆ·äº’åŠ¨è¡Œä¸º
            if random.random() < 0.3:  # 30%æ¦‚ç‡äº’åŠ¨
                recommended_posts = self.rec_system.get_recommendations_for_user(user.user_id, self.posts)
                
                if recommended_posts:
                    # é€‰æ‹©æ¨èå¸–å­è¿›è¡Œäº’åŠ¨
                    post_id = random.choice(recommended_posts)
                    post = next((p for p in self.posts if p.post_id == post_id), None)
                    
                    if post:
                        # ä½¿ç”¨VLLMå†³å®šäº’åŠ¨ç±»å‹
                        interaction_prompt = (
                            f"You are a {user.group} supporter. "
                            f"You see a post: '{post.content[:50]}...' "
                            f"from a {post.group} supporter. "
                            f"Will you LIKE, REPOST, or DISLIKE this post? "
                            f"Respond with only one word: LIKE, REPOST, or DISLIKE."
                        )
                        
                        try:
                            interaction_decision = await self.vllm_client.generate(interaction_prompt)
                            action_upper = interaction_decision.upper().strip()
                            
                            if "LIKE" in action_upper:
                                action = "LIKE_POST"
                                post.num_likes += 1
                                user.liked_posts.append(post_id)
                            elif "REPOST" in action_upper:
                                action = "REPOST"
                                post.num_reposts += 1
                            else:
                                action = "UNLIKE_POST"
                                post.num_dislikes += 1
                                user.disliked_posts.append(post_id)
                                
                        except Exception as e:
                            print(f"VLLM interaction decision failed for user {user.user_id}: {e}")
                            # å›é€€åˆ°åŸºäºä¿¡å¿µçš„å†³ç­–
                            if user.group == post.group:
                                action = "LIKE_POST"
                                post.num_likes += 1
                                user.liked_posts.append(post_id)
                            elif random.random() < 0.2:
                                action = "REPOST"
                                post.num_reposts += 1
                            else:
                                action = "UNLIKE_POST"
                                post.num_dislikes += 1
                                user.disliked_posts.append(post_id)
                        
                        trace = Trace(
                            user_id=user.user_id,
                            post_id=post_id,
                            action=action,
                            timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        )
                        new_traces.append(trace)
        
        # æ·»åŠ æ–°å¸–å­å’Œè¡Œä¸ºè®°å½•
        self.posts.extend(new_posts)
        self.traces.extend(new_traces)
        
        # 3. è®¡ç®—å…¨å±€å½±å“åŠ›
        influence_scores = self.influence_calculator.calculate_global_influence(self.users, self.posts, self.traces)
        
        # 4. æ›´æ–°ç”¨æˆ·ä¿¡å¿µ
        self.users = self.belief_updater.update_global_beliefs(self.users, self.posts, self.traces, self.rec_system)
        
        # 5. æ›´æ–°å½±å“åŠ›åˆ†æ•°
        for user in self.users:
            if user.user_id in influence_scores:
                user.influence_score = influence_scores[user.user_id]
        
        # 6. è®°å½•ç»Ÿè®¡ä¿¡æ¯
        self._record_statistics()
        
        self.current_time += 1
    
    def _record_statistics(self):
        """è®°å½•ç»Ÿè®¡ä¿¡æ¯"""
        trump_count = sum(1 for user in self.users if user.group == "TRUMP")
        biden_count = sum(1 for user in self.users if user.group == "BIDEN")
        neutral_count = sum(1 for user in self.users if user.group == "NEUTRAL")
        
        total_likes = sum(post.num_likes for post in self.posts)
        total_reposts = sum(post.num_reposts for post in self.posts)
        
        self.statistics['trump_users'].append(trump_count)
        self.statistics['biden_users'].append(biden_count)
        self.statistics['neutral_users'].append(neutral_count)
        self.statistics['total_posts'].append(len(self.posts))
        self.statistics['total_likes'].append(total_likes)
        self.statistics['total_reposts'].append(total_reposts)
        
        logger.info(f"ç»Ÿè®¡: TRUMP={trump_count}, BIDEN={biden_count}, NEUTRAL={neutral_count}")
        logger.info(f"å¸–å­æ€»æ•°: {len(self.posts)}, æ€»ç‚¹èµ: {total_likes}, æ€»è½¬å‘: {total_reposts}")
    
    async def run_simulation(self):
        """è¿è¡Œå®Œæ•´æ¨¡æ‹Ÿ"""
        logger.info("å¼€å§‹å…¨å±€Twitteræ¨¡æ‹Ÿ...")
        
        # åˆå§‹åŒ–
        self.initialize_users()
        self.generate_initial_posts()
        
        # è¿è¡Œæ¨¡æ‹Ÿ
        for step in range(self.num_steps):
            await self.simulate_step()
            
            # æ¯10æ­¥è¾“å‡ºè¯¦ç»†ç»Ÿè®¡
            if (step + 1) % 10 == 0:
                self._print_detailed_statistics()
        
        logger.info("æ¨¡æ‹Ÿå®Œæˆ!")
        self._print_final_statistics()
    
    async def demonstrate_sandgraph_components(self):
        """æ¼”ç¤ºSandGraphç»„ä»¶çš„åŠŸèƒ½"""
        if not HAS_SANDGRAPH:
            print("âŒ SandGraphæ¨¡å—ä¸å¯ç”¨ï¼Œæ— æ³•æ¼”ç¤ºç»„ä»¶åŠŸèƒ½")
            return
        
        print(f"\nğŸ­ æ¼”ç¤ºSandGraphç»„ä»¶åŠŸèƒ½:")
        
        try:
            # 1. æ¼”ç¤ºå¥–åŠ±æ§½ç®¡ç†å™¨
            print(f"\nğŸ“Š 1. å¥–åŠ±æ§½ç®¡ç†å™¨æ¼”ç¤º:")
            if self.slot_manager:
                # åˆ†é…ä¸€äº›æ§½ä½
                self.slot_manager.allocate_slot("user_1", 0.8)
                self.slot_manager.allocate_slot("user_2", 0.6)
                self.slot_manager.allocate_slot("user_3", 0.9)
                
                # æ›´æ–°å¥–åŠ±
                self.slot_manager.update_slot_reward("user_1", 0.9)
                self.slot_manager.update_slot_reward("user_2", 0.7)
                
                # è·å–é¡¶çº§æ§½ä½
                top_slots = self.slot_manager.get_top_slots(3)
                print(f"   - é¡¶çº§æ§½ä½: {top_slots}")
                
                # æ˜¾ç¤ºæ§½ä½çŠ¶æ€
                try:
                    slots = getattr(self.slot_manager, 'slots', {})
                    print(f"   - æ§½ä½æ•°é‡: {len(slots)}")
                    print(f"   - æ€»å¥–åŠ±: {sum(slots.values()):.2f}")
                except Exception as e:
                    print(f"   - æ§½ä½çŠ¶æ€è·å–å¤±è´¥: {e}")
            
            # 2. æ¼”ç¤ºåŸºäºæ€»ç»Ÿä¿¡ä»°çš„æ²™ç›’
            print(f"\nğŸ›ï¸ 2. æ€»ç»Ÿä¿¡ä»°æ²™ç›’æ¼”ç¤º:")
            if hasattr(self, 'presidential_sandboxes') and self.presidential_sandboxes:
                for president, sandbox in self.presidential_sandboxes.items():
                    # åˆ›å»ºå¯¹åº”ä¿¡ä»°çš„ä»£ç†
                    if president == "TRUMP":
                        agent = AgentState(
                            agent_id=len(self.presidential_sandboxes),
                            belief_type=BeliefType.POSITIVE,
                            influence_score=0.8,
                            neighbors=[1, 2],
                            group="TRUMP"
                        )
                    elif president == "BIDEN":
                        agent = AgentState(
                            agent_id=len(self.presidential_sandboxes) + 1,
                            belief_type=BeliefType.NEGATIVE,
                            influence_score=0.7,
                            neighbors=[1, 2],
                            group="BIDEN"
                        )
                    else:
                        agent = AgentState(
                            agent_id=len(self.presidential_sandboxes) + 2,
                            belief_type=BeliefType.NEUTRAL,
                            influence_score=0.5,
                            neighbors=[1, 2],
                            group="NEUTRAL"
                        )
                    
                    # æ·»åŠ åˆ°å¯¹åº”æ²™ç›’
                    sandbox.add_agent(agent)
                    print(f"   - {president}æ²™ç›’: ä»£ç†æ•°é‡={len(sandbox.get_agents())}, æ€»å½±å“åŠ›={sandbox.total_influence:.2f}")
            
            # 3. æ¼”ç¤ºä»£ç†å›¾
            print(f"\nğŸ•¸ï¸ 3. ä»£ç†å›¾æ¼”ç¤º:")
            if self.sandgraph_agent_graph:
                # æ·»åŠ ä»£ç†
                if hasattr(self, 'presidential_sandboxes') and self.presidential_sandboxes:
                    for president, sandbox in self.presidential_sandboxes.items():
                        agents = sandbox.get_agents()
                        for agent in agents:
                            self.sandgraph_agent_graph.add_agent(agent)
                
                all_agents = self.sandgraph_agent_graph.get_agents()
                print(f"   - ä»£ç†å›¾å¤§å°: {len(all_agents)}")
                for agent_id, agent in all_agents.items():
                    print(f"     * ä»£ç†{agent_id}: {agent.group}, å½±å“åŠ›={agent.influence_score:.2f}")
            
            # 4. æ¼”ç¤ºå¼‚æ­¥å·¥ä½œæµ
            print(f"\nâš¡ 4. å¼‚æ­¥å·¥ä½œæµæ¼”ç¤º:")
            if self.async_workflow:
                print(f"   - å·¥ä½œæµçŠ¶æ€: å·²åˆå§‹åŒ–")
                try:
                    task_queue = getattr(self.async_workflow, 'task_queue', None)
                    if task_queue:
                        print(f"   - ä»»åŠ¡é˜Ÿåˆ—å¤§å°: {task_queue.qsize()}")
                    else:
                        print(f"   - ä»»åŠ¡é˜Ÿåˆ—: æœªåˆå§‹åŒ–")
                except Exception as e:
                    print(f"   - ä»»åŠ¡é˜Ÿåˆ—çŠ¶æ€è·å–å¤±è´¥: {e}")
                
                try:
                    inference_workers = getattr(self.async_workflow, 'inference_workers', [])
                    weight_update_workers = getattr(self.async_workflow, 'weight_update_workers', [])
                    print(f"   - æ¨ç†å·¥ä½œå™¨æ•°é‡: {len(inference_workers)}")
                    print(f"   - æƒé‡æ›´æ–°å·¥ä½œå™¨æ•°é‡: {len(weight_update_workers)}")
                except Exception as e:
                    print(f"   - å·¥ä½œå™¨çŠ¶æ€è·å–å¤±è´¥: {e}")
            
            # 5. æ¼”ç¤ºLLMç­–ç•¥
            print(f"\nğŸ¤– 5. LLMç­–ç•¥æ¼”ç¤º:")
            if self.llm_policy:
                print(f"   - ç­–ç•¥æ¨¡å¼: {self.llm_policy.mode}")
                print(f"   - æ¨¡å‹åç§°: {self.llm_policy.model_name}")
                print(f"   - åç«¯: {self.llm_policy.backend}")
                print(f"   - ç›‘æ§å¯ç”¨: {self.llm_policy.enable_monitoring}")
            
            # 6. æ¼”ç¤ºFrozen Adaptive LLM
            print(f"\nğŸ§Š 6. Frozen Adaptive LLMæ¼”ç¤º:")
            if self.frozen_adaptive_llm:
                param_info = self.frozen_adaptive_llm.get_parameter_info()
                print(f"   - å‚æ•°æ•°é‡: {len(param_info)}")
                print(f"   - å†»ç»“å±‚: {[name for name, info in param_info.items() if info.frozen]}")
                print(f"   - å¯æ›´æ–°å‚æ•°: {[name for name, info in param_info.items() if not info.frozen]}")
            else:
                print("   - æœªåˆå§‹åŒ–")
            
            # 7. æ¼”ç¤ºAReaLé›†æˆ
            print(f"\nğŸš€ 7. AReaLé›†æˆæ¼”ç¤º:")
            if self.areal_integration:
                stats = self.areal_integration.get_stats()
                print(f"   - ç¼“å­˜å‘½ä¸­ç‡: {stats.get('cache_hit_rate', 'N/A')}")
                print(f"   - ä»»åŠ¡é˜Ÿåˆ—é•¿åº¦: {stats.get('task_queue_length', 'N/A')}")
                print(f"   - å†…å­˜ä½¿ç”¨: {stats.get('memory_usage_gb', 'N/A')}GB")
            else:
                print("   - æœªåˆå§‹åŒ–")
            
            # 8. æ¼”ç¤ºè‡ªè¿›åŒ–OASIS
            print(f"\nğŸ§¬ 8. è‡ªè¿›åŒ–OASISæ¼”ç¤º:")
            if self.self_evolving_oasis:
                try:
                    evolution_stats = self.self_evolving_oasis.get_evolution_stats()
                    print(f"   - è¿›åŒ–æ­¥æ•°: {evolution_stats.get('evolution_step', 'N/A')}")
                    print(f"   - æ¨¡å‹æ± å¤§å°: {evolution_stats.get('model_pool_size', 'N/A')}")
                    print(f"   - å¹³å‡æ€§èƒ½: {evolution_stats.get('average_performance', 'N/A')}")
                    print(f"   - è¿›åŒ–ç­–ç•¥: {evolution_stats.get('evolution_strategy', 'N/A')}")
                except Exception as e:
                    print(f"   - è¿›åŒ–ç»Ÿè®¡è·å–å¤±è´¥: {e}")
                    print(f"   - è‡ªè¿›åŒ–OASISçŠ¶æ€: å·²åˆå§‹åŒ–")
            else:
                print("   - æœªåˆå§‹åŒ–")
            
            print(f"\nğŸ‰ SandGraphç»„ä»¶æ¼”ç¤ºå®Œæˆ!")
            
        except Exception as e:
            print(f"âŒ ç»„ä»¶æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
    
    async def run_camel_oasis_steps(self):
        """è¿è¡Œcamel/oasisç¯å¢ƒæ­¥éª¤ï¼Œç±»ä¼¼åŸå§‹twitter_simulation.py"""
        if not self.env or not self.agent_graph:
            logger.warning("Camel/Oasisç¯å¢ƒæœªåˆå§‹åŒ–ï¼Œè·³è¿‡ç¯å¢ƒæ­¥éª¤")
            return
        
        try:
            # é‡ç½®ç¯å¢ƒ
            await self.env.reset()
            
            # æ­¥éª¤1: åˆ›å»ºç¬¬ä¸€ä¸ªå¸–å­
            actions_1 = {}
            actions_1[self.env.agent_graph.get_agent(0)] = ManualAction(
                action_type=ActionType.CREATE_POST,
                action_args={"content": "Earth is flat."})
            await self.env.step(actions_1)
            
            # æ­¥éª¤2: æ¿€æ´»5ä¸ªä»£ç†
            actions_2 = {
                agent: LLMAction()
                for _, agent in self.env.agent_graph.get_agents([1, 3, 5, 7, 9])
            }
            await self.env.step(actions_2)
            
            # æ­¥éª¤3: åˆ›å»ºç¬¬äºŒä¸ªå¸–å­
            actions_3 = {}
            actions_3[self.env.agent_graph.get_agent(1)] = ManualAction(
                action_type=ActionType.CREATE_POST,
                action_args={"content": "Earth is not flat."})
            await self.env.step(actions_3)
            
            # æ­¥éª¤4: æ¿€æ´»æ‰€æœ‰ä»£ç†
            actions_4 = {
                agent: LLMAction()
                for _, agent in self.env.agent_graph.get_agents()
            }
            await self.env.step(actions_4)
            
            logger.info("Camel/Oasisç¯å¢ƒæ­¥éª¤æ‰§è¡Œå®Œæˆ")
            
        except Exception as e:
            logger.error(f"Camel/Oasisç¯å¢ƒæ­¥éª¤æ‰§è¡Œå¤±è´¥: {e}")
    
    def _print_detailed_statistics(self):
        """æ‰“å°è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        logger.info("=" * 50)
        logger.info("è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯:")
        
        # ç”¨æˆ·ä¿¡å¿µåˆ†å¸ƒ
        trump_users = [u for u in self.users if u.group == "TRUMP"]
        biden_users = [u for u in self.users if u.group == "BIDEN"]
        neutral_users = [u for u in self.users if u.group == "NEUTRAL"]
        
        logger.info(f"TRUMPç”¨æˆ·: {len(trump_users)}")
        if trump_users:
            logger.info(f"  - å¹³å‡ä¿¡å¿µå¼ºåº¦: {np.mean([u.belief_strength for u in trump_users]):.3f}")
            logger.info(f"  - å¹³å‡å½±å“åŠ›: {np.mean([u.influence_score for u in trump_users]):.3f}")
        
        logger.info(f"BIDENç”¨æˆ·: {len(biden_users)}")
        if biden_users:
            logger.info(f"  - å¹³å‡ä¿¡å¿µå¼ºåº¦: {np.mean([u.belief_strength for u in biden_users]):.3f}")
            logger.info(f"  - å¹³å‡å½±å“åŠ›: {np.mean([u.influence_score for u in biden_users]):.3f}")
        
        logger.info(f"NEUTRALç”¨æˆ·: {len(neutral_users)}")
        if neutral_users:
            logger.info(f"  - å¹³å‡ä¿¡å¿µå¼ºåº¦: {np.mean([u.belief_strength for u in neutral_users]):.3f}")
            logger.info(f"  - å¹³å‡å½±å“åŠ›: {np.mean([u.influence_score for u in neutral_users]):.3f}")
        
        # å¸–å­ç»Ÿè®¡
        trump_posts = [p for p in self.posts if p.group == "TRUMP"]
        biden_posts = [p for p in self.posts if p.group == "BIDEN"]
        neutral_posts = [p for p in self.posts if p.group == "NEUTRAL"]
        
        logger.info(f"å¸–å­ç»Ÿè®¡:")
        logger.info(f"  - TRUMPå¸–å­: {len(trump_posts)}, æ€»ç‚¹èµ: {sum(p.num_likes for p in trump_posts)}")
        logger.info(f"  - BIDENå¸–å­: {len(biden_posts)}, æ€»ç‚¹èµ: {sum(p.num_likes for p in biden_posts)}")
        logger.info(f"  - NEUTRALå¸–å­: {len(neutral_posts)}, æ€»ç‚¹èµ: {sum(p.num_likes for p in neutral_posts)}")
        
        logger.info("=" * 50)
    
    def _print_final_statistics(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        logger.info("=" * 60)
        logger.info("æœ€ç»ˆç»Ÿè®¡ç»“æœ:")
        logger.info("=" * 60)
        
        # ç”¨æˆ·åˆ†å¸ƒå˜åŒ–
        initial_trump = self.statistics['trump_users'][0]
        final_trump = self.statistics['trump_users'][-1]
        initial_biden = self.statistics['biden_users'][0]
        final_biden = self.statistics['biden_users'][-1]
        
        logger.info(f"ç”¨æˆ·åˆ†å¸ƒå˜åŒ–:")
        logger.info(f"  TRUMP: {initial_trump} -> {final_trump} (å˜åŒ–: {final_trump - initial_trump})")
        logger.info(f"  BIDEN: {initial_biden} -> {final_biden} (å˜åŒ–: {final_biden - initial_biden})")
        
        # å½±å“åŠ›åˆ†æ
        top_influence_users = sorted(self.users, key=lambda u: u.influence_score, reverse=True)[:5]
        logger.info(f"å½±å“åŠ›æœ€é«˜çš„5ä¸ªç”¨æˆ·:")
        for i, user in enumerate(top_influence_users, 1):
            logger.info(f"  {i}. ç”¨æˆ·{user.user_id} ({user.group}): å½±å“åŠ›={user.influence_score:.3f}, ä¿¡å¿µå¼ºåº¦={user.belief_strength:.3f}")
        
        # å¸–å­åˆ†æ
        top_posts = sorted(self.posts, key=lambda p: p.num_likes + p.num_reposts, reverse=True)[:5]
        logger.info(f"æœ€å—æ¬¢è¿çš„5ä¸ªå¸–å­:")
        for i, post in enumerate(top_posts, 1):
            logger.info(f"  {i}. å¸–å­{post.post_id} ({post.group}): ç‚¹èµ={post.num_likes}, è½¬å‘={post.num_reposts}, å†…å®¹='{post.content[:50]}...'")
        
        logger.info("=" * 60)
    
    def save_results(self, filename: str = "twitter_simulation_global_results.json"):
        """ä¿å­˜æ¨¡æ‹Ÿç»“æœ"""
        results = {
            'simulation_config': {
                'num_users': self.num_users,
                'num_steps': self.num_steps
            },
            'final_users': [
                {
                    'user_id': user.user_id,
                    'group': user.group,
                    'belief_strength': user.belief_strength,
                    'influence_score': user.influence_score,
                    'num_followers': user.num_followers
                }
                for user in self.users
            ],
            'final_posts': [
                {
                    'post_id': post.post_id,
                    'user_id': post.user_id,
                    'group': post.group,
                    'num_likes': post.num_likes,
                    'num_reposts': post.num_reposts,
                    'content': post.content
                }
                for post in self.posts
            ],
            'statistics': self.statistics
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ç»“æœå·²ä¿å­˜åˆ° {filename}")


async def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ Twitter Simulation Global - SandGraphé›†æˆç‰ˆ")
    print("=" * 60)
    
    try:
        # åˆ›å»ºæ¨¡æ‹Ÿå™¨
        print("\nğŸ“‹ åˆ›å»ºTwitteræ¨¡æ‹Ÿå™¨...")
        simulation = TwitterSimulationGlobal(num_users=50, num_steps=30)
        
        # æ¼”ç¤ºSandGraphç»„ä»¶åŠŸèƒ½
        print("\nğŸ” æ¼”ç¤ºSandGraphæ ¸å¿ƒç»„ä»¶...")
        await simulation.demonstrate_sandgraph_components()
        
        # å¦‚æœcamel/oasiså¯ç”¨ï¼Œå…ˆåˆå§‹åŒ–
        if HAS_CAMEL and HAS_OASIS:
            print("\nğŸŒ åˆå§‹åŒ–Camelå’ŒOasis...")
            await simulation._initialize_camel_oasis()
            await simulation.run_camel_oasis_steps()
        else:
            print("\nâš ï¸ Camel/Oasisä¸å¯ç”¨ï¼Œè·³è¿‡ç¯å¢ƒæ­¥éª¤")
        
        # è¿è¡Œæ¨¡æ‹Ÿ
        print("\nğŸ¬ å¼€å§‹å…¨å±€Twitteræ¨¡æ‹Ÿ...")
        await simulation.run_simulation()
        
        # ä¿å­˜ç»“æœ
        print("\nğŸ’¾ ä¿å­˜æ¨¡æ‹Ÿç»“æœ...")
        simulation.save_results()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ¨¡æ‹Ÿå®Œæˆï¼æ‰€æœ‰SandGraphç»„ä»¶å·²æˆåŠŸé›†æˆå’Œæ¼”ç¤º")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ æ¨¡æ‹Ÿè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
