#!/usr/bin/env python3
"""
Twitter Simulation - 8 LoRAæ¨¡å‹ç‰ˆæœ¬

åˆ›å»º8ä¸ªLoRAæ¨¡å‹ï¼Œæ¯ä¸ªLoRAåˆ†é…åˆ°å›ºå®šçš„agentç»„ï¼š
- LoRA 1-4: TRUMPç»„ (4ä¸ªLoRA)
- LoRA 5-8: BIDENç»„ (4ä¸ªLoRA)

æ¯ä¸ªLoRAéƒ½æœ‰è‡ªå·±çš„weightæ›´æ–°æœºåˆ¶å’Œrewardè·Ÿè¸ªã€‚
"""

import asyncio
import os
import time
import logging
import random
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass, field
from datetime import datetime
import json

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class LoRAModel:
    """LoRAæ¨¡å‹é…ç½®"""
    lora_id: int
    group: str  # TRUMP or BIDEN
    rank: int = 8
    alpha: float = 16.0
    learning_rate: float = 1e-4
    weights: Dict[str, Any] = field(default_factory=dict)
    total_reward: float = 0.0
    update_count: int = 0
    
    def __post_init__(self):
        """åˆå§‹åŒ–LoRAæƒé‡"""
        self.weights = {
            'lora_A': [random.uniform(-0.1, 0.1) for _ in range(self.rank)],
            'lora_B': [random.uniform(-0.1, 0.1) for _ in range(self.rank)],
            'scaling': self.alpha / self.rank
        }
    
    def update_weights(self, reward: float):
        """æ›´æ–°LoRAæƒé‡"""
        update_factor = reward * self.learning_rate
        
        # æ›´æ–°æƒé‡
        for i in range(len(self.weights['lora_A'])):
            self.weights['lora_A'][i] += random.uniform(-update_factor, update_factor)
        
        for i in range(len(self.weights['lora_B'])):
            self.weights['lora_B'][i] += random.uniform(-update_factor, update_factor)
        
        self.total_reward += reward
        self.update_count += 1
        
        logger.info(f"LoRA {self.lora_id} ({self.group}) æ›´æ–°: reward={reward:.4f}, æ€»reward={self.total_reward:.4f}")


@dataclass
class Agent:
    """Agenté…ç½®"""
    agent_id: int
    group: str  # TRUMP or BIDEN
    lora_id: int  # åˆ†é…çš„LoRA ID
    belief_strength: float = 0.5
    total_reward: float = 0.0


@dataclass
class Post:
    """å¸–å­æ•°æ®ç»“æ„"""
    post_id: int
    agent_id: int
    content: str
    group: str
    num_likes: int = 0
    num_dislikes: int = 0


class VLLMClient:
    """VLLMå®¢æˆ·ç«¯"""
    
    def __init__(self, url: str = "http://localhost:8001/v1", model_name: str = "qwen-2"):
        self.url = url
        self.model_name = model_name
        self.camel_models = []
        self.connection_available = False
        self.call_count = 0
        
        self._initialize_camel_models()
    
    def _initialize_camel_models(self):
        """åˆå§‹åŒ–8ä¸ªCamel VLLMæ¨¡å‹"""
        try:
            from camel.models import ModelFactory
            from camel.types import ModelPlatformType
            
            # åˆ›å»º8ä¸ªVLLMæ¨¡å‹å®ä¾‹
            for i in range(8):
                vllm_model = ModelFactory.create(
                    model_platform=ModelPlatformType.VLLM,
                    model_type=self.model_name,
                    url=self.url,
                )
                self.camel_models.append(vllm_model)
            
            self.connection_available = True
            print(f"âœ… åˆ›å»ºäº† {len(self.camel_models)} ä¸ªCamel VLLMæ¨¡å‹")
            
        except ImportError:
            print("âš ï¸ Camelæ¨¡å—ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
            self.connection_available = False
        except Exception as e:
            print(f"âš ï¸ Camel VLLMæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self.connection_available = False
    
    async def generate(self, prompt: str, lora_id: Optional[int] = None) -> str:
        """ç”Ÿæˆæ–‡æœ¬å“åº”"""
        self.call_count += 1
        
        if self.camel_models and self.connection_available:
            try:
                # æ ¹æ®lora_idé€‰æ‹©æ¨¡å‹
                if lora_id is not None and 0 <= lora_id < len(self.camel_models):
                    selected_model = self.camel_models[lora_id]
                else:
                    selected_model = random.choice(self.camel_models)
                
                response = await selected_model.arun(prompt)
                print(f"ğŸ¤– VLLM (LoRA {lora_id or 'random'}) ç”Ÿæˆ: {response[:50]}...")
                return response
            except Exception as e:
                print(f"âŒ Camel VLLMè°ƒç”¨å¤±è´¥: {e}")
        
        # æ¨¡æ‹Ÿå“åº”
        return self._generate_mock_response(prompt, lora_id)
    
    def _generate_mock_response(self, prompt: str, lora_id: Optional[int] = None) -> str:
        """ç”Ÿæˆæ¨¡æ‹Ÿå“åº”"""
        if lora_id is not None:
            if lora_id <= 4:  # TRUMPç»„LoRA
                return "I support TRUMP and will post/forward TRUMP messages this round."
            else:  # BIDENç»„LoRA
                return "I support BIDEN and will post/forward BIDEN messages this round."
        
        return "I will post/forward TRUMP messages this round."


class TwitterSimulation8LoRA:
    """8 LoRA Twitteræ¨¡æ‹Ÿå™¨"""
    
    def __init__(self, num_agents: int = 50, num_steps: int = 50, 
                 vllm_url: str = "http://localhost:8001/v1", 
                 model_name: str = "qwen-2"):
        self.num_agents = num_agents
        self.num_steps = num_steps
        self.current_step = 0
        self.current_post_id = 0
        
        print(f"\nğŸš€ åˆå§‹åŒ–8 LoRA Twitteræ¨¡æ‹Ÿå™¨:")
        print(f"   - Agentæ•°é‡: {num_agents}")
        print(f"   - æ—¶é—´æ­¥æ•°: {num_steps}")
        print(f"   - VLLM URL: {vllm_url}")
        
        # åˆå§‹åŒ–VLLMå®¢æˆ·ç«¯
        self.vllm_client = VLLMClient(vllm_url, model_name)
        
        # åˆå§‹åŒ–8ä¸ªLoRAæ¨¡å‹
        self.lora_models = self._initialize_lora_models()
        
        # åˆå§‹åŒ–agents
        self.agents = self._initialize_agents()
        
        # åˆå§‹åŒ–å¸–å­åˆ—è¡¨
        self.posts = []
        
        # ç»Ÿè®¡æ•°æ®
        self.statistics = {
            'step_rewards': [],
            'lora_rewards': [],
            'vllm_calls': [],
            'weight_updates': []
        }
        
        print("ğŸ‰ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ!")
    
    def _initialize_lora_models(self) -> List[LoRAModel]:
        """åˆå§‹åŒ–8ä¸ªLoRAæ¨¡å‹"""
        print("\nğŸ”§ åˆå§‹åŒ–8ä¸ªLoRAæ¨¡å‹:")
        
        lora_models = []
        
        # LoRA 1-4: TRUMPç»„
        for i in range(1, 5):
            lora = LoRAModel(
                lora_id=i,
                group="TRUMP",
                rank=8,
                alpha=16.0,
                learning_rate=1e-4
            )
            lora_models.append(lora)
            print(f"   - LoRA {i}: TRUMPç»„, rank={lora.rank}")
        
        # LoRA 5-8: BIDENç»„
        for i in range(5, 9):
            lora = LoRAModel(
                lora_id=i,
                group="BIDEN",
                rank=8,
                alpha=16.0,
                learning_rate=1e-4
            )
            lora_models.append(lora)
            print(f"   - LoRA {i}: BIDENç»„, rank={lora.rank}")
        
        print(f"âœ… åˆ›å»ºäº† {len(lora_models)} ä¸ªLoRAæ¨¡å‹")
        return lora_models
    
    def _initialize_agents(self) -> List[Agent]:
        """åˆå§‹åŒ–agents"""
        print(f"\nğŸ”§ åˆå§‹åŒ– {self.num_agents} ä¸ªagents:")
        
        agents = []
        
        # åˆ†é…agentsåˆ°LoRAæ¨¡å‹
        agents_per_lora = self.num_agents // 8
        remaining_agents = self.num_agents % 8
        
        agent_id = 0
        for lora_id in range(1, 9):
            current_agents = agents_per_lora
            if remaining_agents > 0:
                current_agents += 1
                remaining_agents -= 1
            
            lora = next(lora for lora in self.lora_models if lora.lora_id == lora_id)
            for _ in range(current_agents):
                agent = Agent(
                    agent_id=agent_id,
                    group=lora.group,
                    lora_id=lora_id,
                    belief_strength=random.uniform(0.6, 1.0)
                )
                agents.append(agent)
                agent_id += 1
        
        # ç»Ÿè®¡
        trump_agents = [a for a in agents if a.group == "TRUMP"]
        biden_agents = [a for a in agents if a.group == "BIDEN"]
        
        print(f"   - TRUMPç»„: {len(trump_agents)} agents")
        print(f"   - BIDENç»„: {len(biden_agents)} agents")
        
        for lora in self.lora_models:
            lora_agents = [a for a in agents if a.lora_id == lora.lora_id]
            print(f"   - LoRA {lora.lora_id} ({lora.group}): {len(lora_agents)} agents")
        
        print(f"âœ… åˆ›å»ºäº† {len(agents)} ä¸ªagents")
        return agents
    
    def calculate_lora_reward(self, lora: LoRAModel) -> float:
        """è®¡ç®—LoRAå¥–åŠ±"""
        lora_agents = [a for a in self.agents if a.lora_id == lora.lora_id]
        lora_posts = [p for p in self.posts if p.agent_id in [a.agent_id for a in lora_agents]]
        
        if not lora_posts:
            return 0.0
        
        # åŸºäºå¸–å­è¡¨ç°è®¡ç®—å¥–åŠ±
        total_likes = sum(p.num_likes for p in lora_posts)
        total_dislikes = sum(p.num_dislikes for p in lora_posts)
        
        reward = total_likes - total_dislikes * 0.5
        return max(0.0, reward)
    
    async def simulate_step(self):
        """æ¨¡æ‹Ÿä¸€ä¸ªæ—¶é—´æ­¥"""
        self.current_step += 1
        logger.info(f"=== æ—¶é—´æ­¥ {self.current_step} ===")
        
        vllm_calls_this_step = 0
        weight_updates_this_step = 0
        
        # 1. ç”Ÿæˆå¸–å­
        new_posts = []
        for agent in self.agents:
            if random.random() < 0.2:  # 20%æ¦‚ç‡å‘å¸–
                prompt = (
                    f"You are a {agent.group} supporter using LoRA {agent.lora_id}. "
                    f"Generate a short post about your political views."
                )
                
                try:
                    generated_content = await self.vllm_client.generate(prompt, agent.lora_id)
                    vllm_calls_this_step += 1
                    
                    clean_content = generated_content[:100].strip()
                    if not clean_content:
                        clean_content = f"{agent.group} supporter post {self.current_post_id}"
                except Exception as e:
                    print(f"VLLM generation failed for agent {agent.agent_id}: {e}")
                    clean_content = f"{agent.group} supporter post {self.current_post_id}"
                
                post = Post(
                    post_id=self.current_post_id,
                    agent_id=agent.agent_id,
                    content=clean_content,
                    group=agent.group
                )
                new_posts.append(post)
                self.current_post_id += 1
        
        self.posts.extend(new_posts)
        
        # 2. äº’åŠ¨è¡Œä¸º
        for agent in self.agents:
            if random.random() < 0.3:  # 30%æ¦‚ç‡äº’åŠ¨
                available_posts = [p for p in self.posts if p.agent_id != agent.agent_id]
                if available_posts:
                    post = random.choice(available_posts)
                    
                    interaction_prompt = (
                        f"You are a {agent.group} supporter using LoRA {agent.lora_id}. "
                        f"Will you LIKE or DISLIKE this post: '{post.content[:50]}...'?"
                    )
                    
                    try:
                        interaction_decision = await self.vllm_client.generate(interaction_prompt, agent.lora_id)
                        vllm_calls_this_step += 1
                        
                        if "LIKE" in interaction_decision.upper():
                            post.num_likes += 1
                        else:
                            post.num_dislikes += 1
                            
                    except Exception as e:
                        print(f"VLLM interaction failed for agent {agent.agent_id}: {e}")
                        if agent.group == post.group:
                            post.num_likes += 1
                        else:
                            post.num_dislikes += 1
        
        # 3. è®¡ç®—å¥–åŠ±å¹¶æ›´æ–°LoRAæƒé‡
        lora_rewards_this_step = []
        for lora in self.lora_models:
            lora_reward = self.calculate_lora_reward(lora)
            lora_rewards_this_step.append(lora_reward)
            
            if lora_reward > 0:
                lora.update_weights(lora_reward)
                weight_updates_this_step += 1
        
        # 4. è®°å½•ç»Ÿè®¡ä¿¡æ¯
        step_total_reward = sum(lora_rewards_this_step)
        
        self.statistics['step_rewards'].append(step_total_reward)
        self.statistics['lora_rewards'].append(lora_rewards_this_step)
        self.statistics['vllm_calls'].append(vllm_calls_this_step)
        self.statistics['weight_updates'].append(weight_updates_this_step)
        
        # 5. è¾“å‡ºæ­¥éª¤ç»Ÿè®¡
        self._print_step_statistics(step_total_reward, lora_rewards_this_step, 
                                  vllm_calls_this_step, weight_updates_this_step)
    
    def _print_step_statistics(self, total_reward: float, lora_rewards: List[float], 
                             vllm_calls: int, weight_updates: int):
        """æ‰“å°æ­¥éª¤ç»Ÿè®¡ä¿¡æ¯"""
        logger.info(f"ğŸ“Š æ­¥éª¤ {self.current_step} ç»Ÿè®¡:")
        logger.info(f"   - æ€»å¥–åŠ±: {total_reward:.4f}")
        logger.info(f"   - VLLMè°ƒç”¨: {vllm_calls}")
        logger.info(f"   - æƒé‡æ›´æ–°: {weight_updates}")
        
        # LoRAå¥–åŠ±è¯¦æƒ…
        logger.info(f"   - LoRAå¥–åŠ±è¯¦æƒ…:")
        for i, reward in enumerate(lora_rewards):
            lora = self.lora_models[i]
            logger.info(f"     * LoRA {lora.lora_id} ({lora.group}): {reward:.4f}")
        
        # ç»„åˆ«è¡¨ç°
        trump_reward = sum(lora_rewards[i] for i, lora in enumerate(self.lora_models) if lora.group == "TRUMP")
        biden_reward = sum(lora_rewards[i] for i, lora in enumerate(self.lora_models) if lora.group == "BIDEN")
        
        logger.info(f"   - ç»„åˆ«è¡¨ç°:")
        logger.info(f"     * TRUMPç»„: {trump_reward:.4f}")
        logger.info(f"     * BIDENç»„: {biden_reward:.4f}")
    
    async def run_simulation(self):
        """è¿è¡Œå®Œæ•´æ¨¡æ‹Ÿ"""
        logger.info("å¼€å§‹8 LoRA Twitteræ¨¡æ‹Ÿ...")
        
        for step in range(self.num_steps):
            await self.simulate_step()
            
            if (step + 1) % 10 == 0:
                self._print_detailed_statistics()
        
        logger.info("æ¨¡æ‹Ÿå®Œæˆ!")
        self._print_final_statistics()
    
    def _print_detailed_statistics(self):
        """æ‰“å°è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        logger.info("=" * 60)
        logger.info("è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯:")
        
        # LoRAæ€§èƒ½ç»Ÿè®¡
        logger.info("LoRAæ€§èƒ½ç»Ÿè®¡:")
        for lora in self.lora_models:
            logger.info(f"  - LoRA {lora.lora_id} ({lora.group}):")
            logger.info(f"    æ€»å¥–åŠ±: {lora.total_reward:.4f}")
            logger.info(f"    æ›´æ–°æ¬¡æ•°: {lora.update_count}")
        
        logger.info("=" * 60)
    
    def _print_final_statistics(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        logger.info("=" * 80)
        logger.info("æœ€ç»ˆç»Ÿè®¡ç»“æœ:")
        logger.info("=" * 80)
        
        # æ€»ä½“ç»Ÿè®¡
        total_vllm_calls = sum(self.statistics['vllm_calls'])
        total_weight_updates = sum(self.statistics['weight_updates'])
        total_reward = sum(self.statistics['step_rewards'])
        
        logger.info(f"æ€»ä½“ç»Ÿè®¡:")
        logger.info(f"  - æ€»VLLMè°ƒç”¨: {total_vllm_calls}")
        logger.info(f"  - æ€»æƒé‡æ›´æ–°: {total_weight_updates}")
        logger.info(f"  - æ€»å¥–åŠ±: {total_reward:.4f}")
        
        # LoRAæœ€ç»ˆæ€§èƒ½
        logger.info(f"LoRAæœ€ç»ˆæ€§èƒ½:")
        for lora in self.lora_models:
            logger.info(f"  - LoRA {lora.lora_id} ({lora.group}):")
            logger.info(f"    æ€»å¥–åŠ±: {lora.total_reward:.4f}")
            logger.info(f"    æ›´æ–°æ¬¡æ•°: {lora.update_count}")
        
        # ç»„åˆ«å¯¹æ¯”
        trump_loras = [lora for lora in self.lora_models if lora.group == "TRUMP"]
        biden_loras = [lora for lora in self.lora_models if lora.group == "BIDEN"]
        
        trump_total_reward = sum(lora.total_reward for lora in trump_loras)
        biden_total_reward = sum(lora.total_reward for lora in biden_loras)
        
        logger.info(f"ç»„åˆ«å¯¹æ¯”:")
        logger.info(f"  - TRUMPç»„æ€»å¥–åŠ±: {trump_total_reward:.4f}")
        logger.info(f"  - BIDENç»„æ€»å¥–åŠ±: {biden_total_reward:.4f}")
        logger.info(f"  - èƒœå‡ºç»„: {'TRUMP' if trump_total_reward > biden_total_reward else 'BIDEN'}")
        
        logger.info("=" * 80)
    
    def save_results(self, filename: str = "twitter_simulation_8lora_results.json"):
        """ä¿å­˜æ¨¡æ‹Ÿç»“æœ"""
        results = {
            'simulation_config': {
                'num_agents': self.num_agents,
                'num_steps': self.num_steps
            },
            'lora_models': [
                {
                    'lora_id': lora.lora_id,
                    'group': lora.group,
                    'total_reward': lora.total_reward,
                    'update_count': lora.update_count
                }
                for lora in self.lora_models
            ],
            'statistics': self.statistics
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ç»“æœå·²ä¿å­˜åˆ° {filename}")


async def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸš€ Twitter Simulation - 8 LoRAæ¨¡å‹ç‰ˆæœ¬")
    print("=" * 80)
    
    try:
        # åˆ›å»ºæ¨¡æ‹Ÿå™¨
        print("\nğŸ“‹ åˆ›å»º8 LoRA Twitteræ¨¡æ‹Ÿå™¨...")
        simulation = TwitterSimulation8LoRA(num_agents=50, num_steps=30)
        
        # è¿è¡Œæ¨¡æ‹Ÿ
        print("\nğŸ¬ å¼€å§‹8 LoRA Twitteræ¨¡æ‹Ÿ...")
        await simulation.run_simulation()
        
        # ä¿å­˜ç»“æœ
        print("\nğŸ’¾ ä¿å­˜æ¨¡æ‹Ÿç»“æœ...")
        simulation.save_results()
        
        print("\n" + "=" * 80)
        print("ğŸ‰ 8 LoRAæ¨¡æ‹Ÿå®Œæˆï¼")
        print("=" * 80)
        
    except Exception as e:
        print(f"\nâŒ æ¨¡æ‹Ÿè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
