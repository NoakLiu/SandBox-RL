#!/usr/bin/env python3
"""
Enhanced SandGraph OASISç¤¾äº¤ç½‘ç»œæ¨¡æ‹Ÿæ¼”ç¤º - é›†æˆWanDBå’ŒTensorBoardç›‘æ§

é›†æˆOASIS (Open Agent Social Interaction Simulations) åˆ°SandGraphæ¡†æ¶ï¼š
1. å¤§è§„æ¨¡æ™ºèƒ½ä½“ç¤¾äº¤ç½‘ç»œæ¨¡æ‹Ÿ
2. ä¿¡æ¯ä¼ æ’­å’Œç¾¤ä½“è¡Œä¸ºç ”ç©¶
3. ç¤¾äº¤ç½‘ç»œåŠ¨æ€åˆ†æ
4. æ™ºèƒ½ä½“è¡Œä¸ºä¼˜åŒ–
5. å®æ—¶ç›‘æ§å’Œå¯è§†åŒ–
"""

import sys
import os
import time
import json
import argparse
import random
from typing import Dict, Any, List, Union, Optional
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from sandgraph.core.llm_interface import create_shared_llm_manager
from sandgraph.core.sg_workflow import (
    SG_Workflow, WorkflowMode, EnhancedWorkflowNode,
    NodeType, NodeCondition, NodeLimits, GameState
)
from sandgraph.core.rl_algorithms import RLTrainer, RLConfig, RLAlgorithm
from sandgraph.core.monitoring import (
    SocialNetworkMonitor, 
    MonitoringConfig, 
    SocialNetworkMetrics, 
    MetricsCollector,
    create_monitor
)
from sandgraph.core.visualization import (
    SocialNetworkVisualizer,
    create_visualizer,
    quick_visualization
)

# å¯¼å…¥åŸå§‹OASIS demoçš„ç±»
from oasis_social_demo import (
    SocialActionType, UserProfile, SocialPost, OasisSocialSandbox, LLMSocialDecisionMaker
)


class EnhancedOasisSocialSandbox(OasisSocialSandbox):
    """å¢å¼ºç‰ˆOASISç¤¾äº¤ç½‘ç»œæ²™ç›’ - é›†æˆç›‘æ§åŠŸèƒ½"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.sandbox_id = f"enhanced_oasis_social_{int(time.time())}"
        
        # ç›‘æ§ç›¸å…³
        self.metrics_history = []
        self.monitor = None
        self.visualizer = None
        self.start_time = time.time()
    
    def setup_monitoring(self, config: MonitoringConfig):
        """è®¾ç½®ç›‘æ§ç³»ç»Ÿ"""
        self.monitor = create_monitor(config)
        self.visualizer = create_visualizer("./visualizations/enhanced_oasis")
        
        # æ·»åŠ å‘Šè­¦å›è°ƒ
        self.monitor.add_alert_callback(self._handle_alert)
        
        print("âœ… OASIS Social Network monitoring system initialized")
    
    def _handle_alert(self, alert: Dict[str, Any]):
        """å¤„ç†ç›‘æ§å‘Šè­¦"""
        print(f"ğŸš¨ OASIS ALERT [{alert['severity'].upper()}]: {alert['message']}")
        
        # è®°å½•å‘Šè­¦åˆ°æ–‡ä»¶
        alert_log_path = "./logs/enhanced_oasis_alerts.json"
        os.makedirs(os.path.dirname(alert_log_path), exist_ok=True)
        
        try:
            alerts = []
            if os.path.exists(alert_log_path):
                with open(alert_log_path, "r") as f:
                    alerts = json.load(f)
            
            alerts.append(alert)
            
            with open(alert_log_path, "w") as f:
                json.dump(alerts, f, indent=2)
        except Exception as e:
            print(f"Failed to log alert: {e}")
    
    def _collect_metrics(self) -> SocialNetworkMetrics:
        """æ”¶é›†OASISç¤¾äº¤ç½‘ç»œæŒ‡æ ‡"""
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_users = len(self.users)
        total_posts = len(self.posts)
        total_comments = len(self.comments)
        
        # è®¡ç®—äº’åŠ¨ç»Ÿè®¡
        total_likes = sum(post.likes for post in self.posts.values())
        total_shares = sum(post.shares for post in self.posts.values())
        total_follows = sum(len(user.following) for user in self.users.values())
        
        # è®¡ç®—æ´»è·ƒç”¨æˆ·
        active_users = sum(1 for user in self.users.values() 
                          if len(user.posts) > 0 or len(user.comments) > 0)
        
        # è®¡ç®—ç½‘ç»œå¯†åº¦
        total_possible_connections = total_users * (total_users - 1)
        actual_connections = sum(len(user.following) for user in self.users.values())
        network_density = actual_connections / total_possible_connections if total_possible_connections > 0 else 0
        
        # è®¡ç®—å¹³å‡å…³æ³¨è€…æ•°
        avg_followers = sum(len(user.followers) for user in self.users.values()) / total_users if total_users > 0 else 0
        
        # è®¡ç®—å‚ä¸åº¦
        engagement_rate = (total_likes + total_comments + total_shares) / (total_posts * 10) if total_posts > 0 else 0
        
        # è®¡ç®—çƒ­é—¨å†…å®¹
        viral_posts = sum(1 for post in self.posts.values() if post.trending_score > 0.5)
        trending_topics = len(set([post.content.split('#')[1].split()[0] 
                                  for post in self.posts.values() 
                                  if '#' in post.content]))
        
        # åˆ›å»ºæŒ‡æ ‡å¯¹è±¡
        metrics = SocialNetworkMetrics(
            total_users=total_users,
            active_users=active_users,
            new_users=int(total_users * 0.1),  # æ¨¡æ‹Ÿæ–°ç”¨æˆ·
            churned_users=int(total_users * 0.02),  # æ¨¡æ‹Ÿæµå¤±ç”¨æˆ·
            user_growth_rate=0.08,  # æ¨¡æ‹Ÿå¢é•¿ç‡
            total_posts=total_posts,
            total_likes=total_likes,
            total_comments=total_comments,
            total_shares=total_shares,
            engagement_rate=min(1.0, engagement_rate),
            avg_session_time=random.uniform(15, 45),
            bounce_rate=random.uniform(0.1, 0.3),
            retention_rate=random.uniform(0.6, 0.9),
            viral_posts=viral_posts,
            trending_topics=trending_topics,
            content_quality_score=random.uniform(0.6, 0.9),
            user_satisfaction_score=random.uniform(0.5, 0.95),
            content_diversity_score=random.uniform(0.4, 0.8),
            controversy_level=random.uniform(0.0, 0.4),
            network_density=network_density,
            avg_followers=avg_followers,
            avg_following=total_follows / total_users if total_users > 0 else 0,
            clustering_coefficient=random.uniform(0.2, 0.6),
            network_growth_rate=0.05,
            total_communities=random.randint(3, 10),
            avg_community_size=random.uniform(5, 20),
            community_engagement=random.uniform(0.3, 0.7),
            cross_community_interactions=random.randint(10, 50),
            influencer_count=int(total_users * 0.1),
            avg_influence_score=random.uniform(0.3, 0.8),
            viral_spread_rate=random.uniform(0.1, 0.5),
            information_cascade_depth=random.uniform(1.5, 4.0),
            response_time_avg=random.uniform(0.5, 2.0),
            error_rate=random.uniform(0.01, 0.05),
            system_uptime=time.time() - self.start_time
        )
        
        return metrics
    
    def case_generator(self) -> Dict[str, Any]:
        """ç”Ÿæˆå½“å‰çŠ¶æ€ - å¢å¼ºç‰ˆï¼ŒåŒ…å«ç›‘æ§"""
        # è°ƒç”¨çˆ¶ç±»æ–¹æ³•
        state = super().case_generator()
        
        # æ”¶é›†ç›‘æ§æŒ‡æ ‡
        if self.monitor:
            metrics = self._collect_metrics()
            self.metrics_history.append(metrics)
            self.monitor.update_metrics(metrics)
        
        return state
    
    def run_full_cycle(self, llm_func=None) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„æ²™ç›’å‘¨æœŸ - æ»¡è¶³Sandboxåè®®"""
        # ç”Ÿæˆå½“å‰çŠ¶æ€
        case = self.case_generator()
        
        # å¦‚æœæœ‰LLMå‡½æ•°ï¼Œä½¿ç”¨å®ƒç”Ÿæˆå“åº”
        if llm_func:
            try:
                response = llm_func(case)
                # éªŒè¯å“åº”
                score = self.verify_score(response, case)
                return {
                    "case": case,
                    "response": response,
                    "score": score,
                    "status": "success"
                }
            except Exception as e:
                return {
                    "case": case,
                    "response": f"Error: {str(e)}",
                    "score": 0.0,
                    "status": "error",
                    "error": str(e)
                }
        else:
            # æ²¡æœ‰LLMå‡½æ•°ï¼Œè¿”å›é»˜è®¤å“åº”
            return {
                "case": case,
                "response": "Enhanced OASIS social network simulation",
                "score": 0.5,
                "status": "default"
            }


class EnhancedLLMSocialDecisionMaker(LLMSocialDecisionMaker):
    """å¢å¼ºç‰ˆLLMç¤¾äº¤å†³ç­–å™¨ - é›†æˆç›‘æ§åŠŸèƒ½"""
    
    def __init__(self, llm_manager):
        super().__init__(llm_manager)
        # é‡æ–°æ³¨å†ŒèŠ‚ç‚¹åç§°
        self.llm_manager.register_node("enhanced_oasis_decision", {
            "role": "OASISç¤¾äº¤ç½‘ç»œç­–ç•¥ä¸“å®¶",
            "reasoning_type": "strategic",
            "temperature": 0.7,
            "max_length": 512
        })
    
    def make_decision(self, current_state: Union[str, Dict[str, Any]]) -> Dict[str, Any]:
        """åŸºäºå½“å‰çŠ¶æ€åšå‡ºå†³ç­– - å¢å¼ºç‰ˆ"""
        self.decision_count += 1
        
        # å¤„ç†è¾“å…¥ç±»å‹
        if isinstance(current_state, str):
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸ºå­—å…¸æˆ–ä½¿ç”¨é»˜è®¤çŠ¶æ€
            try:
                # å°è¯•è§£æJSONå­—ç¬¦ä¸²
                state_dict = json.loads(current_state)
            except (json.JSONDecodeError, TypeError):
                # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤çŠ¶æ€
                state_dict = {
                    "state": {
                        "network_state": {"total_users": 100, "total_posts": 30, "network_density": 0.1},
                        "user_behavior": {"active_users": 50, "engagement_rate": 0.3},
                        "content_metrics": {"quality_score": 0.7}
                    },
                    "trending_posts": [],
                    "active_users": []
                }
        else:
            # å¦‚æœå·²ç»æ˜¯å­—å…¸ï¼Œç›´æ¥ä½¿ç”¨
            state_dict = current_state
        
        # æ„å»ºå¢å¼ºçš„å†³ç­–æç¤º
        prompt = self._construct_enhanced_decision_prompt(state_dict)
        
        try:
            # ç”ŸæˆLLMå“åº”
            response = self.llm_manager.generate_for_node(
                "enhanced_oasis_decision",
                prompt,
                temperature=0.3,
                max_new_tokens=128
            )
            
            # è§£æå“åº”
            decision = self._parse_decision_response(response.text)
            
            if decision is None:
                decision = {
                    "action": "CREATE_POST",
                    "target": "N/A",
                    "reasoning": "Fallback decision"
                }
            
            # æ›´æ–°å†å²
            self._update_history(state_dict, decision, response.text)
            
            return {
                "decision": decision,
                "llm_response": response.text,
                "decision_count": self.decision_count
            }
            
        except Exception as e:
            print(f"âŒ Decision generation failed: {e}")
            fallback_decision = {
                "action": "CREATE_POST",
                "target": "N/A",
                "reasoning": f"Error: {str(e)}"
            }
            
            self._update_history(state_dict, fallback_decision, f"Error: {str(e)}")
            
            return {
                "decision": fallback_decision,
                "llm_response": f"Error: {str(e)}",
                "decision_count": self.decision_count
            }
    
    def _construct_enhanced_decision_prompt(self, state: Dict[str, Any]) -> str:
        """æ„å»ºå¢å¼ºçš„å†³ç­–æç¤º"""
        network_state = state.get("state", {}).get("network_state", {})
        user_behavior = state.get("state", {}).get("user_behavior", {})
        content_metrics = state.get("state", {}).get("content_metrics", {})
        
        trending_posts = state.get("trending_posts", [])
        active_users = state.get("active_users", [])
        
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªOASISç¤¾äº¤ç½‘ç»œç­–ç•¥ä¸“å®¶ã€‚åŸºäºå½“å‰çš„ç½‘ç»œçŠ¶æ€ï¼Œè¯·åšå‡ºæœ€ä¼˜çš„ç¤¾äº¤ç½‘ç»œç®¡ç†å†³ç­–ã€‚

å½“å‰ç½‘ç»œçŠ¶æ€ï¼š
- æ€»ç”¨æˆ·æ•°: {network_state.get('total_users', 0)}
- æ´»è·ƒç”¨æˆ·æ•°: {user_behavior.get('active_users', 0)}
- æ€»å¸–å­æ•°: {network_state.get('total_posts', 0)}
- å‚ä¸åº¦: {user_behavior.get('engagement_rate', 0):.3f}
- ç½‘ç»œå¯†åº¦: {network_state.get('network_density', 0):.3f}
- å†…å®¹è´¨é‡: {content_metrics.get('quality_score', 0):.3f}

çƒ­é—¨å¸–å­ (å‰3ä¸ª):
{chr(10).join([f"- {post['content'][:50]}... (åˆ†æ•°: {post['trending_score']:.2f})" for post in trending_posts[:3]])}

æ´»è·ƒç”¨æˆ· (å‰3ä¸ª):
{chr(10).join([f"- {user['user_id']} (æ´»è·ƒåº¦: {user['activity_score']}, å…³æ³¨è€…: {user['followers_count']})" for user in active_users[:3]])}

å¯ç”¨çš„åŠ¨ä½œç±»å‹ï¼š
- CREATE_POST: åˆ›å»ºæ–°å¸–å­
- LIKE_POST: ç‚¹èµå¸–å­
- FOLLOW: å…³æ³¨ç”¨æˆ·
- SHARE: åˆ†äº«å¸–å­
- DO_NOTHING: ä¸æ‰§è¡Œä»»ä½•åŠ¨ä½œ

è¯·é€‰æ‹©æœ€åˆé€‚çš„åŠ¨ä½œæ¥æå‡ç½‘ç»œæ´»è·ƒåº¦å’Œç”¨æˆ·å‚ä¸åº¦ã€‚è€ƒè™‘ä»¥ä¸‹å› ç´ ï¼š
1. å½“å‰ç½‘ç»œçŠ¶æ€å’Œè¶‹åŠ¿
2. ç”¨æˆ·è¡Œä¸ºå’Œåå¥½
3. å†…å®¹è´¨é‡å’Œå¤šæ ·æ€§
4. ç¤¾åŒºå»ºè®¾å’Œå‘å±•

è¯·ä»¥ä»¥ä¸‹æ ¼å¼å›å¤ï¼š
ACTION: [åŠ¨ä½œç±»å‹]
TARGET: [ç›®æ ‡ç”¨æˆ·æˆ–å¸–å­ID]
REASONING: [å†³ç­–ç†ç”±]
"""
        
        return prompt


def create_enhanced_rl_oasis_workflow(llm_manager, monitor_config: MonitoringConfig):
    """åˆ›å»ºå¢å¼ºç‰ˆRL OASISå·¥ä½œæµ"""
    
    # åˆ›å»ºæ²™ç›’
    sandbox = EnhancedOasisSocialSandbox(
        initial_users=100,
        max_users=1000,
        initial_posts=30,
        interaction_probability=0.3
    )
    
    # è®¾ç½®ç›‘æ§
    sandbox.setup_monitoring(monitor_config)
    
    # åˆ›å»ºå†³ç­–å™¨
    decision_maker = EnhancedLLMSocialDecisionMaker(llm_manager)
    
    # åˆ›å»ºRLè®­ç»ƒå™¨
    rl_config = RLConfig(
        algorithm=RLAlgorithm.PPO,
        learning_rate=0.001,
        batch_size=32,
        gamma=0.99
    )
    rl_trainer = RLTrainer(rl_config, llm_manager)
    
    # åˆ›å»ºå·¥ä½œæµ
    workflow = SG_Workflow("enhanced_oasis_social", WorkflowMode.TRADITIONAL, llm_manager)
    
    # æ·»åŠ èŠ‚ç‚¹
    env_node = EnhancedWorkflowNode("oasis_env", NodeType.SANDBOX, sandbox=sandbox)
    decision_node = EnhancedWorkflowNode("oasis_decision", NodeType.LLM, 
                                       llm_func=decision_maker.make_decision,
                                       metadata={"role": "OASIS Social Network Analyst"})
    optimizer_node = EnhancedWorkflowNode("oasis_optimizer", NodeType.RL, 
                                        rl_trainer=rl_trainer)
    
    workflow.add_node(env_node)
    workflow.add_node(decision_node)
    workflow.add_node(optimizer_node)
    
    # è¿æ¥èŠ‚ç‚¹
    workflow.add_edge("oasis_env", "oasis_decision")
    workflow.add_edge("oasis_decision", "oasis_optimizer")
    workflow.add_edge("oasis_optimizer", "oasis_env")
    
    return workflow, rl_trainer, decision_maker, sandbox


def run_enhanced_rl_oasis_demo(steps: int = 10, 
                              enable_wandb: bool = True,
                              enable_tensorboard: bool = True,
                              wandb_project: str = "sandgraph-enhanced-oasis"):
    """è¿è¡Œå¢å¼ºç‰ˆRL OASISæ¼”ç¤º"""
    
    print("ğŸš€ Enhanced OASIS Social Network Demo with Monitoring")
    print("=" * 60)
    
    # åˆ›å»ºLLMç®¡ç†å™¨
    llm_manager = create_shared_llm_manager("mistralai/Mistral-7B-Instruct-v0.2")
    
    # åˆ›å»ºç›‘æ§é…ç½®
    monitor_config = MonitoringConfig(
        enable_wandb=enable_wandb,
        enable_tensorboard=enable_tensorboard,
        wandb_project_name=wandb_project,
        wandb_run_name=f"enhanced_oasis_{int(time.time())}",
        tensorboard_log_dir="./logs/enhanced_oasis",
        log_file_path="./logs/enhanced_oasis_metrics.json",
        metrics_sampling_interval=2.0,
        engagement_rate_threshold=0.15,
        user_growth_threshold=0.08
    )
    
    # åˆ›å»ºå·¥ä½œæµ
    workflow, rl_trainer, decision_maker, sandbox = create_enhanced_rl_oasis_workflow(
        llm_manager, monitor_config
    )
    
    # å¯åŠ¨ç›‘æ§
    sandbox.monitor.start_monitoring()
    
    print("âœ… Enhanced OASIS workflow created and monitoring started")
    print(f"ğŸ“Š Running simulation for {steps} steps...")
    
    try:
        for step in range(steps):
            print(f"\nğŸ“ˆ Step {step + 1}/{steps}")
            print("-" * 40)
            
            # æ‰§è¡Œå·¥ä½œæµ
            start_time = time.time()
            result = workflow.execute_full_workflow()
            execution_time = time.time() - start_time
            
            # æ›´æ–°RLç­–ç•¥
            rl_trainer.update_policy()
            
            # è·å–å½“å‰çŠ¶æ€
            current_state = sandbox.case_generator()
            
            # æ‰“å°æ­¥éª¤æ‘˜è¦
            network_state = current_state.get("state", {}).get("network_state", {})
            user_behavior = current_state.get("state", {}).get("user_behavior", {})
            
            print(f"â±ï¸  Execution time: {execution_time:.2f}s")
            print(f"ğŸ‘¥ Users: {network_state.get('total_users', 0)} (Active: {user_behavior.get('active_users', 0)})")
            print(f"ğŸ“ˆ Engagement: {user_behavior.get('engagement_rate', 0):.3f}")
            print(f"ğŸŒ Network Density: {network_state.get('network_density', 0):.3f}")
            
            # å»¶è¿Ÿ
            if step < steps - 1:
                time.sleep(2.0)
                
    except KeyboardInterrupt:
        print("\nâ¹ï¸  Simulation interrupted by user")
    except Exception as e:
        print(f"\nâŒ Error during simulation: {e}")
    finally:
        # åœæ­¢ç›‘æ§
        sandbox.monitor.stop_monitoring()
        
        # å¯¼å‡ºç»“æœ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # å¯¼å‡ºæŒ‡æ ‡
        metrics_file = f"./logs/enhanced_oasis_metrics_{timestamp}.json"
        sandbox.monitor.export_metrics(metrics_file, "json")
        
        # åˆ›å»ºå¯è§†åŒ–
        if sandbox.metrics_history:
            report_files = sandbox.visualizer.export_visualization_report(
                sandbox.metrics_history, 
                f"./visualizations/enhanced_oasis_{timestamp}"
            )
            
            print(f"\nğŸ“ Results exported:")
            print(f"   - Metrics: {metrics_file}")
            for viz_type, path in report_files.items():
                print(f"   - {viz_type}: {path}")
        
        # æ‰“å°æœ€ç»ˆç»Ÿè®¡
        if sandbox.metrics_history:
            final_metrics = sandbox.metrics_history[-1]
            print(f"\nğŸ“Š Final Statistics:")
            print(f"   - Total Users: {final_metrics.total_users}")
            print(f"   - Engagement Rate: {final_metrics.engagement_rate:.3f}")
            print(f"   - Content Quality: {final_metrics.content_quality_score:.3f}")
            print(f"   - Network Density: {final_metrics.network_density:.3f}")
            print(f"   - Total Alerts: {len(sandbox.monitor.alerts)}")
        
        print("\nâœ… Enhanced OASIS demo completed!")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Enhanced OASIS Social Network Demo with Monitoring")
    
    parser.add_argument("--steps", type=int, default=10, 
                       help="Number of simulation steps")
    parser.add_argument("--enable-wandb", action="store_true", default=True,
                       help="Enable WanDB logging")
    parser.add_argument("--enable-tensorboard", action="store_true", default=True,
                       help="Enable TensorBoard logging")
    parser.add_argument("--wandb-project", type=str, default="sandgraph-enhanced-oasis",
                       help="WanDB project name")
    parser.add_argument("--tensorboard-dir", type=str, default="./logs/enhanced_oasis",
                       help="TensorBoard log directory")
    
    args = parser.parse_args()
    
    # è¿è¡Œæ¼”ç¤º
    run_enhanced_rl_oasis_demo(
        steps=args.steps,
        enable_wandb=args.enable_wandb,
        enable_tensorboard=args.enable_tensorboard,
        wandb_project=args.wandb_project
    )


if __name__ == "__main__":
    main() 