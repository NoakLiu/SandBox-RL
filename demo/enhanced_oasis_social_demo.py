#!/usr/bin/env python3
"""
Enhanced Sandbox-RL OASISç¤¾äº¤ç½‘ç»œæ¨¡æ‹Ÿæ¼”ç¤º - åŸºäºåŸå§‹OASIS demoï¼Œé›†æˆWanDBå’ŒTensorBoardç›‘æ§

é›†æˆOASIS (Open Agent Social Interaction Simulations) åˆ°Sandbox-RLæ¡†æ¶ï¼š
1. å¤§è§„æ¨¡æ™ºèƒ½ä½“ç¤¾äº¤ç½‘ç»œæ¨¡æ‹Ÿ
2. ä¿¡æ¯ä¼ æ’­å’Œç¾¤ä½“è¡Œä¸ºç ”ç©¶
3. ç¤¾äº¤ç½‘ç»œåŠ¨æ€åˆ†æ
4. æ™ºèƒ½ä½“è¡Œä¸ºä¼˜åŒ–
5. å®æ—¶ç›‘æ§å’Œå¯è§†åŒ–
"""

import sys
import os
import time
import json
import argparse
import random
import re
from typing import Dict, Any, List, Union, Optional
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from sandbox_rl.core.llm_interface import create_shared_llm_manager
from sandbox_rl.core.rl_algorithms import RLTrainer, RLConfig, RLAlgorithm
from sandbox_rl.core.monitoring import (
    SocialNetworkMonitor, 
    MonitoringConfig, 
    SocialNetworkMetrics, 
    MetricsCollector,
    create_monitor
)

# å¯¼å…¥åŸå§‹OASIS demoçš„ç±»
from oasis_social_demo import (
    SocialActionType, UserProfile, SocialPost, OasisSocialSandbox, LLMSocialDecisionMaker
)


class EnhancedOasisSocialSandbox(OasisSocialSandbox):
    """å¢å¼ºç‰ˆOASISç¤¾äº¤ç½‘ç»œæ²™ç›’ - é›†æˆç›‘æ§åŠŸèƒ½"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.sandbox_id = f"enhanced_oasis_social_{int(time.time())}"
        
        # ç›‘æ§ç›¸å…³
        self.metrics_history = []
        self.monitor = None
        self.start_time = time.time()
    
    def setup_monitoring(self, config: MonitoringConfig):
        """è®¾ç½®ç›‘æ§ç³»ç»Ÿ"""
        self.monitor = create_monitor(config)
        
        # æ·»åŠ å‘Šè­¦å›è°ƒ
        self.monitor.add_alert_callback(self._handle_alert)
        
        print("âœ… OASIS Social Network monitoring system initialized")
    
    def _handle_alert(self, alert: Dict[str, Any]):
        """å¤„ç†ç›‘æ§å‘Šè­¦"""
        print(f"ğŸš¨ OASIS ALERT [{alert['severity'].upper()}]: {alert['message']}")
        
        # è®°å½•å‘Šè­¦åˆ°æ–‡ä»¶
        alert_log_path = "./logs/enhanced_oasis_alerts.json"
        os.makedirs(os.path.dirname(alert_log_path), exist_ok=True)
        
        try:
            alerts = []
            if os.path.exists(alert_log_path):
                with open(alert_log_path, "r") as f:
                    alerts = json.load(f)
            
            alerts.append(alert)
            
            with open(alert_log_path, "w") as f:
                json.dump(alerts, f, indent=2)
        except Exception as e:
            print(f"Failed to log alert: {e}")
    
    def _collect_metrics(self) -> SocialNetworkMetrics:
        """æ”¶é›†OASISç¤¾äº¤ç½‘ç»œæŒ‡æ ‡"""
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_users = len(self.users)
        total_posts = len(self.posts)
        total_comments = len(self.comments)
        
        # è®¡ç®—äº’åŠ¨ç»Ÿè®¡
        total_likes = sum(post.likes for post in self.posts.values())
        total_shares = sum(post.shares for post in self.posts.values())
        total_follows = sum(len(user.following) for user in self.users.values())
        
        # è®¡ç®—æ´»è·ƒç”¨æˆ·
        active_users = sum(1 for user in self.users.values() 
                          if len(user.posts) > 0 or len(user.comments) > 0)
        
        # è®¡ç®—ç½‘ç»œå¯†åº¦
        total_possible_connections = total_users * (total_users - 1)
        actual_connections = sum(len(user.following) for user in self.users.values())
        network_density = actual_connections / total_possible_connections if total_possible_connections > 0 else 0
        
        # è®¡ç®—å¹³å‡å…³æ³¨è€…æ•°
        avg_followers = sum(len(user.followers) for user in self.users.values()) / total_users if total_users > 0 else 0
        
        # è®¡ç®—å‚ä¸åº¦
        engagement_rate = (total_likes + total_comments + total_shares) / (total_posts * 10) if total_posts > 0 else 0
        
        # è®¡ç®—çƒ­é—¨å†…å®¹
        viral_posts = sum(1 for post in self.posts.values() if post.trending_score > 0.5)
        trending_topics = len(set([post.content.split('#')[1].split()[0] 
                                  for post in self.posts.values() 
                                  if '#' in post.content]))
        
        # åˆ›å»ºæŒ‡æ ‡å¯¹è±¡
        metrics = SocialNetworkMetrics(
            total_users=total_users,
            active_users=active_users,
            new_users=int(total_users * 0.1),  # æ¨¡æ‹Ÿæ–°ç”¨æˆ·
            churned_users=int(total_users * 0.02),  # æ¨¡æ‹Ÿæµå¤±ç”¨æˆ·
            user_growth_rate=0.08,  # æ¨¡æ‹Ÿå¢é•¿ç‡
            total_posts=total_posts,
            total_likes=total_likes,
            total_comments=total_comments,
            total_shares=total_shares,
            engagement_rate=min(1.0, engagement_rate),
            avg_session_time=random.uniform(15, 45),
            bounce_rate=random.uniform(0.1, 0.3),
            retention_rate=random.uniform(0.6, 0.9),
            viral_posts=viral_posts,
            trending_topics=trending_topics,
            content_quality_score=random.uniform(0.6, 0.9),
            user_satisfaction_score=random.uniform(0.5, 0.95),
            content_diversity_score=random.uniform(0.4, 0.8),
            controversy_level=random.uniform(0.0, 0.4),
            network_density=network_density,
            avg_followers=avg_followers,
            avg_following=total_follows / total_users if total_users > 0 else 0,
            clustering_coefficient=random.uniform(0.2, 0.6),
            network_growth_rate=0.05,
            total_communities=random.randint(3, 10),
            avg_community_size=random.uniform(5, 20),
            community_engagement=random.uniform(0.3, 0.7),
            cross_community_interactions=random.randint(10, 50),
            influencer_count=int(total_users * 0.1),
            avg_influence_score=random.uniform(0.3, 0.8),
            viral_spread_rate=random.uniform(0.1, 0.5),
            information_cascade_depth=random.uniform(1.5, 4.0),
            response_time_avg=random.uniform(0.5, 2.0),
            error_rate=random.uniform(0.01, 0.05),
            system_uptime=time.time() - self.start_time
        )
        
        return metrics


class EnhancedLLMSocialDecisionMaker(LLMSocialDecisionMaker):
    """å¢å¼ºç‰ˆLLMç¤¾äº¤å†³ç­–å™¨ - é›†æˆç›‘æ§åŠŸèƒ½"""
    
    def __init__(self, llm_manager):
        super().__init__(llm_manager)
        # é‡æ–°æ³¨å†ŒèŠ‚ç‚¹åç§°
        self.llm_manager.register_node("enhanced_oasis_decision", {
            "role": "OASISç¤¾äº¤ç½‘ç»œç­–ç•¥ä¸“å®¶",
            "reasoning_type": "strategic",
            "temperature": 0.7,
            "max_length": 512
        })
    
    def make_decision(self, current_state: Dict[str, Any]) -> Dict[str, Any]:
        """åŸºäºå½“å‰çŠ¶æ€åšå‡ºå†³ç­– - å¢å¼ºç‰ˆ"""
        self.decision_count += 1
        
        # æ„å»ºå¢å¼ºçš„å†³ç­–æç¤º
        prompt = self._construct_enhanced_decision_prompt(current_state)
        
        print("=" * 80)
        print(f"Enhanced OASIS Decision {self.decision_count} - Complete Prompt:")
        print("=" * 80)
        print(prompt)
        print("=" * 80)
        
        try:
            # ç”ŸæˆLLMå“åº”
            response = self.llm_manager.generate_for_node(
                "enhanced_oasis_decision",
                prompt,
                temperature=0.7,
                max_new_tokens=256
            )
            
            print(f"LLM Response Status: {response.status if hasattr(response, 'status') else 'unknown'}")
            print(f"LLM Complete Response: {response.text}")
            
            # è§£æå“åº”
            decision = self._parse_decision_response(response.text)
            
            if decision is None:
                decision = {
                    "action": "CREATE_POST",
                    "user_id": "user_0",
                    "target_id": None,
                    "content": "Hello OASIS world!",
                    "reasoning": "Fallback decision"
                }
            
            # æ›´æ–°å†å²
            self._update_history(current_state, decision, response.text)
            
            return {
                "decision": decision,
                "llm_response": response.text,
                "decision_count": self.decision_count
            }
            
        except Exception as e:
            print(f"âŒ Decision generation failed: {e}")
            fallback_decision = {
                "action": "CREATE_POST",
                "user_id": "user_0",
                "target_id": None,
                "content": "Hello OASIS world!",
                "reasoning": f"Error: {str(e)}"
            }
            
            self._update_history(current_state, fallback_decision, f"Error: {str(e)}")
            
            return {
                "decision": fallback_decision,
                "llm_response": f"Error: {str(e)}",
                "decision_count": self.decision_count
            }
    
    def _construct_enhanced_decision_prompt(self, state: Dict[str, Any]) -> str:
        """æ„å»ºå¢å¼ºçš„å†³ç­–æç¤º"""
        network_state = state.get("state", {}).get("network_state", {})
        trending_content = state.get("state", {}).get("trending_content", [])
        active_users = state.get("state", {}).get("active_users", [])
        
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªOASISç¤¾äº¤ç½‘ç»œç­–ç•¥ä¸“å®¶ã€‚åŸºäºå½“å‰çš„ç½‘ç»œçŠ¶æ€ï¼Œè¯·åšå‡ºæœ€ä¼˜çš„ç¤¾äº¤ç½‘ç»œç®¡ç†å†³ç­–ã€‚

å½“å‰ç½‘ç»œçŠ¶æ€ï¼š
- æ€»ç”¨æˆ·æ•°: {network_state.get('total_users', 0)}
- æ€»å¸–å­æ•°: {network_state.get('total_posts', 0)}
- æ€»ç‚¹èµæ•°: {network_state.get('total_likes', 0)}
- æ€»åˆ†äº«æ•°: {network_state.get('total_shares', 0)}
- ç½‘ç»œå¯†åº¦: {network_state.get('network_density', 0):.3f}

çƒ­é—¨å¸–å­ (å‰3ä¸ª):
{chr(10).join([f"- {post['content'][:50]}... (åˆ†æ•°: {post['trending_score']:.2f})" for post in trending_content[:3]])}

æ´»è·ƒç”¨æˆ· (å‰3ä¸ª):
{chr(10).join([f"- {user['user_id']} (æ´»è·ƒåº¦: {user['activity_score']}, å…³æ³¨è€…: {user['followers_count']})" for user in active_users[:3]])}

å¯ç”¨çš„åŠ¨ä½œç±»å‹ï¼š
- CREATE_POST: åˆ›å»ºæ–°å¸–å­
- CREATE_COMMENT: è¯„è®ºå¸–å­
- LIKE_POST: ç‚¹èµå¸–å­
- FOLLOW: å…³æ³¨ç”¨æˆ·
- SHARE: åˆ†äº«å¸–å­
- TREND: æå‡å¸–å­çƒ­åº¦

å¯ç”¨ç”¨æˆ·: user_0, user_1, user_2, user_3, user_4, user_5, user_6, user_7, user_8, user_9
å¯ç”¨å¸–å­: post_0, post_1, post_2, post_3, post_4, post_5, post_6, post_7, post_8, post_9

è¯·ä»¥ä»¥ä¸‹æ ¼å¼å›å¤ï¼š
ACTION: [åŠ¨ä½œç±»å‹] [ç”¨æˆ·ID] [ç›®æ ‡ID] [å†…å®¹]
REASONING: [å†³ç­–ç†ç”±]

ä¾‹å¦‚ï¼š
ACTION: CREATE_POST user_3 "Exploring the latest AI developments! #AI #technology"
REASONING: Creating content about trending technology topics can increase engagement.
"""
        
        return prompt
    
    def _parse_decision_response(self, response: str) -> Optional[Dict[str, Any]]:
        """è§£æLLMå†³ç­–å“åº” - å¢å¼ºç‰ˆ"""
        response = response.strip()
        
        print(f"ğŸ” è§£æå“åº”: {response[:200]}...")
        
        try:
            # æŸ¥æ‰¾ACTIONè¡Œ - æ”¯æŒå¤šç§æ ¼å¼
            action_patterns = [
                # æ ‡å‡†æ ¼å¼: ACTION: CREATE_POST user_0 target_id content
                r'ACTION:\s*([A-Z_]+)\s+([a-z_0-9]+)\s+([a-z_0-9_]+)\s+(.+)',
                # æ— ç›®æ ‡æ ¼å¼: ACTION: CREATE_POST user_0 content
                r'ACTION:\s*([A-Z_]+)\s+([a-z_0-9]+)\s+(.+)',
                # è¿å­—ç¬¦æ ¼å¼: ACTION: CREATE_POST - user_5 - content
                r'ACTION:\s*([A-Z_]+)\s*[-â€“]\s*([a-z_0-9_]+)\s*[-â€“]\s*(.+)',
                # è¿å­—ç¬¦æ ¼å¼æ— ç›®æ ‡: ACTION: CREATE_POST - user_5 content
                r'ACTION:\s*([A-Z_]+)\s*[-â€“]\s*([a-z_0-9_]+)\s+(.+)',
                # æ–¹æ‹¬å·æ ¼å¼: ACTION: CREATE_COMMENT [USER_1] [TARGET_POST] content
                r'ACTION:\s*([A-Z_]+)\s+\[([^\]]+)\]\s+\[([^\]]+)\]\s+(.+)',
                # æ–¹æ‹¬å·æ ¼å¼æ— ç›®æ ‡: ACTION: CREATE_POST [USER_1] content
                r'ACTION:\s*([A-Z_]+)\s+\[([^\]]+)\]\s+(.+)',
                # å°å†™æ ¼å¼: action: create_post user_0 target_id content
                r'action:\s*([A-Z_]+)\s+([a-z_0-9]+)\s+([a-z_0-9_]+)\s+(.+)',
                # é¦–å­—æ¯å¤§å†™æ ¼å¼: Action: Create_Post user_0 target_id content
                r'Action:\s*([A-Z_]+)\s+([a-z_0-9]+)\s+([a-z_0-9_]+)\s+(.+)',
            ]
            
            action = None
            user_id = None
            target_id = None
            content = None
            
            for pattern in action_patterns:
                action_match = re.search(pattern, response, re.IGNORECASE)
                if action_match:
                    action = action_match.group(1).upper()
                    
                    # å¤„ç†æ–¹æ‹¬å·æ ¼å¼
                    if '[' in action_match.group(2):
                        # æ–¹æ‹¬å·æ ¼å¼
                        user_id_raw = action_match.group(2).strip('[]')
                        if len(action_match.groups()) >= 4:
                            target_id_raw = action_match.group(3).strip('[]')
                            content = action_match.group(4).strip()
                        else:
                            content = action_match.group(3).strip()
                        
                        # å¤„ç†å ä½ç¬¦
                        user_id = self._resolve_placeholder(user_id_raw)
                        target_id = self._resolve_placeholder(target_id_raw) if 'target_id_raw' in locals() else None
                    else:
                        # æ ‡å‡†æ ¼å¼æˆ–è¿å­—ç¬¦æ ¼å¼
                        user_id = action_match.group(2)
                        if len(action_match.groups()) >= 4:
                            target_id = action_match.group(3)
                            content = action_match.group(4).strip()
                        else:
                            content = action_match.group(3).strip()
                    
                    print(f"âœ… æ‰¾åˆ°ACTION: {action} {user_id} {target_id or 'None'} {content[:30]}...")
                    break
            
            if not action or not user_id:
                print("âŒ æœªæ‰¾åˆ°å®Œæ•´çš„ACTIONå­—æ®µ")
                return None
            
            # éªŒè¯åŠ¨ä½œæ˜¯å¦æœ‰æ•ˆ
            valid_actions = [
                "CREATE_POST", "CREATE_COMMENT", "LIKE_POST", 
                "FOLLOW", "SHARE", "TREND"
            ]
            
            if action not in valid_actions:
                print(f"âŒ æ— æ•ˆçš„ACTION: {action}")
                return None
            
            # æŸ¥æ‰¾REASONINGè¡Œ
            reasoning_patterns = [
                r'REASONING:\s*(.+?)(?:\n|$)',  # æ ‡å‡†æ ¼å¼
                r'reasoning:\s*(.+?)(?:\n|$)',  # å°å†™
                r'Reasoning:\s*(.+?)(?:\n|$)',  # é¦–å­—æ¯å¤§å†™
            ]
            
            reasoning = "No reasoning provided"
            for pattern in reasoning_patterns:
                reasoning_match = re.search(pattern, response, re.IGNORECASE)
                if reasoning_match:
                    reasoning = reasoning_match.group(1).strip()
                    print(f"âœ… æ‰¾åˆ°REASONING: {reasoning[:50]}...")
                    break
            
            print(f"âœ… è§£ææˆåŠŸ: {action} {user_id} | {reasoning[:30]}...")
            
            return {
                "action": action,
                "user_id": user_id,
                "target_id": target_id,
                "content": content,
                "reasoning": reasoning
            }
            
        except Exception as e:
            print(f"âŒ Decision parsing failed: {e}")
            return None


def run_enhanced_rl_oasis_demo(steps: int = 10, 
                              enable_wandb: bool = True,
                              enable_tensorboard: bool = True,
                              wandb_project: str = "sandgraph-enhanced-oasis"):
    """è¿è¡Œå¢å¼ºç‰ˆRL OASISæ¼”ç¤º - åŸºäºåŸå§‹OASIS demo"""
    
    print("ğŸš€ Enhanced OASIS Social Network Demo with Monitoring")
    print("=" * 60)
    
    # 1. åˆ›å»ºLLMç®¡ç†å™¨
    print("\n1. Creating LLM Manager")
    llm_manager = create_shared_llm_manager(
        model_name="mistralai/Mistral-7B-Instruct-v0.2",
        backend="huggingface",
        temperature=0.7,
        max_length=512,
        device="auto",
        torch_dtype="float16"
    )
    
    # 2. åˆ›å»ºç›‘æ§é…ç½®
    monitor_config = MonitoringConfig(
        enable_wandb=enable_wandb,
        enable_tensorboard=enable_tensorboard,
        wandb_project_name=wandb_project,
        wandb_run_name=f"enhanced_oasis_{int(time.time())}",
        tensorboard_log_dir="./logs/enhanced_oasis",
        log_file_path="./logs/enhanced_oasis_metrics.json",
        metrics_sampling_interval=2.0,
        engagement_rate_threshold=0.15,
        user_growth_threshold=0.08
    )
    
    # 3. åˆ›å»ºæ²™ç›’å’Œå†³ç­–å™¨
    print("\n2. Creating Enhanced OASIS Components")
    sandbox = EnhancedOasisSocialSandbox(
        initial_users=50,
        max_users=1000,
        initial_posts=20
    )
    
    # è®¾ç½®ç›‘æ§
    sandbox.setup_monitoring(monitor_config)
    
    # åˆ›å»ºå†³ç­–å™¨
    decision_maker = EnhancedLLMSocialDecisionMaker(llm_manager)
    
    # åˆ›å»ºRLè®­ç»ƒå™¨
    rl_config = RLConfig(
        algorithm=RLAlgorithm.PPO,
        learning_rate=0.001,
        batch_size=32,
        gamma=0.99
    )
    rl_trainer = RLTrainer(rl_config, llm_manager)
    
    # 4. æ‰§è¡Œå¤šæ­¥ç¤¾äº¤ç½‘ç»œæ¨¡æ‹Ÿ
    print(f"\n3. Executing {steps} Enhanced OASIS Social Network Steps")
    
    results = []
    for step in range(steps):
        print(f"\n--- ç¬¬ {step + 1} æ­¥ ---")
        
        try:
            # è·å–å½“å‰çŠ¶æ€
            case = sandbox.case_generator()
            current_state = case["state"]
            
            # ä½¿ç”¨LLMåšå‡ºå†³ç­–
            decision_result = decision_maker.make_decision(current_state)
            decision = decision_result["decision"]
            
            # æ‰§è¡Œç¤¾äº¤å†³ç­–
            try:
                # æ‰§è¡Œç¤¾äº¤è¡ŒåŠ¨
                action_result = sandbox.execute_social_action(
                    decision["action"],
                    decision["user_id"],
                    decision.get("target_id"),
                    decision.get("content")
                )
                
                # éªŒè¯å’Œæ‰§è¡Œå†³ç­–
                score = sandbox.verify_score(
                    f"{decision['action']} {decision.get('target_id', 'general')}",
                    case
                )
                
                # è®¡ç®—å¥–åŠ±
                reward = score * 10
                
                # æ„å»ºçŠ¶æ€ç‰¹å¾
                state_features = {
                    "total_users": current_state["network_state"].get("total_users", 0),
                    "network_density": current_state["network_state"].get("network_density", 0.0),
                    "total_posts": current_state["network_state"].get("total_posts", 0),
                    "total_likes": current_state["network_state"].get("total_likes", 0),
                    "decision_type": _encode_social_action(decision["action"])
                }
                
                # æ·»åŠ åˆ°RLè®­ç»ƒå™¨
                rl_trainer.add_experience(
                    state=state_features,
                    action=json.dumps(decision),
                    reward=reward,
                    done=False
                )
                
                # æ›´æ–°ç­–ç•¥
                update_result = rl_trainer.update_policy()
                
                # æ˜¾ç¤ºRLæ›´æ–°çŠ¶æ€
                print(f"RL Update Status: {update_result.get('status', 'unknown')}")
                if update_result.get('status') == 'insufficient_data':
                    print(f"  Trajectory Count: {update_result.get('trajectory_count', 0)}")
                    print(f"  Required Batch Size: {update_result.get('required_batch_size', 0)}")
                elif update_result.get('status') == 'updated':
                    print(f"  Training Step: {update_result.get('training_step', 0)}")
                    print(f"  Algorithm: {update_result.get('algorithm', 'unknown')}")
                
                result = {
                    "state": current_state,
                    "decision": decision,
                    "llm_response": decision_result["llm_response"],
                    "action_result": action_result,
                    "score": score,
                    "reward": reward,
                    "rl_update": update_result,
                    "sandbox_id": sandbox.sandbox_id
                }
                
                print(f"LLM Decision: {decision['action']} {decision.get('user_id', '')}")
                print(f"Decision Reason: {decision.get('reasoning', '')}")
                print(f"Action Success: {action_result.get('success', False)}")
                print(f"Social Score: {score:.3f}")
                print(f"RL Reward: {reward:.3f}")
                
                # æ˜¾ç¤ºå½“å‰ç½‘ç»œçŠ¶æ€
                network_state = current_state["network_state"]
                print(f"Total Users: {network_state.get('total_users', 0)}")
                print(f"Total Posts: {network_state.get('total_posts', 0)}")
                print(f"Network Density: {network_state.get('network_density', 0.0):.3f}")
                
                results.append(result)
                
            except Exception as e:
                print(f"âŒ Social Action Execution Error: {e}")
                result = {
                    "state": current_state,
                    "decision": {"action": "CREATE_POST", "reasoning": f"Execution Error: {e}"},
                    "score": 0.0,
                    "reward": 0.0,
                    "error": str(e)
                }
                results.append(result)
        
        except Exception as e:
            print(f"âŒ Step {step + 1} Execution Error: {e}")
    
    # 5. è¾“å‡ºæœ€ç»ˆç»“æœ
    print("\n4. Final Results")
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    total_reward = sum(r.get("reward", 0) for r in results)
    avg_score = sum(r.get("score", 0) for r in results) / len(results) if results else 0
    decision_count = decision_maker.decision_count
    
    print(f"Total Decisions: {decision_count}")
    print(f"Total Reward: {total_reward:.3f}")
    print(f"Average Score: {avg_score:.3f}")
    
    # æ˜¾ç¤ºRLè®­ç»ƒç»Ÿè®¡
    rl_stats = rl_trainer.get_training_stats()
    print(f"RL Training Steps: {rl_stats['training_step']}")
    print(f"RL Algorithm: {rl_stats['algorithm']}")
    
    # å¯¼å‡ºç›‘æ§ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # å¯¼å‡ºæŒ‡æ ‡
    if sandbox.monitor:
        metrics_file = f"./logs/enhanced_oasis_metrics_{timestamp}.json"
        sandbox.monitor.export_metrics(metrics_file, "json")
        
        print(f"\nğŸ“ Results exported:")
        print(f"   - Metrics: {metrics_file}")
        
        # æ‰“å°æœ€ç»ˆç»Ÿè®¡
        if sandbox.metrics_history:
            final_metrics = sandbox.metrics_history[-1]
            print(f"\nğŸ“Š Final Statistics:")
            print(f"   - Total Users: {final_metrics.total_users}")
            print(f"   - Engagement Rate: {final_metrics.engagement_rate:.3f}")
            print(f"   - Content Quality: {final_metrics.content_quality_score:.3f}")
            print(f"   - Network Density: {final_metrics.network_density:.3f}")
            print(f"   - Total Alerts: {len(sandbox.monitor.alerts) if sandbox.monitor else 0}")
    
    print("\nâœ… Enhanced OASIS demo completed!")
    
    return results


def _encode_social_action(action: str) -> int:
    """ç¼–ç ç¤¾äº¤è¡ŒåŠ¨ç±»å‹"""
    action_map = {
        "CREATE_POST": 1,
        "CREATE_COMMENT": 2,
        "LIKE_POST": 3,
        "FOLLOW": 4,
        "SHARE": 5,
        "TREND": 6
    }
    return action_map.get(action, 0)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Enhanced OASIS Social Network Demo with Monitoring")
    
    parser.add_argument("--steps", type=int, default=10, 
                       help="Number of simulation steps")
    parser.add_argument("--enable-wandb", action="store_true", default=True,
                       help="Enable WanDB logging")
    parser.add_argument("--enable-tensorboard", action="store_true", default=True,
                       help="Enable TensorBoard logging")
    parser.add_argument("--wandb-project", type=str, default="sandgraph-enhanced-oasis",
                       help="WanDB project name")
    parser.add_argument("--tensorboard-dir", type=str, default="./logs/enhanced_oasis",
                       help="TensorBoard log directory")
    
    args = parser.parse_args()
    
    # è¿è¡Œæ¼”ç¤º
    run_enhanced_rl_oasis_demo(
        steps=args.steps,
        enable_wandb=args.enable_wandb,
        enable_tensorboard=args.enable_tensorboard,
        wandb_project=args.wandb_project
    )


if __name__ == "__main__":
    main() 