#!/usr/bin/env python3
"""
Oasisä»»åŠ¡å®ç°æ¼”ç¤º - é›†æˆSandbox-RLXè‡ªè¿›åŒ–LLM
==========================================

è¿™ä¸ªæ¼”ç¤ºå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨Oasisä»»åŠ¡å®šä¹‰æ–‡æ¡£ä¸­æè¿°çš„ä»»åŠ¡ï¼Œ
ç»“åˆSandbox-RLXçš„è‡ªè¿›åŒ–LLMåŠŸèƒ½æ¥å®ç°æ™ºèƒ½çš„ç¤¾äº¤ç½‘ç»œæ¨¡æ‹Ÿã€‚
ç‰¹åˆ«é’ˆå¯¹ä¿¡æ¯ä¼ æ’­ã€ç«äº‰è¡Œä¸ºå’Œé”™è¯¯ä¿¡æ¯æ‰©æ•£ç­‰å…³é”®åœºæ™¯ã€‚
"""

import sys
import os
import time
import json
import asyncio
import logging
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, field
from datetime import datetime
import random

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å¯¼å…¥Sandbox-RLXè‡ªè¿›åŒ–Oasisæ¨¡å—
from sandbox_rl.core.self_evolving_oasis import (
    create_self_evolving_oasis,
    SelfEvolvingLLM,
    TaskType,
    EvolutionStrategy,
    SelfEvolvingConfig
)


@dataclass
class OasisScenarioConfig:
    """Oasisåœºæ™¯é…ç½®"""
    # åŸºç¡€é…ç½®
    enable_self_evolution: bool = True
    evolution_strategy: str = "adaptive_compression"
    enable_lora: bool = True
    enable_kv_cache_compression: bool = True
    
    # åœºæ™¯ç‰¹å®šé…ç½®
    misinformation_detection_config: dict = field(default_factory=lambda: {
        "accuracy_threshold": 0.9,
        "response_time_limit": 300,
        "false_positive_tolerance": 0.1,
        "detection_model": "specialized_misinformation_detector"
    })
    
    competition_analysis_config: dict = field(default_factory=lambda: {
        "analysis_depth": "comprehensive",
        "prediction_horizon": "3_months",
        "confidence_threshold": 0.8,
        "update_frequency": "real_time"
    })
    
    propagation_analysis_config: dict = field(default_factory=lambda: {
        "path_tracking": True,
        "velocity_prediction": True,
        "influence_mapping": True,
        "optimization_goal": "maximize_truth_spread"
    })
    
    # è¿›åŒ–é…ç½®
    evolution_interval: int = 10
    performance_threshold: float = 0.7
    adaptation_learning_rate: float = 1e-4
    model_pool_size: int = 5


@dataclass
class ScenarioPerformanceMetrics:
    """åœºæ™¯æ€§èƒ½æŒ‡æ ‡"""
    # é”™è¯¯ä¿¡æ¯æ£€æµ‹æŒ‡æ ‡
    detection_accuracy: float = 0.0
    false_positive_rate: float = 0.0
    false_negative_rate: float = 0.0
    response_time: float = 0.0
    
    # ç«äº‰åˆ†ææŒ‡æ ‡
    competition_prediction_accuracy: float = 0.0
    strategy_effectiveness: float = 0.0
    conflict_resolution_success: float = 0.0
    
    # ä¼ æ’­åˆ†ææŒ‡æ ‡
    propagation_prediction_accuracy: float = 0.0
    influence_assessment_accuracy: float = 0.0
    path_analysis_quality: float = 0.0
    
    # ç½‘ç»œä¼˜åŒ–æŒ‡æ ‡
    connection_optimization_effectiveness: float = 0.0
    network_stability_improvement: float = 0.0
    resource_utilization_efficiency: float = 0.0


class ContentGenerationTask:
    """å†…å®¹ç”Ÿæˆä»»åŠ¡ - ä¸“æ³¨äºä¿¡æ¯ä¼ æ’­ç ”ç©¶"""
    
    def __init__(self, evolving_llm: SelfEvolvingLLM):
        self.evolving_llm = evolving_llm
        self.task_type = TaskType.CONTENT_GENERATION
    
    async def generate_content(
        self, 
        agent_profile: dict, 
        content_type: str,
        target_audience: dict,
        propagation_goal: str
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆå…·æœ‰ä¼ æ’­æ½œåŠ›çš„å†…å®¹
        
        Args:
            agent_profile: æ™ºèƒ½ä½“ç‰¹å¾ (æ€§æ ¼ã€å…´è¶£ã€å½±å“åŠ›ç­‰)
            content_type: å†…å®¹ç±»å‹ ("news", "opinion", "fact", "misinformation")
            target_audience: ç›®æ ‡å—ä¼—ç‰¹å¾
            propagation_goal: ä¼ æ’­ç›®æ ‡ ("maximize_reach", "maximize_engagement", "maximize_influence")
        
        Returns:
            åŒ…å«ç”Ÿæˆå†…å®¹ã€é¢„æœŸä¼ æ’­æ•ˆæœã€ç›®æ ‡å—ä¼—åˆ†æçš„ç»“æœ
        """
        prompt = self._build_propagation_prompt(agent_profile, content_type, target_audience, propagation_goal)
        
        start_time = time.time()
        result = self.evolving_llm.process_task(
            self.task_type,
            prompt,
            {
                "agent_profile": agent_profile,
                "content_type": content_type,
                "target_audience": target_audience,
                "propagation_goal": propagation_goal,
                "context": "information_propagation_study"
            }
        )
        response_time = time.time() - start_time
        
        if "error" not in result:
            content = result["response"].text
            performance_score = result.get("performance_score", 0.7)
        else:
            content = self._generate_fallback_content(content_type, agent_profile)
            performance_score = 0.4
        
        # è®°å½•æ€§èƒ½æŒ‡æ ‡
        self._record_performance(response_time, performance_score, content_type)
        
        return {
            "content": content,
            "content_type": content_type,
            "expected_propagation": self._estimate_propagation_potential(content, target_audience),
            "target_audience_analysis": self._analyze_target_audience(target_audience),
            "performance_score": performance_score,
            "response_time": response_time
        }
    
    def _build_propagation_prompt(self, agent_profile: dict, content_type: str, target_audience: dict, propagation_goal: str) -> str:
        return f"""
        ä½œä¸º{agent_profile.get('personality', 'tech_enthusiast')}ç±»å‹çš„ç”¨æˆ·ï¼Œç”Ÿæˆä¸€æ¡{content_type}ç±»å‹çš„å†…å®¹ã€‚
        
        ç›®æ ‡å—ä¼—ç‰¹å¾ï¼š
        - å¹´é¾„åˆ†å¸ƒ: {target_audience.get('age_distribution', 'general')}
        - å…´è¶£åå¥½: {target_audience.get('interests', [])}
        - æ´»è·ƒæ—¶æ®µ: {target_audience.get('active_hours', 'all_day')}
        - ä¼ æ’­å€¾å‘: {target_audience.get('propagation_tendency', 'moderate')}
        
        ä¼ æ’­ç›®æ ‡: {propagation_goal}
        
        è¦æ±‚ï¼š
        1. å†…å®¹å…·æœ‰å¼ºçƒˆçš„ä¼ æ’­æ½œåŠ›
        2. ç¬¦åˆç›®æ ‡å—ä¼—çš„è®¤çŸ¥åå¥½
        3. åŒ…å«æƒ…æ„Ÿè§¦å‘å…ƒç´ 
        4. æ˜“äºç†è§£å’Œè½¬å‘
        5. é•¿åº¦æ§åˆ¶åœ¨200å­—ä»¥å†…
        """
    
    def _generate_fallback_content(self, content_type: str, agent_profile: dict) -> str:
        """ç”Ÿæˆå¤‡ç”¨å†…å®¹"""
        fallback_contents = {
            "news": "æœ€æ–°ç§‘æŠ€åŠ¨æ€ï¼šäººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨å¿«é€Ÿå‘å±•ï¼Œä¸ºå„è¡Œå„ä¸šå¸¦æ¥é©å‘½æ€§å˜åŒ–ã€‚",
            "opinion": "æˆ‘è®¤ä¸ºå½“å‰çš„æŠ€æœ¯å‘å±•è¶‹åŠ¿éå¸¸ä»¤äººå…´å¥‹ï¼Œæˆ‘ä»¬åº”è¯¥ç§¯ææ‹¥æŠ±è¿™äº›å˜åŒ–ã€‚",
            "fact": "æ ¹æ®æœ€æ–°ç ”ç©¶ï¼ŒAIæŠ€æœ¯åœ¨åŒ»ç–—ã€æ•™è‚²ç­‰é¢†åŸŸçš„åº”ç”¨å·²ç»å–å¾—äº†æ˜¾è‘—æˆæœã€‚",
            "misinformation": "æœ‰ä¼ è¨€ç§°æ–°æŠ€æœ¯å¯èƒ½å¸¦æ¥é£é™©ï¼Œä½†ä¸“å®¶è¡¨ç¤ºè¿™äº›æ‹…å¿§è¢«å¤¸å¤§äº†ã€‚"
        }
        return fallback_contents.get(content_type, "è¿™æ˜¯ä¸€æ¡å…³äºæŠ€æœ¯å‘å±•çš„å†…å®¹ã€‚")
    
    def _estimate_propagation_potential(self, content: str, target_audience: dict) -> dict:
        """ä¼°ç®—ä¼ æ’­æ½œåŠ›"""
        # ç®€åŒ–çš„ä¼ æ’­æ½œåŠ›ä¼°ç®—
        base_score = 0.5
        audience_multiplier = target_audience.get('propagation_tendency', 0.5)
        content_length_factor = min(len(content) / 100, 1.0)
        
        return {
            "propagation_score": base_score * audience_multiplier * content_length_factor,
            "expected_reach": int(1000 * audience_multiplier),
            "engagement_potential": "medium"
        }
    
    def _analyze_target_audience(self, target_audience: dict) -> dict:
        """åˆ†æç›®æ ‡å—ä¼—"""
        return {
            "audience_size": "large" if target_audience.get('propagation_tendency', 0.5) > 0.7 else "medium",
            "engagement_likelihood": target_audience.get('propagation_tendency', 0.5),
            "content_preferences": target_audience.get('interests', [])
        }
    
    def _record_performance(self, response_time: float, performance_score: float, content_type: str):
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        logger.info(f"å†…å®¹ç”Ÿæˆä»»åŠ¡ - ç±»å‹:{content_type}, å“åº”æ—¶é—´:{response_time:.2f}s, æ€§èƒ½åˆ†æ•°:{performance_score:.3f}")


class MisinformationDetectionTask:
    """é”™è¯¯ä¿¡æ¯æ£€æµ‹ä»»åŠ¡"""
    
    def __init__(self, evolving_llm: SelfEvolvingLLM):
        self.evolving_llm = evolving_llm
        self.task_type = TaskType.BEHAVIOR_ANALYSIS
    
    async def detect_misinformation(
        self,
        content: str,
        source_profile: dict,
        propagation_context: dict,
        fact_check_data: dict
    ) -> Dict[str, Any]:
        """
        æ£€æµ‹å†…å®¹æ˜¯å¦ä¸ºé”™è¯¯ä¿¡æ¯
        
        Args:
            content: å¾…æ£€æµ‹çš„å†…å®¹
            source_profile: å‘å¸ƒè€…ç‰¹å¾
            propagation_context: ä¼ æ’­ä¸Šä¸‹æ–‡
            fact_check_data: äº‹å®æ ¸æŸ¥æ•°æ®
        
        Returns:
            åŒ…å«æ£€æµ‹ç»“æœã€ç½®ä¿¡åº¦ã€é£é™©ç­‰çº§ã€å»ºè®®æªæ–½çš„ç»“æœ
        """
        prompt = self._build_detection_prompt(content, source_profile, propagation_context, fact_check_data)
        
        start_time = time.time()
        result = self.evolving_llm.process_task(
            self.task_type,
            prompt,
            {
                "content": content,
                "source_profile": source_profile,
                "propagation_context": propagation_context,
                "fact_check_data": fact_check_data,
                "detection_type": "misinformation"
            }
        )
        response_time = time.time() - start_time
        
        if "error" not in result:
            detection_result = self._parse_detection_result(result)
            performance_score = result.get("performance_score", 0.7)
        else:
            detection_result = self._generate_default_detection(content, source_profile)
            performance_score = 0.4
        
        # è®°å½•æ€§èƒ½æŒ‡æ ‡
        self._record_performance(response_time, performance_score)
        
        return {
            **detection_result,
            "performance_score": performance_score,
            "response_time": response_time
        }
    
    def _build_detection_prompt(self, content: str, source_profile: dict, propagation_context: dict, fact_check_data: dict) -> str:
        return f"""
        æ£€æµ‹ä»¥ä¸‹å†…å®¹æ˜¯å¦ä¸ºé”™è¯¯ä¿¡æ¯ï¼š
        
        å†…å®¹: {content}
        
        å‘å¸ƒè€…ç‰¹å¾ï¼š
        - å†å²è¡Œä¸º: {source_profile.get('history', 'unknown')}
        - å¯ä¿¡åº¦è¯„åˆ†: {source_profile.get('credibility_score', 0.0)}
        - ä¼ æ’­å€¾å‘: {source_profile.get('propagation_tendency', 'unknown')}
        
        ä¼ æ’­ä¸Šä¸‹æ–‡ï¼š
        - ä¼ æ’­é€Ÿåº¦: {propagation_context.get('spread_velocity', 'unknown')}
        - å½±å“èŒƒå›´: {propagation_context.get('impact_scope', 'unknown')}
        - å—ä¼—ååº”: {propagation_context.get('audience_reaction', 'unknown')}
        
        äº‹å®æ ¸æŸ¥æ•°æ®: {fact_check_data}
        
        è¯·è¯„ä¼°ï¼š
        1. å†…å®¹çœŸå®æ€§è¯„åˆ† (0-1)
        2. é”™è¯¯ä¿¡æ¯é£é™©ç­‰çº§ (ä½/ä¸­/é«˜)
        3. ä¼ æ’­é£é™©é¢„æµ‹
        4. å»ºè®®çš„åº”å¯¹æªæ–½
        5. éœ€è¦é‡ç‚¹å…³æ³¨çš„å…³é”®è¯æˆ–æ¨¡å¼
        """
    
    def _parse_detection_result(self, result: dict) -> dict:
        """è§£ææ£€æµ‹ç»“æœ"""
        try:
            response_text = result["response"].text
            # å°è¯•è§£æç»“æ„åŒ–çš„æ£€æµ‹ç»“æœ
            if "çœŸå®æ€§è¯„åˆ†" in response_text:
                # æå–æ•°å€¼
                import re
                score_match = re.search(r'çœŸå®æ€§è¯„åˆ†[ï¼š:]\s*([0-9.]+)', response_text)
                risk_match = re.search(r'é£é™©ç­‰çº§[ï¼š:]\s*(ä½|ä¸­|é«˜)', response_text)
                
                return {
                    "authenticity_score": float(score_match.group(1)) if score_match else 0.5,
                    "risk_level": risk_match.group(1) if risk_match else "ä¸­",
                    "is_misinformation": "çœŸå®æ€§è¯„åˆ†" in response_text and "ä½" in response_text,
                    "confidence": 0.8,
                    "recommended_actions": ["monitor", "flag"],
                    "key_patterns": ["suspicious_keywords"]
                }
            else:
                return self._generate_default_detection("", {})
        except Exception as e:
            logger.warning(f"è§£ææ£€æµ‹ç»“æœå¤±è´¥: {e}")
            return self._generate_default_detection("", {})
    
    def _generate_default_detection(self, content: str, source_profile: dict) -> dict:
        """ç”Ÿæˆé»˜è®¤æ£€æµ‹ç»“æœ"""
        credibility_score = source_profile.get('credibility_score', 0.5)
        is_misinformation = credibility_score < 0.3
        
        return {
            "authenticity_score": credibility_score,
            "risk_level": "é«˜" if is_misinformation else "ä½",
            "is_misinformation": is_misinformation,
            "confidence": 0.6,
            "recommended_actions": ["monitor"] if is_misinformation else ["allow"],
            "key_patterns": []
        }
    
    def _record_performance(self, response_time: float, performance_score: float):
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        logger.info(f"é”™è¯¯ä¿¡æ¯æ£€æµ‹ä»»åŠ¡ - å“åº”æ—¶é—´:{response_time:.2f}s, æ€§èƒ½åˆ†æ•°:{performance_score:.3f}")


class GroupBehaviorAnalysisTask:
    """ç¾¤ä½“è¡Œä¸ºåˆ†æä»»åŠ¡ - ä¸“æ³¨äºç«äº‰åˆ†æ"""
    
    def __init__(self, evolving_llm: SelfEvolvingLLM):
        self.evolving_llm = evolving_llm
        self.task_type = TaskType.BEHAVIOR_ANALYSIS
    
    async def analyze_competition_behavior(
        self,
        group_a: dict,
        group_b: dict,
        competition_history: list,
        network_state: dict
    ) -> Dict[str, Any]:
        """
        åˆ†æç¾¤ä½“é—´çš„ç«äº‰è¡Œä¸ºå’Œç­–ç•¥
        
        Args:
            group_a: ç¾¤ä½“Açš„ç‰¹å¾å’Œè¡Œä¸ºæ•°æ®
            group_b: ç¾¤ä½“Bçš„ç‰¹å¾å’Œè¡Œä¸ºæ•°æ®
            competition_history: ç«äº‰å†å²è®°å½•
            network_state: å½“å‰ç½‘ç»œçŠ¶æ€
        
        Returns:
            åŒ…å«ç«äº‰ç­–ç•¥ã€å¯¹æŠ—å¼ºåº¦ã€å½±å“èŒƒå›´ã€èƒœè´Ÿé¢„æµ‹çš„ç»“æœ
        """
        prompt = self._build_competition_prompt(group_a, group_b, competition_history, network_state)
        
        start_time = time.time()
        result = self.evolving_llm.process_task(
            self.task_type,
            prompt,
            {
                "group_a": group_a,
                "group_b": group_b,
                "competition_history": competition_history,
                "network_state": network_state,
                "analysis_type": "competition_behavior"
            }
        )
        response_time = time.time() - start_time
        
        if "error" not in result:
            analysis_result = self._parse_competition_analysis(result)
            performance_score = result.get("performance_score", 0.7)
        else:
            analysis_result = self._generate_default_competition_analysis(group_a, group_b)
            performance_score = 0.4
        
        # è®°å½•æ€§èƒ½æŒ‡æ ‡
        self._record_performance(response_time, performance_score)
        
        return {
            **analysis_result,
            "performance_score": performance_score,
            "response_time": response_time
        }
    
    def _build_competition_prompt(self, group_a: dict, group_b: dict, competition_history: list, network_state: dict) -> str:
        return f"""
        åˆ†æä¸¤ä¸ªç¾¤ä½“åœ¨ç½‘ç»œä¸­çš„ç«äº‰è¡Œä¸ºï¼š
        
        ç¾¤ä½“Aç‰¹å¾ï¼š
        - è§„æ¨¡: {group_a.get('size', 0)} ç”¨æˆ·
        - å½±å“åŠ›: {group_a.get('influence', 0.0)}
        - ç­–ç•¥å€¾å‘: {group_a.get('strategy_tendency', 'unknown')}
        - æ´»è·ƒåº¦: {group_a.get('activity_level', 0.0)}
        
        ç¾¤ä½“Bç‰¹å¾ï¼š
        - è§„æ¨¡: {group_b.get('size', 0)} ç”¨æˆ·
        - å½±å“åŠ›: {group_b.get('influence', 0.0)}
        - ç­–ç•¥å€¾å‘: {group_b.get('strategy_tendency', 'unknown')}
        - æ´»è·ƒåº¦: {group_b.get('activity_level', 0.0)}
        
        ç«äº‰å†å²: {len(competition_history)} æ¬¡å¯¹æŠ—
        
        è¯·åˆ†æï¼š
        1. åŒæ–¹çš„ç«äº‰ç­–ç•¥å’Œç‰¹ç‚¹
        2. å¯¹æŠ—çš„å¼ºåº¦å’Œé¢‘ç‡
        3. å¯¹ç½‘ç»œæ•´ä½“ç»“æ„çš„å½±å“
        4. æœªæ¥ç«äº‰è¶‹åŠ¿é¢„æµ‹
        5. å¯èƒ½çš„å†²çªå‡çº§ç‚¹
        """
    
    def _parse_competition_analysis(self, result: dict) -> dict:
        """è§£æç«äº‰åˆ†æç»“æœ"""
        try:
            response_text = result["response"].text
            # ç®€åŒ–çš„ç»“æœè§£æ
            return {
                "competition_intensity": 0.7,  # åŸºäºå“åº”å†…å®¹ä¼°ç®—
                "group_a_strategy": "aggressive" if "aggressive" in response_text.lower() else "defensive",
                "group_b_strategy": "defensive" if "defensive" in response_text.lower() else "aggressive",
                "conflict_escalation_risk": "medium",
                "network_stability_impact": "moderate",
                "predicted_outcome": "balanced",
                "recommendations": ["monitor", "mediate"]
            }
        except Exception as e:
            logger.warning(f"è§£æç«äº‰åˆ†æç»“æœå¤±è´¥: {e}")
            return self._generate_default_competition_analysis({}, {})
    
    def _generate_default_competition_analysis(self, group_a: dict, group_b: dict) -> dict:
        """ç”Ÿæˆé»˜è®¤ç«äº‰åˆ†æç»“æœ"""
        group_a_influence = group_a.get('influence', 0.5)
        group_b_influence = group_b.get('influence', 0.5)
        
        return {
            "competition_intensity": abs(group_a_influence - group_b_influence),
            "group_a_strategy": "balanced",
            "group_b_strategy": "balanced",
            "conflict_escalation_risk": "low",
            "network_stability_impact": "minimal",
            "predicted_outcome": "balanced",
            "recommendations": ["monitor"]
        }
    
    def _record_performance(self, response_time: float, performance_score: float):
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        logger.info(f"ç¾¤ä½“è¡Œä¸ºåˆ†æä»»åŠ¡ - å“åº”æ—¶é—´:{response_time:.2f}s, æ€§èƒ½åˆ†æ•°:{performance_score:.3f}")


class OasisTaskScheduler:
    """Oasisä»»åŠ¡è°ƒåº¦å™¨ - æ”¯æŒåœºæ™¯é©±åŠ¨çš„ä»»åŠ¡æ‰§è¡Œ"""
    
    def __init__(self, evolving_llm: SelfEvolvingLLM, config: OasisScenarioConfig):
        self.evolving_llm = evolving_llm
        self.config = config
        
        # åˆå§‹åŒ–ä»»åŠ¡å¤„ç†å™¨
        self.task_handlers = {
            # ä¿¡æ¯ä¼ æ’­ä»»åŠ¡
            "content_generation": ContentGenerationTask(evolving_llm),
            "misinformation_detection": MisinformationDetectionTask(evolving_llm),
            
            # ç«äº‰åˆ†æä»»åŠ¡
            "group_behavior_analysis": GroupBehaviorAnalysisTask(evolving_llm),
        }
        
        # æ€§èƒ½ç›‘æ§
        self.performance_monitor = TaskPerformanceMonitor()
        self.evolution_trigger = EvolutionTrigger()
        
        logger.info("Oasisä»»åŠ¡è°ƒåº¦å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def execute_scenario(
        self, 
        scenario_type: str, 
        scenario_data: dict,
        execution_mode: str = "sequential"
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œç‰¹å®šåœºæ™¯çš„ä»»åŠ¡åºåˆ—
        
        Args:
            scenario_type: åœºæ™¯ç±»å‹ ("misinformation_spread", "group_competition", "information_propagation")
            scenario_data: åœºæ™¯æ•°æ®
            execution_mode: æ‰§è¡Œæ¨¡å¼ ("sequential", "parallel", "adaptive")
        
        Returns:
            åŒ…å«æ‰§è¡Œç»“æœã€æ€§èƒ½æŒ‡æ ‡ã€è¿›åŒ–å»ºè®®çš„ç»“æœ
        """
        # æ ¹æ®åœºæ™¯ç±»å‹é€‰æ‹©ä»»åŠ¡åºåˆ—
        task_sequence = self._get_scenario_tasks(scenario_type)
        
        # æ‰§è¡Œä»»åŠ¡åºåˆ—
        results = []
        for task_config in task_sequence:
            task_result = await self._execute_task_with_context(task_config, scenario_data)
            results.append(task_result)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘è¿›åŒ–
            if self.evolution_trigger.should_evolve(task_result):
                await self._trigger_evolution(task_result)
        
        return self._compile_scenario_results(results, scenario_type)
    
    def _get_scenario_tasks(self, scenario_type: str) -> list:
        """æ ¹æ®åœºæ™¯ç±»å‹è·å–ä»»åŠ¡åºåˆ—"""
        scenario_configs = {
            "misinformation_spread": [
                {"type": "misinformation_detection", "priority": "high"},
                {"type": "content_generation", "priority": "medium"},
            ],
            "group_competition": [
                {"type": "group_behavior_analysis", "priority": "high"},
                {"type": "content_generation", "priority": "medium"},
            ],
            "information_propagation": [
                {"type": "content_generation", "priority": "high"},
                {"type": "misinformation_detection", "priority": "medium"},
            ]
        }
        
        return scenario_configs.get(scenario_type, [])
    
    async def _execute_task_with_context(self, task_config: dict, scenario_data: dict) -> dict:
        """åœ¨åœºæ™¯ä¸Šä¸‹æ–‡ä¸­æ‰§è¡Œä»»åŠ¡"""
        task_type = task_config["type"]
        priority = task_config["priority"]
        
        if task_type not in self.task_handlers:
            return {
                "task_type": task_type,
                "error": f"æœªçŸ¥ä»»åŠ¡ç±»å‹: {task_type}",
                "success": False
            }
        
        handler = self.task_handlers[task_type]
        
        try:
            if task_type == "content_generation":
                result = await handler.generate_content(
                    agent_profile=scenario_data.get("agent_profile", {}),
                    content_type=scenario_data.get("content_type", "news"),
                    target_audience=scenario_data.get("target_audience", {}),
                    propagation_goal=scenario_data.get("propagation_goal", "maximize_reach")
                )
            elif task_type == "misinformation_detection":
                result = await handler.detect_misinformation(
                    content=scenario_data.get("content", ""),
                    source_profile=scenario_data.get("source_profile", {}),
                    propagation_context=scenario_data.get("propagation_context", {}),
                    fact_check_data=scenario_data.get("fact_check_data", {})
                )
            elif task_type == "group_behavior_analysis":
                result = await handler.analyze_competition_behavior(
                    group_a=scenario_data.get("group_a", {}),
                    group_b=scenario_data.get("group_b", {}),
                    competition_history=scenario_data.get("competition_history", []),
                    network_state=scenario_data.get("network_state", {})
                )
            else:
                result = {"error": f"æœªå®ç°çš„ä»»åŠ¡ç±»å‹: {task_type}"}
            
            # è®°å½•æ€§èƒ½
            self.performance_monitor.record_task_performance(task_type, result)
            
            return {
                "task_type": task_type,
                "priority": priority,
                "result": result,
                "timestamp": datetime.now().isoformat(),
                "success": "error" not in result,
                "performance_score": result.get("performance_score", 0.0)
            }
            
        except Exception as e:
            logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥ {task_type}: {e}")
            return {
                "task_type": task_type,
                "priority": priority,
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
                "success": False,
                "performance_score": 0.0
            }
    
    async def _trigger_evolution(self, task_result: dict):
        """è§¦å‘è¿›åŒ–"""
        logger.info(f"è§¦å‘æ¨¡å‹è¿›åŒ– - ä»»åŠ¡: {task_result['task_type']}, æ€§èƒ½åˆ†æ•°: {task_result.get('performance_score', 0.0)}")
        # è¿™é‡Œå¯ä»¥æ·»åŠ å…·ä½“çš„è¿›åŒ–é€»è¾‘
    
    def _compile_scenario_results(self, results: list, scenario_type: str) -> dict:
        """ç¼–è¯‘åœºæ™¯ç»“æœ"""
        successful_results = [r for r in results if r["success"]]
        failed_results = [r for r in results if not r["success"]]
        
        avg_performance = sum(r.get("performance_score", 0) for r in successful_results) / len(successful_results) if successful_results else 0
        
        return {
            "scenario_type": scenario_type,
            "total_tasks": len(results),
            "successful_tasks": len(successful_results),
            "failed_tasks": len(failed_results),
            "average_performance": avg_performance,
            "results": results,
            "recommendations": self._generate_recommendations(results, scenario_type)
        }
    
    def _generate_recommendations(self, results: list, scenario_type: str) -> list:
        """ç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        if scenario_type == "misinformation_spread":
            if any(r.get("result", {}).get("is_misinformation", False) for r in results):
                recommendations.append("æ£€æµ‹åˆ°é”™è¯¯ä¿¡æ¯ï¼Œå»ºè®®ç«‹å³é‡‡å–é˜»æ–­æªæ–½")
            recommendations.append("åŠ å¼ºé”™è¯¯ä¿¡æ¯æ£€æµ‹æ¨¡å‹çš„è®­ç»ƒ")
        
        elif scenario_type == "group_competition":
            if any(r.get("result", {}).get("conflict_escalation_risk") == "high" for r in results):
                recommendations.append("æ£€æµ‹åˆ°é«˜å†²çªé£é™©ï¼Œå»ºè®®è¿›è¡Œè°ƒè§£")
            recommendations.append("ç›‘æ§ç¾¤ä½“ç«äº‰åŠ¨æ€ï¼Œé˜²æ­¢ç½‘ç»œæåŒ–")
        
        return recommendations


class TaskPerformanceMonitor:
    """ä»»åŠ¡æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.performance_history = []
        self.scenario_metrics = {}
    
    def record_task_performance(self, task_type: str, result: dict):
        """è®°å½•ä»»åŠ¡æ€§èƒ½"""
        self.performance_history.append({
            "task_type": task_type,
            "result": result,
            "timestamp": datetime.now()
        })
    
    def analyze_scenario_trends(self, scenario_type: str) -> dict:
        """åˆ†æåœºæ™¯æ€§èƒ½è¶‹åŠ¿"""
        if scenario_type not in self.scenario_metrics:
            return {"trend": "insufficient_data"}
        
        recent_metrics = self.scenario_metrics[scenario_type]
        
        return {
            "scenario_type": scenario_type,
            "performance_trend": "stable",  # ç®€åŒ–çš„è¶‹åŠ¿åˆ†æ
            "optimization_opportunities": ["improve_detection_accuracy"],
            "evolution_recommendations": ["update_model_parameters"]
        }


class EvolutionTrigger:
    """è¿›åŒ–è§¦å‘å™¨"""
    
    def __init__(self):
        self.evolution_thresholds = {
            "misinformation_spread": 0.6,  # é”™è¯¯ä¿¡æ¯ä¼ æ’­æ£€æµ‹å‡†ç¡®ç‡é˜ˆå€¼
            "group_competition": 0.7,      # ç«äº‰åˆ†æå‡†ç¡®ç‡é˜ˆå€¼
            "information_propagation": 0.8  # ä¿¡æ¯ä¼ æ’­é¢„æµ‹å‡†ç¡®ç‡é˜ˆå€¼
        }
    
    def should_evolve(self, task_result: dict) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦è§¦å‘è¿›åŒ–"""
        performance_score = task_result.get("performance_score", 0.0)
        return performance_score < 0.7  # ç®€åŒ–çš„é˜ˆå€¼åˆ¤æ–­


async def run_oasis_scenario_demo():
    """è¿è¡ŒOasisåœºæ™¯æ¼”ç¤º"""
    
    print("ğŸš€ Oasisåœºæ™¯æ¼”ç¤º - ä¿¡æ¯ä¼ æ’­ä¸ç«äº‰åˆ†æ")
    print("=" * 60)
    print("æ”¯æŒåœºæ™¯:")
    print("- é”™è¯¯ä¿¡æ¯ä¼ æ’­æ£€æµ‹")
    print("- ç¾¤ä½“ç«äº‰è¡Œä¸ºåˆ†æ")
    print("- ä¿¡æ¯ä¼ æ’­æ•ˆæœé¢„æµ‹")
    print("- è‡ªè¿›åŒ–LLMé›†æˆ")
    print("=" * 60)
    
    # åˆ›å»ºé…ç½®
    config = OasisScenarioConfig(
        enable_self_evolution=True,
        evolution_strategy="adaptive_compression",
        enable_lora=True,
        enable_kv_cache_compression=True,
        evolution_interval=5,
        performance_threshold=0.7
    )
    
    # åˆ›å»ºè‡ªè¿›åŒ–LLM
    sandbox = create_self_evolving_oasis(
        evolution_strategy=config.evolution_strategy,
        enable_lora=config.enable_lora,
        enable_kv_cache_compression=config.enable_kv_cache_compression,
        model_pool_size=config.model_pool_size,
        evolution_interval=config.evolution_interval
    )
    
    # è·å–è‡ªè¿›åŒ–LLMå®ä¾‹
    evolving_llm = sandbox.evolving_llm
    
    # åˆ›å»ºä»»åŠ¡è°ƒåº¦å™¨
    task_scheduler = OasisTaskScheduler(evolving_llm, config)
    
    # åœºæ™¯1: é”™è¯¯ä¿¡æ¯ä¼ æ’­æ£€æµ‹
    print("\n--- åœºæ™¯1: é”™è¯¯ä¿¡æ¯ä¼ æ’­æ£€æµ‹ ---")
    misinformation_scenario = {
        "content": "æœ€æ–°ç ”ç©¶å‘ç°ï¼ŒæŸç§æ–°æŠ€æœ¯å¯èƒ½å¯¹äººä½“å¥åº·é€ æˆä¸¥é‡å±å®³ï¼Œä¸“å®¶å‘¼åç«‹å³åœæ­¢ä½¿ç”¨ã€‚",
        "source_profile": {
            "credibility_score": 0.3,
            "history": "frequent_misinformation",
            "propagation_tendency": "high"
        },
        "propagation_context": {
            "spread_velocity": "fast",
            "impact_scope": "large",
            "audience_reaction": "concerned"
        },
        "fact_check_data": {
            "verified_sources": ["scientific_journal"],
            "contradicting_evidence": ["health_authority_statement"],
            "expert_opinions": ["safety_confirmed"]
        }
    }
    
    result1 = await task_scheduler.execute_scenario(
        scenario_type="misinformation_spread",
        scenario_data=misinformation_scenario
    )
    
    print(f"âœ“ é”™è¯¯ä¿¡æ¯æ£€æµ‹å®Œæˆ:")
    print(f"  æ£€æµ‹å‡†ç¡®ç‡: {result1['average_performance']:.3f}")
    print(f"  æˆåŠŸä»»åŠ¡æ•°: {result1['successful_tasks']}/{result1['total_tasks']}")
    print(f"  å»ºè®®: {result1['recommendations']}")
    
    # åœºæ™¯2: ç¾¤ä½“ç«äº‰åˆ†æ
    print("\n--- åœºæ™¯2: ç¾¤ä½“ç«äº‰åˆ†æ ---")
    competition_scenario = {
        "group_a": {
            "size": 5000,
            "influence": 0.7,
            "strategy_tendency": "aggressive",
            "activity_level": 0.8
        },
        "group_b": {
            "size": 3000,
            "influence": 0.6,
            "strategy_tendency": "defensive",
            "activity_level": 0.7
        },
        "competition_history": [
            {"type": "content_battle", "winner": "group_a", "timestamp": time.time() - 86400},
            {"type": "influence_contest", "winner": "group_b", "timestamp": time.time() - 43200}
        ],
        "network_state": {
            "total_users": 100000,
            "active_users": 80000,
            "network_density": 0.01
        }
    }
    
    result2 = await task_scheduler.execute_scenario(
        scenario_type="group_competition",
        scenario_data=competition_scenario
    )
    
    print(f"âœ“ ç¾¤ä½“ç«äº‰åˆ†æå®Œæˆ:")
    print(f"  åˆ†æå‡†ç¡®ç‡: {result2['average_performance']:.3f}")
    print(f"  æˆåŠŸä»»åŠ¡æ•°: {result2['successful_tasks']}/{result2['total_tasks']}")
    print(f"  å»ºè®®: {result2['recommendations']}")
    
    # åœºæ™¯3: ä¿¡æ¯ä¼ æ’­æ•ˆæœé¢„æµ‹
    print("\n--- åœºæ™¯3: ä¿¡æ¯ä¼ æ’­æ•ˆæœé¢„æµ‹ ---")
    propagation_scenario = {
        "agent_profile": {
            "personality": "influencer",
            "interests": ["technology", "innovation"],
            "activity_level": 0.9
        },
        "content_type": "news",
        "target_audience": {
            "age_distribution": "18-35",
            "interests": ["technology", "AI"],
            "active_hours": "evening",
            "propagation_tendency": 0.8
        },
        "propagation_goal": "maximize_influence"
    }
    
    result3 = await task_scheduler.execute_scenario(
        scenario_type="information_propagation",
        scenario_data=propagation_scenario
    )
    
    print(f"âœ“ ä¿¡æ¯ä¼ æ’­é¢„æµ‹å®Œæˆ:")
    print(f"  é¢„æµ‹å‡†ç¡®ç‡: {result3['average_performance']:.3f}")
    print(f"  æˆåŠŸä»»åŠ¡æ•°: {result3['successful_tasks']}/{result3['total_tasks']}")
    print(f"  å»ºè®®: {result3['recommendations']}")
    
    # ä¿å­˜ç»“æœ
    results = {
        "misinformation_detection": result1,
        "group_competition": result2,
        "information_propagation": result3,
        "evolution_stats": sandbox.evolving_llm.get_evolution_stats(),
        "config": config.__dict__
    }
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    os.makedirs("./data", exist_ok=True)
    with open("./data/oasis_scenario_demo_results.json", "w") as f:
        json.dump(results, f, indent=2, default=str)
    
    print(f"\n=== æ¼”ç¤ºå®Œæˆ ===")
    print(f"ç»“æœå·²ä¿å­˜åˆ°: ./data/oasis_scenario_demo_results.json")
    print(f"æ€»åœºæ™¯æ•°: 3")
    print(f"å¹³å‡æ€§èƒ½: {(result1['average_performance'] + result2['average_performance'] + result3['average_performance']) / 3:.3f}")
    print(f"è¿›åŒ–æ­¥éª¤: {results['evolution_stats']['evolution_step']}")
    
    return results


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Oasisåœºæ™¯æ¼”ç¤º")
    parser.add_argument("--scenarios", type=str, default="all", 
                       choices=["misinformation", "competition", "propagation", "all"],
                       help="è¦è¿è¡Œçš„åœºæ™¯")
    parser.add_argument("--strategy", type=str, default="adaptive_compression", 
                       choices=["gradient_based", "meta_learning", "adaptive_compression", "multi_model"],
                       help="è¿›åŒ–ç­–ç•¥")
    
    args = parser.parse_args()
    
    try:
        results = asyncio.run(run_oasis_scenario_demo())
        print("\nâœ… æ¼”ç¤ºå®Œæˆ!")
        
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc() 