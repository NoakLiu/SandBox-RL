#!/usr/bin/env python3
"""
SandGraph ç¤¾äº¤ç½‘ç»œç¯å¢ƒæ¼”ç¤º - åŸºäºRLçš„LLMå†³ç­–æ¶æ„

æ–°çš„æ¶æ„è®¾è®¡ï¼š
1. Sandboxä½œä¸ºç¯å¢ƒèŠ‚ç‚¹
2. LLMä½œä¸ºå†³ç­–å™¨ï¼ˆä¸æ˜¯èŠ‚ç‚¹ï¼‰
3. RLç®—æ³•æ›´æ–°LLMæƒé‡
4. çŠ¶æ€è½¬ç§»ç”±LLMå†³ç­–é©±åŠ¨
"""

import sys
import os
import time
import json
import argparse
import random
import re
from typing import Dict, Any, List, Union, Optional
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from sandgraph.core.llm_interface import create_shared_llm_manager
from sandgraph.core.sg_workflow import (
    SG_Workflow, WorkflowMode, EnhancedWorkflowNode,
    NodeType, NodeCondition, NodeLimits, GameState
)
from sandgraph.core.rl_algorithms import RLTrainer, RLConfig, RLAlgorithm
from sandgraph.sandbox_implementations import SocialNetworkSandbox


def print_section(title: str):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print(f"\n{'='*60}")
    print(f" {title}")
    print(f"{'='*60}")


class LLMDecisionMaker:
    """LLMå†³ç­–å™¨ - ä¸æ˜¯èŠ‚ç‚¹ï¼Œè€Œæ˜¯å†³ç­–å¼•æ“"""
    
    def __init__(self, llm_manager):
        self.llm_manager = llm_manager
        self.decision_count = 0
        
        # å†å²æ•°æ®ç®¡ç†
        self.decision_history = []  # å†³ç­–å†å²
        self.network_history = []   # ç½‘ç»œçŠ¶æ€å†å²
        self.user_history = []      # ç”¨æˆ·è¡Œä¸ºå†å²
        self.performance_history = [] # è¡¨ç°å†å²
        
        # æ³¨å†Œå†³ç­–èŠ‚ç‚¹
        self.llm_manager.register_node("social_decision", {
            "role": "ç¤¾äº¤ç½‘ç»œç­–ç•¥ä¸“å®¶",
            "reasoning_type": "strategic",
            "temperature": 0.7,
            "max_length": 512
        })
    
    def make_decision(self, current_state: Dict[str, Any]) -> Dict[str, Any]:
        """åŸºäºå½“å‰çŠ¶æ€åšå‡ºå†³ç­–"""
        self.decision_count += 1
        
        # æ„å»ºå†³ç­–æç¤º
        prompt = self._construct_decision_prompt(current_state)
        
        print("=" * 80)
        print(f"Decision {self.decision_count} - Complete Prompt Content:")
        print("=" * 80)
        print(prompt)
        print("=" * 80)
        
        try:
            # ç”ŸæˆLLMå“åº”
            response = self.llm_manager.generate_for_node(
                "social_decision",
                prompt,
                temperature=0.7,
                max_new_tokens=256,  # å¢åŠ tokenæ•°é‡
                do_sample=True
            )
            
            print(f"LLM Response Status: {response.status if hasattr(response, 'status') else 'unknown'}")
            print(f"LLM Complete Response: {response.text}")
            
            # è§£æå“åº”
            decision = self._parse_decision_response(response.text)
            
            # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨æ›´å®½æ¾çš„è§£æ
            if decision is None:
                decision = self._parse_decision_fallback(response.text)
            
            # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å†³ç­–
            if decision is None:
                decision = {
                    "action": "CREATE_POST",
                    "target": "N/A",
                    "reasoning": "Fallback decision due to parsing failure"
                }
            
            # æ›´æ–°å†å²æ•°æ®
            self._update_history(current_state, decision, response.text)
            
            return {
                "decision": decision,
                "llm_response": response.text,
                "prompt": prompt,
                "decision_count": self.decision_count
            }
            
        except Exception as e:
            print(f"âŒ Decision generation failed: {e}")
            fallback_decision = {
                "action": "CREATE_POST",
                "target": "N/A", 
                "reasoning": f"Error in decision generation: {str(e)}"
            }
            
            # æ›´æ–°å†å²æ•°æ®ï¼ˆå³ä½¿å¤±è´¥ï¼‰
            self._update_history(current_state, fallback_decision, f"Error: {str(e)}")
            
            return {
                "decision": fallback_decision,
                "llm_response": f"Error: {str(e)}",
                "prompt": prompt,
                "decision_count": self.decision_count
            }
    
    def _update_history(self, state: Dict[str, Any], decision: Dict[str, Any], llm_response: str):
        """æ›´æ–°å†å²æ•°æ®"""
        # è®°å½•å†³ç­–å†å²
        decision_record = {
            "step": self.decision_count,
            "timestamp": datetime.now().isoformat(),
            "decision": decision,
            "llm_response": llm_response,
            "network_state": state.get("network_state", {}),
            "user_behavior": state.get("user_behavior", {}),
            "content_metrics": state.get("content_metrics", {})
        }
        self.decision_history.append(decision_record)
        
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
        if len(self.decision_history) > 50:
            self.decision_history = self.decision_history[-50:]
        
        # è®°å½•ç½‘ç»œçŠ¶æ€å†å²
        network_record = {
            "step": self.decision_count,
            "network_state": state.get("network_state", {}),
            "user_behavior": state.get("user_behavior", {})
        }
        self.network_history.append(network_record)
        
        # è®°å½•ç”¨æˆ·è¡Œä¸ºå†å²
        user_record = {
            "step": self.decision_count,
            "user_behavior": state.get("user_behavior", {}),
            "engagement_score": self._calculate_engagement_score(state)
        }
        self.user_history.append(user_record)
        
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
        if len(self.network_history) > 30:
            self.network_history = self.network_history[-30:]
        if len(self.user_history) > 30:
            self.user_history = self.user_history[-30:]
    
    def _calculate_engagement_score(self, state: Dict[str, Any]) -> float:
        """è®¡ç®—ç”¨æˆ·å‚ä¸åº¦åˆ†æ•°"""
        user_behavior = state.get("user_behavior", {})
        
        # è®¡ç®—å„ç§å‚ä¸åº¦æŒ‡æ ‡
        total_posts = user_behavior.get("posts_created", 0)
        total_likes = user_behavior.get("likes_given", 0)
        total_comments = user_behavior.get("comments_made", 0)
        total_shares = user_behavior.get("shares_made", 0)
        active_users = user_behavior.get("active_users", 0)
        
        # ç»¼åˆå‚ä¸åº¦åˆ†æ•°
        engagement_score = (
            total_posts * 0.3 +
            total_likes * 0.2 +
            total_comments * 0.3 +
            total_shares * 0.2
        ) * (active_users / 100.0)  # å½’ä¸€åŒ–
        
        return min(1.0, engagement_score)
    
    def _construct_decision_prompt(self, state: Dict[str, Any]) -> str:
        """æ„é€ å†³ç­–æç¤ºï¼ˆåŒ…å«å†å²æ•°æ®ï¼‰"""
        network_state = state.get("network_state", {})
        user_behavior = state.get("user_behavior", {})
        content_metrics = state.get("content_metrics", {})
        
        # æ„å»ºç½‘ç»œçŠ¶æ€æ‘˜è¦
        network_summary = []
        for user_id, user_data in network_state.items():
            network_summary.append(
                f"User {user_id}: "
                f"Followers={user_data.get('followers', 0)}, "
                f"Following={user_data.get('following', 0)}, "
                f"Posts={user_data.get('posts', 0)}, "
                f"Engagement={user_data.get('engagement_rate', 0):.2f}%"
            )
        
        # æ„å»ºç”¨æˆ·è¡Œä¸ºæ‘˜è¦
        behavior_summary = f"""
Current User Behavior:
- Active Users: {user_behavior.get('active_users', 0)}
- Posts Created: {user_behavior.get('posts_created', 0)}
- Likes Given: {user_behavior.get('likes_given', 0)}
- Comments Made: {user_behavior.get('comments_made', 0)}
- Shares Made: {user_behavior.get('shares_made', 0)}
- Average Session Time: {user_behavior.get('avg_session_time', 0):.1f} minutes
"""
        
        # æ„å»ºå†…å®¹æŒ‡æ ‡æ‘˜è¦
        content_summary = f"""
Content Performance:
- Viral Posts: {content_metrics.get('viral_posts', 0)}
- Trending Topics: {content_metrics.get('trending_topics', 0)}
- Content Quality Score: {content_metrics.get('quality_score', 0):.2f}
- User Satisfaction: {content_metrics.get('satisfaction_score', 0):.2f}
"""
        
        # æ„å»ºå†å²å†³ç­–æ‘˜è¦
        history_summary = ""
        if self.decision_history:
            recent_decisions = self.decision_history[-5:]  # æœ€è¿‘5ä¸ªå†³ç­–
            history_summary = "\nRecent Decision History:\n"
            for record in recent_decisions:
                decision = record["decision"]
                history_summary += f"- Step {record['step']}: {decision['action']} - {decision.get('reasoning', 'No reasoning')}\n"
        
        # æ„å»ºå†å²è¡¨ç°æ‘˜è¦
        performance_summary = ""
        if self.user_history:
            recent_performance = self.user_history[-5:]  # æœ€è¿‘5ä¸ªè¡¨ç°è®°å½•
            performance_summary = "\nRecent Performance:\n"
            for record in recent_performance:
                performance_summary += f"- Step {record['step']}: Engagement Score = {record['engagement_score']:.3f}\n"
        
        # æ„å»ºå®Œæ•´æç¤º
        prompt = f"""
You are a social network strategy expert in a simulation game. This is NOT real social media management - it's a simulation game for testing AI strategies.

IMPORTANT: You MUST respond in ENGLISH only. Do NOT use Chinese or any other language.

Your goal is to maximize user engagement and network growth through strategic content and user interaction decisions.

Current Network State:
{chr(10).join(network_summary)}

{behavior_summary}

{content_summary}

{history_summary}

{performance_summary}

Based on the current state and history, you must make a specific decision to improve the social network. You can choose from these actions:

1. CREATE_POST - Create engaging content to increase user activity
2. ENCOURAGE_INTERACTION - Promote likes, comments, and shares
3. FEATURE_USER - Highlight active users to increase engagement
4. LAUNCH_CAMPAIGN - Start a viral marketing campaign
5. IMPROVE_ALGORITHM - Optimize content recommendation algorithm
6. ADD_FEATURE - Introduce new social features
7. MODERATE_CONTENT - Improve content quality and safety
8. EXPAND_NETWORK - Grow user base through targeted outreach

CRITICAL REQUIREMENTS:
- You MUST respond in ENGLISH only
- You MUST provide a specific action with clear reasoning
- No vague responses, no cautious strategies, no holding back
- This is a simulation game - be bold and specific!
- You MUST use the exact format below

REQUIRED FORMAT (copy and fill in):
ACTION: [specific action name from the list above]
TARGET: [specific target if applicable, or "N/A"]
REASONING: [clear explanation of why this action will improve the network]

Example response:
ACTION: CREATE_POST
TARGET: N/A
REASONING: The network has low content creation activity, creating engaging posts will increase user engagement and attract more active users.

What specific action will you take to improve this social network? Respond in the exact format above.

IMPORTANT: Your response must start with "ACTION:" and follow the exact format shown above. Do not provide any other analysis or explanation outside of this format.
"""
        
        return prompt
    
    def _parse_decision_response(self, response: str) -> Optional[Dict[str, Any]]:
        """è§£æLLMå†³ç­–å“åº”"""
        response = response.strip()
        
        print(f"ğŸ” è§£æå“åº”: {response[:200]}...")  # æ‰“å°å‰200ä¸ªå­—ç¬¦ç”¨äºè°ƒè¯•
        
        # å°è¯•è§£ææ ‡å‡†æ ¼å¼
        try:
            # æŸ¥æ‰¾ACTIONè¡Œ - ä½¿ç”¨æ›´å®½æ¾çš„æ­£åˆ™è¡¨è¾¾å¼
            action_patterns = [
                r'ACTION:\s*([A-Z_]+)',  # æ ‡å‡†æ ¼å¼
                r'action:\s*([A-Z_]+)',  # å°å†™
                r'Action:\s*([A-Z_]+)',  # é¦–å­—æ¯å¤§å†™
                r'ACTION\s*:\s*([A-Z_]+)',  # æ— å†’å·ç©ºæ ¼
                r'ACTION\s*=\s*([A-Z_]+)',  # ç­‰å·æ ¼å¼
            ]
            
            action = None
            for pattern in action_patterns:
                action_match = re.search(pattern, response, re.IGNORECASE)
                if action_match:
                    action = action_match.group(1).upper()
                    print(f"âœ… æ‰¾åˆ°ACTION: {action}")
                    break
            
            if not action:
                print("âŒ æœªæ‰¾åˆ°ACTIONå­—æ®µ")
                return None
            
            # æŸ¥æ‰¾TARGETè¡Œ - ä½¿ç”¨æ›´å®½æ¾çš„æ­£åˆ™è¡¨è¾¾å¼
            target_patterns = [
                r'TARGET:\s*(.+?)(?:\n|$)',  # æ ‡å‡†æ ¼å¼
                r'target:\s*(.+?)(?:\n|$)',  # å°å†™
                r'Target:\s*(.+?)(?:\n|$)',  # é¦–å­—æ¯å¤§å†™
                r'TARGET\s*:\s*(.+?)(?:\n|$)',  # æ— å†’å·ç©ºæ ¼
                r'TARGET\s*=\s*(.+?)(?:\n|$)',  # ç­‰å·æ ¼å¼
            ]
            
            target = "N/A"
            for pattern in target_patterns:
                target_match = re.search(pattern, response, re.IGNORECASE)
                if target_match:
                    target = target_match.group(1).strip()
                    print(f"âœ… æ‰¾åˆ°TARGET: {target}")
                    break
            
            # æŸ¥æ‰¾REASONINGè¡Œ - ä½¿ç”¨æ›´å®½æ¾çš„æ­£åˆ™è¡¨è¾¾å¼
            reasoning_patterns = [
                r'REASONING:\s*(.+?)(?:\n|$)',  # æ ‡å‡†æ ¼å¼
                r'reasoning:\s*(.+?)(?:\n|$)',  # å°å†™
                r'Reasoning:\s*(.+?)(?:\n|$)',  # é¦–å­—æ¯å¤§å†™
                r'REASONING\s*:\s*(.+?)(?:\n|$)',  # æ— å†’å·ç©ºæ ¼
                r'REASONING\s*=\s*(.+?)(?:\n|$)',  # ç­‰å·æ ¼å¼
            ]
            
            reasoning = "No reasoning provided"
            for pattern in reasoning_patterns:
                reasoning_match = re.search(pattern, response, re.IGNORECASE)
                if reasoning_match:
                    reasoning = reasoning_match.group(1).strip()
                    print(f"âœ… æ‰¾åˆ°REASONING: {reasoning[:50]}...")
                    break
            
            # éªŒè¯åŠ¨ä½œæ˜¯å¦æœ‰æ•ˆ
            valid_actions = [
                "CREATE_POST", "ENCOURAGE_INTERACTION", "FEATURE_USER", 
                "LAUNCH_CAMPAIGN", "IMPROVE_ALGORITHM", "ADD_FEATURE", 
                "MODERATE_CONTENT", "EXPAND_NETWORK"
            ]
            
            if action not in valid_actions:
                print(f"âŒ æ— æ•ˆçš„ACTION: {action}")
                return None
            
            print(f"âœ… è§£ææˆåŠŸ: {action} | {target} | {reasoning[:30]}...")
            
            return {
                "action": action,
                "target": target,
                "reasoning": reasoning
            }
            
        except Exception as e:
            print(f"âŒ Decision parsing failed: {e}")
            return None
    
    def _parse_decision_fallback(self, response: str) -> Optional[Dict[str, Any]]:
        """å¤‡ç”¨å†³ç­–è§£æé€»è¾‘"""
        # å°è¯•ä»å“åº”ä¸­æå–ä»»ä½•å¯èƒ½çš„åŠ¨ä½œ
        response_upper = response.upper()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä»»ä½•æœ‰æ•ˆåŠ¨ä½œ
        valid_actions = [
            "CREATE_POST", "ENCOURAGE_INTERACTION", "FEATURE_USER", 
            "LAUNCH_CAMPAIGN", "IMPROVE_ALGORITHM", "ADD_FEATURE", 
            "MODERATE_CONTENT", "EXPAND_NETWORK"
        ]
        
        for action in valid_actions:
            if action in response_upper:
                return {
                    "action": action,
                    "target": "N/A",
                    "reasoning": f"Extracted action '{action}' from response"
                }
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆåŠ¨ä½œï¼Œè¿”å›None
        return None


def create_rl_social_workflow(llm_manager) -> tuple[SG_Workflow, RLTrainer, LLMDecisionMaker]:
    """åˆ›å»ºåŸºäºRLçš„LLMå†³ç­–ç¤¾äº¤ç½‘ç»œå·¥ä½œæµ"""
    
    # åˆ›å»ºRLé…ç½®
    rl_config = RLConfig(
        algorithm=RLAlgorithm.PPO,
        learning_rate=3e-4,
        gamma=0.99,
        gae_lambda=0.95,
        clip_ratio=0.2,
        value_loss_coef=0.5,
        entropy_coef=0.01,
        max_grad_norm=0.5,
        batch_size=32,
        mini_batch_size=8,
        ppo_epochs=4,
        target_kl=0.01
    )
    
    # åˆ›å»ºRLè®­ç»ƒå™¨
    rl_trainer = RLTrainer(rl_config, llm_manager)
    
    # åˆ›å»ºLLMå†³ç­–å™¨
    decision_maker = LLMDecisionMaker(llm_manager)
    
    # åˆ›å»ºå·¥ä½œæµ
    workflow = SG_Workflow("rl_social_workflow", WorkflowMode.TRADITIONAL, llm_manager)
    
    # åˆ›å»ºç¤¾äº¤ç½‘ç»œæ²™ç›’
    sandbox = SocialNetworkSandbox(
        initial_users=100,
        max_users=1000
    )
    
    # åˆ›å»ºç¤¾äº¤ç½‘ç»œç¯å¢ƒèŠ‚ç‚¹
    def social_env_func(inputs: Dict[str, Any]) -> Dict[str, Any]:
        """ç¤¾äº¤ç½‘ç»œç¯å¢ƒèŠ‚ç‚¹å‡½æ•°"""
        # è·å–å½“å‰çŠ¶æ€
        case = sandbox.case_generator()
        current_state = case["state"]
        
        # ä½¿ç”¨LLMåšå‡ºå†³ç­–
        decision_result = decision_maker.make_decision(current_state)
        decision = decision_result["decision"]  # ä»ç»“æœä¸­æå–å†³ç­–
        
        # æ‰§è¡Œç¤¾äº¤ç½‘ç»œå†³ç­–
        try:
            # éªŒè¯å’Œæ‰§è¡Œå†³ç­–
            score = sandbox.verify_score(
                f"{decision['action']} {decision.get('target', '')}",
                case
            )
            
            # è®¡ç®—å¥–åŠ±
            reward = score * 10
            
            # æ„å»ºçŠ¶æ€ç‰¹å¾
            state_features = {
                "active_users": current_state["user_behavior"]["active_users"],
                "engagement_rate": _calculate_engagement_rate(current_state),
                "content_quality": current_state["content_metrics"]["quality_score"],
                "network_growth": _calculate_network_growth(current_state),
                "decision_type": _encode_decision_type(decision["action"])
            }
            
            # æ·»åŠ åˆ°RLè®­ç»ƒå™¨
            rl_trainer.add_experience(
                state=state_features,
                action=json.dumps(decision),
                reward=reward,
                done=False
            )
            
            # æ›´æ–°ç­–ç•¥
            update_result = rl_trainer.update_policy()
            
            return {
                "state": current_state,
                "decision": decision,
                "llm_response": decision_result["llm_response"],
                "score": score,
                "reward": reward,
                "rl_update": update_result,
                "sandbox_id": sandbox.sandbox_id
            }
            
        except Exception as e:
            print(f"ç¤¾äº¤ç½‘ç»œæ‰§è¡Œé”™è¯¯: {e}")
            return {
                "state": current_state,
                "decision": {"action": "CREATE_POST", "reasoning": f"æ‰§è¡Œé”™è¯¯: {e}"},
                "score": 0.0,
                "reward": 0.0,
                "error": str(e)
            }
    
    # æ·»åŠ ç¤¾äº¤ç½‘ç»œç¯å¢ƒèŠ‚ç‚¹
    social_env_node = EnhancedWorkflowNode(
        "social_environment",
        NodeType.SANDBOX,
        sandbox=sandbox,
        condition=NodeCondition(),
        limits=NodeLimits(max_visits=10, resource_cost={"energy": 10, "tokens": 5})
    )
    workflow.add_node(social_env_node)
    
    return workflow, rl_trainer, decision_maker


def _calculate_engagement_rate(state: Dict[str, Any]) -> float:
    """è®¡ç®—ç”¨æˆ·å‚ä¸ç‡"""
    user_behavior = state.get("user_behavior", {})
    active_users = user_behavior.get("active_users", 0)
    total_users = len(state.get("network_state", {}))
    
    if total_users == 0:
        return 0.0
    
    return active_users / total_users


def _calculate_network_growth(state: Dict[str, Any]) -> float:
    """è®¡ç®—ç½‘ç»œå¢é•¿ç‡"""
    network_state = state.get("network_state", {})
    total_users = len(network_state)
    
    # åŸºäºç”¨æˆ·æ•°é‡å’Œè¿æ¥åº¦è®¡ç®—å¢é•¿ç‡
    total_connections = 0
    for user_data in network_state.values():
        total_connections += user_data.get("followers", 0) + user_data.get("following", 0)
    
    if total_users == 0:
        return 0.0
    
    avg_connections = total_connections / total_users
    return min(1.0, avg_connections / 100.0)  # å½’ä¸€åŒ–


def _encode_decision_type(action: str) -> int:
    """ç¼–ç å†³ç­–ç±»å‹"""
    action_map = {
        "CREATE_POST": 1,
        "ENCOURAGE_INTERACTION": 2,
        "FEATURE_USER": 3,
        "LAUNCH_CAMPAIGN": 4,
        "IMPROVE_ALGORITHM": 5,
        "ADD_FEATURE": 6,
        "MODERATE_CONTENT": 7,
        "EXPAND_NETWORK": 8
    }
    return action_map.get(action, 0)


def run_rl_social_demo(steps: int = 5, model_name: str = "mistralai/Mistral-7B-Instruct-v0.2"):
    """è¿è¡ŒåŸºäºRLçš„LLMå†³ç­–ç¤¾äº¤ç½‘ç»œæ¼”ç¤º"""
    
    print_section("RL-based LLM Decision Social Network Demo")
    
    # 1. åˆ›å»ºLLMç®¡ç†å™¨
    print(f"\n1. Creating LLM Manager with model: {model_name}")
    llm_manager = create_shared_llm_manager(
        model_name=model_name,
        backend="huggingface",
        temperature=0.7,
        max_length=512,
        device="auto",
        torch_dtype="float16"
    )
    
    # 2. åˆ›å»ºå·¥ä½œæµå’ŒRLè®­ç»ƒå™¨
    print("\n2. Creating RL Social Network Workflow")
    workflow, rl_trainer, decision_maker = create_rl_social_workflow(llm_manager)
    
    # 3. æ‰§è¡Œå¤šæ­¥ç¤¾äº¤ç½‘ç»œç®¡ç†
    print(f"\n3. Executing {steps} Social Network Management Steps")
    
    results = []
    for step in range(steps):
        print(f"\n--- ç¬¬ {step + 1} æ­¥ ---")
        
        try:
            # ç›´æ¥æ‰§è¡Œç¤¾äº¤ç½‘ç»œç¯å¢ƒèŠ‚ç‚¹
            node = workflow.nodes.get("social_environment")
            if node and node.sandbox:
                # è·å–å½“å‰çŠ¶æ€
                case = node.sandbox.case_generator()
                current_state = case["state"]
                
                # ä½¿ç”¨LLMåšå‡ºå†³ç­–
                decision_result = decision_maker.make_decision(current_state)
                decision = decision_result["decision"]  # ä»ç»“æœä¸­æå–å†³ç­–
                
                # æ‰§è¡Œç¤¾äº¤ç½‘ç»œå†³ç­–
                try:
                    # éªŒè¯å’Œæ‰§è¡Œå†³ç­–
                    score = node.sandbox.verify_score(
                        f"{decision['action']} {decision.get('target', '')}",
                        case
                    )
                    
                    # è®¡ç®—å¥–åŠ±
                    reward = score * 10
                    
                    # æ„å»ºçŠ¶æ€ç‰¹å¾
                    state_features = {
                        "active_users": current_state["user_behavior"]["active_users"],
                        "engagement_rate": _calculate_engagement_rate(current_state),
                        "content_quality": current_state["content_metrics"]["quality_score"],
                        "network_growth": _calculate_network_growth(current_state),
                        "decision_type": _encode_decision_type(decision["action"])
                    }
                    
                    # æ·»åŠ åˆ°RLè®­ç»ƒå™¨
                    rl_trainer.add_experience(
                        state=state_features,
                        action=json.dumps(decision),
                        reward=reward,
                        done=False
                    )
                    
                    # æ›´æ–°ç­–ç•¥
                    update_result = rl_trainer.update_policy()
                    
                    result = {
                        "step": step + 1,
                        "state": current_state,
                        "decision": decision,
                        "llm_response": decision_result["llm_response"],
                        "score": score,
                        "reward": reward,
                        "rl_update": update_result
                    }
                    
                    results.append(result)
                    
                    # æ‰“å°ç»“æœ
                    print(f"Decision: {decision['action']}")
                    print(f"Target: {decision.get('target', 'N/A')}")
                    print(f"Reasoning: {decision['reasoning']}")
                    print(f"Score: {score:.2f}")
                    print(f"Reward: {reward:.2f}")
                    print(f"Active Users: {current_state['user_behavior']['active_users']}")
                    print(f"Engagement Rate: {_calculate_engagement_rate(current_state):.3f}")
                    
                except Exception as e:
                    print(f"æ‰§è¡Œé”™è¯¯: {e}")
                    result = {
                        "step": step + 1,
                        "error": str(e),
                        "decision": {"action": "CREATE_POST", "reasoning": f"æ‰§è¡Œé”™è¯¯: {e}"}
                    }
                    results.append(result)
            
        except Exception as e:
            print(f"æ­¥éª¤ {step + 1} æ‰§è¡Œå¤±è´¥: {e}")
            result = {
                "step": step + 1,
                "error": str(e)
            }
            results.append(result)
    
    # 4. æ˜¾ç¤ºæœ€ç»ˆç»“æœ
    print_section("Final Results")
    
    successful_steps = [r for r in results if "error" not in r]
    if successful_steps:
        avg_score = sum(r["score"] for r in successful_steps) / len(successful_steps)
        avg_reward = sum(r["reward"] for r in successful_steps) / len(successful_steps)
        final_engagement = _calculate_engagement_rate(successful_steps[-1]["state"])
        
        print(f"Average Score: {avg_score:.2f}")
        print(f"Average Reward: {avg_reward:.2f}")
        print(f"Final Engagement Rate: {final_engagement:.3f}")
        print(f"Successful Steps: {len(successful_steps)}/{steps}")
    
    # 5. æ˜¾ç¤ºRLè®­ç»ƒç»Ÿè®¡
    print_section("RL Training Statistics")
    training_stats = rl_trainer.get_training_stats()
    print(f"Training Steps: {training_stats['training_step']}")
    print(f"Algorithm: {training_stats['algorithm']}")
    print(f"Recent Updates: {len(training_stats['recent_updates'])}")
    
    return results


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="SandGraph Social Network Demo")
    parser.add_argument("--steps", type=int, default=5, help="Number of steps to run")
    parser.add_argument("--model", type=str, default="mistralai/Mistral-7B-Instruct-v0.2", help="LLM model to use")
    
    args = parser.parse_args()
    
    print("ğŸ”¥ SandGraph Social Network Demo")
    print("=" * 60)
    print(f"Steps: {args.steps}")
    print(f"Model: {args.model}")
    
    # æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
    supported_models = [
        "Qwen/Qwen-7B-Chat",
        "Qwen/Qwen-1_8B-Chat", 
        "microsoft/Phi-2",
        "google/gemma-2b-it",
        "01-ai/Yi-6B-Chat",
        "mistralai/Mistral-7B-Instruct-v0.2",
        "THUDM/chatglm3-6b",
        "baichuan-inc/Baichuan2-7B-Chat"
    ]
    
    if args.model not in supported_models:
        print(f"\nâš ï¸  Warning: Model {args.model} not in supported list.")
        print(f"Supported models: {', '.join(supported_models)}")
        print("Continuing anyway...")
    
    try:
        results = run_rl_social_demo(args.steps, args.model)
        print("\nâœ… Demo completed successfully!")
        
    except Exception as e:
        print(f"\nâŒ Demo failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 