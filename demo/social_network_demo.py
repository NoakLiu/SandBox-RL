#!/usr/bin/env python3
"""
Sandbox-RL ç¤¾äº¤ç½‘ç»œç¯å¢ƒæ¼”ç¤º - åŸºäºRLçš„LLMå†³ç­–æ¶æ„

æ–°çš„æ¶æ„è®¾è®¡ï¼š
1. Sandboxä½œä¸ºç¯å¢ƒèŠ‚ç‚¹
2. LLMä½œä¸ºå†³ç­–å™¨ï¼ˆä¸æ˜¯èŠ‚ç‚¹ï¼‰
3. RLç®—æ³•æ›´æ–°LLMæƒé‡
4. çŠ¶æ€è½¬ç§»ç”±LLMå†³ç­–é©±åŠ¨
"""

import sys
import os
import time
import json
import argparse
import random
import re
from typing import Dict, Any, List, Union, Optional
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from sandbox_rl.core.llm_interface import create_shared_llm_manager
from sandbox_rl.core.sg_workflow import (
    SG_Workflow, WorkflowMode, EnhancedWorkflowNode,
    NodeType, NodeCondition, NodeLimits, GameState
)
from sandbox_rl.core.rl_algorithms import RLTrainer, RLConfig, RLAlgorithm
from sandbox_rl.sandbox_implementations import SocialNetworkSandbox


def print_section(title: str):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print(f"\n{'='*60}")
    print(f" {title}")
    print(f"{'='*60}")


class LLMDecisionMaker:
    """LLMå†³ç­–å™¨ - ä¸æ˜¯èŠ‚ç‚¹ï¼Œè€Œæ˜¯å†³ç­–å¼•æ“"""
    
    def __init__(self, llm_manager):
        self.llm_manager = llm_manager
        self.decision_count = 0
        
        # å†å²æ•°æ®ç®¡ç†
        self.decision_history = []  # å†³ç­–å†å²
        self.network_history = []   # ç½‘ç»œçŠ¶æ€å†å²
        self.user_history = []      # ç”¨æˆ·è¡Œä¸ºå†å²
        self.performance_history = [] # è¡¨ç°å†å²
        
        # æ³¨å†Œå†³ç­–èŠ‚ç‚¹
        self.llm_manager.register_node("social_decision", {
            "role": "ç¤¾äº¤ç½‘ç»œç­–ç•¥ä¸“å®¶",
            "reasoning_type": "strategic",
            "temperature": 0.7,
            "max_length": 512
        })
    
    def make_decision(self, current_state: Dict[str, Any]) -> Dict[str, Any]:
        """åŸºäºå½“å‰çŠ¶æ€åšå‡ºå†³ç­–"""
        self.decision_count += 1
        
        # æ„å»ºå†³ç­–æç¤º
        prompt = self._construct_decision_prompt(current_state)
        
        print("=" * 80)
        print(f"Decision {self.decision_count} - Complete Prompt Content:")
        print("=" * 80)
        print(prompt)
        print("=" * 80)
        
        try:
            # ç”ŸæˆLLMå“åº” - æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯å¼ºåˆ¶æ ¼å¼
            system_message = """You are a social network strategy expert. You MUST respond with EXACTLY 3 lines in this format:
ACTION: [ACTION_NAME]
TARGET: [TARGET_VALUE] 
REASONING: [REASONING_TEXT]

Do not add any other text, explanations, or formatting. Only the 3 lines above."""
            
            response = self.llm_manager.generate_for_node(
                "social_decision",
                prompt,
                temperature=0.3,  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ä¸€è‡´çš„æ ¼å¼
                max_new_tokens=128,  # å‡å°‘tokenæ•°é‡
                do_sample=True,
                system_message=system_message
            )
            
            print(f"LLM Response Status: {response.status if hasattr(response, 'status') else 'unknown'}")
            print(f"LLM Complete Response: {response.text}")
            
            # è§£æå“åº”
            decision = self._parse_decision_response(response.text)
            
            # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨æ›´å®½æ¾çš„è§£æ
            if decision is None:
                decision = self._parse_decision_fallback(response.text)
            
            # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å†³ç­–
            if decision is None:
                decision = {
                    "action": "CREATE_POST",
                    "target": "N/A",
                    "reasoning": "Fallback decision due to parsing failure"
                }
            
            # æ›´æ–°å†å²æ•°æ®
            self._update_history(current_state, decision, response.text)
            
            return {
                "decision": decision,
                "llm_response": response.text,
                "prompt": prompt,
                "decision_count": self.decision_count
            }
            
        except Exception as e:
            print(f"âŒ Decision generation failed: {e}")
            fallback_decision = {
                "action": "CREATE_POST",
                "target": "N/A", 
                "reasoning": f"Error in decision generation: {str(e)}"
            }
            
            # æ›´æ–°å†å²æ•°æ®ï¼ˆå³ä½¿å¤±è´¥ï¼‰
            self._update_history(current_state, fallback_decision, f"Error: {str(e)}")
            
            return {
                "decision": fallback_decision,
                "llm_response": f"Error: {str(e)}",
                "prompt": prompt,
                "decision_count": self.decision_count
            }
    
    def _update_history(self, state: Dict[str, Any], decision: Dict[str, Any], llm_response: str):
        """æ›´æ–°å†å²æ•°æ®"""
        # è®°å½•å†³ç­–å†å²
        decision_record = {
            "step": self.decision_count,
            "timestamp": datetime.now().isoformat(),
            "decision": decision,
            "llm_response": llm_response,
            "network_state": state.get("network_state", {}),
            "user_behavior": state.get("user_behavior", {}),
            "content_metrics": state.get("content_metrics", {})
        }
        self.decision_history.append(decision_record)
        
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
        if len(self.decision_history) > 50:
            self.decision_history = self.decision_history[-50:]
        
        # è®°å½•ç½‘ç»œçŠ¶æ€å†å²
        network_record = {
            "step": self.decision_count,
            "network_state": state.get("network_state", {}),
            "user_behavior": state.get("user_behavior", {})
        }
        self.network_history.append(network_record)
        
        # è®°å½•ç”¨æˆ·è¡Œä¸ºå†å²
        user_record = {
            "step": self.decision_count,
            "user_behavior": state.get("user_behavior", {}),
            "engagement_score": self._calculate_engagement_score(state)
        }
        self.user_history.append(user_record)
        
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
        if len(self.network_history) > 30:
            self.network_history = self.network_history[-30:]
        if len(self.user_history) > 30:
            self.user_history = self.user_history[-30:]
    
    def _calculate_engagement_score(self, state: Dict[str, Any]) -> float:
        """è®¡ç®—ç”¨æˆ·å‚ä¸åº¦åˆ†æ•°"""
        user_behavior = state.get("user_behavior", {})
        
        # è®¡ç®—å„ç§å‚ä¸åº¦æŒ‡æ ‡
        total_posts = user_behavior.get("posts_created", 0)
        total_likes = user_behavior.get("likes_given", 0)
        total_comments = user_behavior.get("comments_made", 0)
        total_shares = user_behavior.get("shares_made", 0)
        active_users = user_behavior.get("active_users", 0)
        
        # ç»¼åˆå‚ä¸åº¦åˆ†æ•°
        engagement_score = (
            total_posts * 0.3 +
            total_likes * 0.2 +
            total_comments * 0.3 +
            total_shares * 0.2
        ) * (active_users / 100.0)  # å½’ä¸€åŒ–
        
        return min(1.0, engagement_score)
    
    def _construct_decision_prompt(self, state: Dict[str, Any]) -> str:
        """æ„é€ å†³ç­–æç¤ºï¼ˆåŒ…å«å†å²æ•°æ®ï¼‰"""
        network_state = state.get("network_state", {})
        user_behavior = state.get("user_behavior", {})
        content_metrics = state.get("content_metrics", {})
        network_dynamics = state.get("network_dynamics", {})
        
        # æ„å»ºç½‘ç»œçŠ¶æ€æ‘˜è¦
        network_summary = []
        for user_id, user_data in network_state.items():
            network_summary.append(
                f"User {user_id}: "
                f"Followers={user_data.get('followers', 0)}, "
                f"Following={user_data.get('following', 0)}, "
                f"Posts={user_data.get('posts', 0)}, "
                f"Engagement={user_data.get('engagement_rate', 0):.2f}%"
            )
        
        # æ„å»ºç”¨æˆ·è¡Œä¸ºæ‘˜è¦
        behavior_summary = f"""
Current User Behavior:
- Active Users: {user_behavior.get('active_users', 0)}
- Posts Created: {user_behavior.get('posts_created', 0)}
- Likes Given: {user_behavior.get('likes_given', 0)}
- Comments Made: {user_behavior.get('comments_made', 0)}
- Shares Made: {user_behavior.get('shares_made', 0)}
- Average Session Time: {user_behavior.get('avg_session_time', 0):.1f} minutes
- Bounce Rate: {user_behavior.get('bounce_rate', 0):.2f}
- Retention Rate: {user_behavior.get('retention_rate', 0):.2f}
"""
        
        # æ„å»ºå†…å®¹æŒ‡æ ‡æ‘˜è¦
        content_summary = f"""
Content Performance:
- Viral Posts: {content_metrics.get('viral_posts', 0)}
- Trending Topics: {content_metrics.get('trending_topics', 0)}
- Content Quality Score: {content_metrics.get('quality_score', 0):.2f}
- User Satisfaction: {content_metrics.get('satisfaction_score', 0):.2f}
- Content Diversity: {content_metrics.get('diversity_score', 0):.2f}
- Controversy Level: {content_metrics.get('controversy_level', 0):.2f}
"""
        
        # æ„å»ºç½‘ç»œåŠ¨æ€æ‘˜è¦
        dynamics_summary = f"""
Network Dynamics:
- Network Mood: {network_dynamics.get('mood', 0):.2f} (-1=Negative, 1=Positive)
- Competition Level: {network_dynamics.get('competition_level', 0):.2f}
- Innovation Rate: {network_dynamics.get('innovation_rate', 0):.2f}
- Crisis Level: {network_dynamics.get('crisis_level', 0):.2f}
"""
        
        # æ„å»ºå†å²å†³ç­–æ‘˜è¦
        history_summary = ""
        if self.decision_history:
            recent_decisions = self.decision_history[-5:]  # æœ€è¿‘5ä¸ªå†³ç­–
            history_summary = "\nRecent Decision History:\n"
            for record in recent_decisions:
                decision = record["decision"]
                history_summary += f"- Step {record['step']}: {decision['action']} - {decision.get('reasoning', 'No reasoning')}\n"
        
        # æ„å»ºå†å²è¡¨ç°æ‘˜è¦
        performance_summary = ""
        if self.user_history:
            recent_performance = self.user_history[-5:]  # æœ€è¿‘5ä¸ªè¡¨ç°è®°å½•
            performance_summary = "\nRecent Performance:\n"
            for record in recent_performance:
                performance_summary += f"- Step {record['step']}: Engagement Score = {record['engagement_score']:.3f}\n"
        
        # æ„å»ºç­–ç•¥å»ºè®®
        strategy_advice = self._generate_strategy_advice(state)
        
        # é‡æ„åçš„å¢å¼ºæç¤º - æ›´ä¸¥æ ¼çš„æ ¼å¼è¦æ±‚
        prompt = f"""You are a social network strategy expert. You MUST respond with EXACTLY 3 lines:

ACTION: [CREATE_POST|ENCOURAGE_INTERACTION|FEATURE_USER|LAUNCH_CAMPAIGN|IMPROVE_ALGORITHM|ADD_FEATURE|MODERATE_CONTENT|EXPAND_NETWORK]
TARGET: [specific target or "N/A"]
REASONING: [brief explanation]

Current State:
- Active Users: {user_behavior.get('active_users', 0)}
- Posts Created: {user_behavior.get('posts_created', 0)}
- Content Quality: {content_metrics.get('quality_score', 0):.2f}
- Network Mood: {network_dynamics.get('mood', 0):.2f}
- Crisis Level: {network_dynamics.get('crisis_level', 0):.2f}
- Bounce Rate: {user_behavior.get('bounce_rate', 0):.2f}

Strategy Guidelines:
- Negative mood â†’ LAUNCH_CAMPAIGN or ENCOURAGE_INTERACTION
- High crisis â†’ MODERATE_CONTENT or LAUNCH_CAMPAIGN  
- Low innovation â†’ ADD_FEATURE or IMPROVE_ALGORITHM
- High controversy â†’ MODERATE_CONTENT
- High bounce rate â†’ IMPROVE_ALGORITHM

Respond with EXACTLY 3 lines in the format above. No other text."""
        
        return prompt
    
    def _generate_strategy_advice(self, state: Dict[str, Any]) -> str:
        """æ ¹æ®å½“å‰çŠ¶æ€ç”Ÿæˆç­–ç•¥å»ºè®®"""
        network_dynamics = state.get("network_dynamics", {})
        user_behavior = state.get("user_behavior", {})
        content_metrics = state.get("content_metrics", {})
        
        advice = []
        
        # åŸºäºç½‘ç»œæƒ…ç»ªçš„å»ºè®®
        mood = network_dynamics.get("mood", 0)
        if mood < -0.3:
            advice.append("âš ï¸ Network mood is negative - consider LAUNCH_CAMPAIGN or ENCOURAGE_INTERACTION to boost morale")
        elif mood > 0.3:
            advice.append("âœ… Network mood is positive - good time for EXPAND_NETWORK or ADD_FEATURE")
        
        # åŸºäºå±æœºç¨‹åº¦çš„å»ºè®®
        crisis_level = network_dynamics.get("crisis_level", 0)
        if crisis_level > 0.4:
            advice.append("ğŸš¨ Crisis detected - prioritize MODERATE_CONTENT or LAUNCH_CAMPAIGN to address issues")
        
        # åŸºäºäº‰è®®ç¨‹åº¦çš„å»ºè®®
        controversy_level = content_metrics.get("controversy_level", 0)
        if controversy_level > 0.4:
            advice.append("âš ï¸ High controversy - use MODERATE_CONTENT to control the situation")
        
        # åŸºäºåˆ›æ–°ç‡çš„å»ºè®®
        innovation_rate = network_dynamics.get("innovation_rate", 0)
        if innovation_rate < 0.3:
            advice.append("ğŸ’¡ Low innovation - consider ADD_FEATURE or IMPROVE_ALGORITHM to drive innovation")
        
        # åŸºäºç”¨æˆ·ä½“éªŒçš„å»ºè®®
        bounce_rate = user_behavior.get("bounce_rate", 0)
        if bounce_rate > 0.5:
            advice.append("ğŸ“‰ High bounce rate - use IMPROVE_ALGORITHM to improve user experience")
        
        # åŸºäºå†…å®¹è´¨é‡çš„å»ºè®®
        quality_score = content_metrics.get("quality_score", 0)
        if quality_score < 0.6:
            advice.append("ğŸ“ Low content quality - consider CREATE_POST or IMPROVE_ALGORITHM")
        
        # åŸºäºç”¨æˆ·å‚ä¸çš„å»ºè®®
        active_users = user_behavior.get("active_users", 0)
        if active_users < 50:
            advice.append("ğŸ‘¥ Low active users - consider FEATURE_USER or ENCOURAGE_INTERACTION")
        
        if not advice:
            advice.append("âœ… Network is stable - any action can help maintain growth")
        
        return "\n".join(advice)
    
    def _parse_decision_response(self, response: str) -> Optional[Dict[str, Any]]:
        """è§£æLLMå†³ç­–å“åº”"""
        response = response.strip()
        
        print(f"ğŸ” è§£æå“åº”: {response[:200]}...")  # æ‰“å°å‰200ä¸ªå­—ç¬¦ç”¨äºè°ƒè¯•
        
        # å°è¯•è§£ææ ‡å‡†æ ¼å¼
        try:
            # æŸ¥æ‰¾ACTIONè¡Œ - ä½¿ç”¨æ›´å®½æ¾çš„æ­£åˆ™è¡¨è¾¾å¼
            action_patterns = [
                r'ACTION:\s*([A-Z_]+)',  # æ ‡å‡†æ ¼å¼
                r'action:\s*([A-Z_]+)',  # å°å†™
                r'Action:\s*([A-Z_]+)',  # é¦–å­—æ¯å¤§å†™
                r'ACTION\s*:\s*([A-Z_]+)',  # æ— å†’å·ç©ºæ ¼
                r'ACTION\s*=\s*([A-Z_]+)',  # ç­‰å·æ ¼å¼
                r'^([A-Z_]+)\s*$',  # å•ç‹¬ä¸€è¡Œ
            ]
            
            action = None
            for pattern in action_patterns:
                action_match = re.search(pattern, response, re.IGNORECASE | re.MULTILINE)
                if action_match:
                    action = action_match.group(1).upper()
                    print(f"âœ… æ‰¾åˆ°ACTION: {action}")
                    break
            
            if not action:
                print("âŒ æœªæ‰¾åˆ°ACTIONå­—æ®µ")
                return None
            
            # æŸ¥æ‰¾TARGETè¡Œ - ä½¿ç”¨æ›´å®½æ¾çš„æ­£åˆ™è¡¨è¾¾å¼
            target_patterns = [
                r'TARGET:\s*(.+?)(?:\n|$)',  # æ ‡å‡†æ ¼å¼
                r'target:\s*(.+?)(?:\n|$)',  # å°å†™
                r'Target:\s*(.+?)(?:\n|$)',  # é¦–å­—æ¯å¤§å†™
                r'TARGET\s*:\s*(.+?)(?:\n|$)',  # æ— å†’å·ç©ºæ ¼
                r'TARGET\s*=\s*(.+?)(?:\n|$)',  # ç­‰å·æ ¼å¼
            ]
            
            target = "N/A"
            for pattern in target_patterns:
                target_match = re.search(pattern, response, re.IGNORECASE | re.MULTILINE)
                if target_match:
                    target = target_match.group(1).strip()
                    print(f"âœ… æ‰¾åˆ°TARGET: {target}")
                    break
            
            # æŸ¥æ‰¾REASONINGè¡Œ - ä½¿ç”¨æ›´å®½æ¾çš„æ­£åˆ™è¡¨è¾¾å¼
            reasoning_patterns = [
                r'REASONING:\s*(.+?)(?:\n|$)',  # æ ‡å‡†æ ¼å¼
                r'reasoning:\s*(.+?)(?:\n|$)',  # å°å†™
                r'Reasoning:\s*(.+?)(?:\n|$)',  # é¦–å­—æ¯å¤§å†™
                r'REASONING\s*:\s*(.+?)(?:\n|$)',  # æ— å†’å·ç©ºæ ¼
                r'REASONING\s*=\s*(.+?)(?:\n|$)',  # ç­‰å·æ ¼å¼
            ]
            
            reasoning = "No reasoning provided"
            for pattern in reasoning_patterns:
                reasoning_match = re.search(pattern, response, re.IGNORECASE | re.MULTILINE)
                if reasoning_match:
                    reasoning = reasoning_match.group(1).strip()
                    print(f"âœ… æ‰¾åˆ°REASONING: {reasoning[:50]}...")
                    break
            
            # éªŒè¯åŠ¨ä½œæ˜¯å¦æœ‰æ•ˆ
            valid_actions = [
                "CREATE_POST", "ENCOURAGE_INTERACTION", "FEATURE_USER", 
                "LAUNCH_CAMPAIGN", "IMPROVE_ALGORITHM", "ADD_FEATURE", 
                "MODERATE_CONTENT", "EXPAND_NETWORK"
            ]
            
            if action not in valid_actions:
                print(f"âŒ æ— æ•ˆçš„ACTION: {action}")
                return None
            
            print(f"âœ… è§£ææˆåŠŸ: {action} | {target} | {reasoning[:30]}...")
            
            return {
                "action": action,
                "target": target,
                "reasoning": reasoning
            }
            
        except Exception as e:
            print(f"âŒ Decision parsing failed: {e}")
            return None
    
    def _parse_decision_fallback(self, response: str) -> Optional[Dict[str, Any]]:
        """å¤‡ç”¨å†³ç­–è§£æé€»è¾‘"""
        # å°è¯•ä»å“åº”ä¸­æå–ä»»ä½•å¯èƒ½çš„åŠ¨ä½œ
        response_upper = response.upper()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä»»ä½•æœ‰æ•ˆåŠ¨ä½œ
        valid_actions = [
            "CREATE_POST", "ENCOURAGE_INTERACTION", "FEATURE_USER", 
            "LAUNCH_CAMPAIGN", "IMPROVE_ALGORITHM", "ADD_FEATURE", 
            "MODERATE_CONTENT", "EXPAND_NETWORK"
        ]
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºåŠ¨ä½œï¼ˆåŸºäºå½“å‰çŠ¶æ€ï¼‰
        action_priority = []
        for action in valid_actions:
            if action in response_upper:
                action_priority.append(action)
        
        if action_priority:
            # é€‰æ‹©ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„åŠ¨ä½œ
            selected_action = action_priority[0]
            
            # å°è¯•ä»å“åº”ä¸­æå–ä¸€äº›ä¸Šä¸‹æ–‡ä½œä¸ºæ¨ç†
            reasoning = "Action extracted from response"
            
            # æŸ¥æ‰¾åŒ…å«åŠ¨ä½œçš„å¥å­
            sentences = response.split('.')
            for sentence in sentences:
                if selected_action.lower().replace('_', ' ') in sentence.lower():
                    reasoning = sentence.strip()
                    break
            
            return {
                "action": selected_action,
                "target": "N/A",
                "reasoning": reasoning[:100] + "..." if len(reasoning) > 100 else reasoning
            }
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆåŠ¨ä½œï¼Œè¿”å›None
        return None


def create_rl_social_workflow(llm_manager) -> tuple[SG_Workflow, RLTrainer, LLMDecisionMaker]:
    """åˆ›å»ºåŸºäºRLçš„LLMå†³ç­–ç¤¾äº¤ç½‘ç»œå·¥ä½œæµ"""
    
    # åˆ›å»ºRLé…ç½® - å‡å°batch sizeä»¥åœ¨å°‘é‡æ­¥éª¤åå¼€å§‹è®­ç»ƒ
    rl_config = RLConfig(
        algorithm=RLAlgorithm.PPO,
        learning_rate=3e-4,
        gamma=0.99,
        gae_lambda=0.95,
        clip_ratio=0.2,
        value_loss_coef=0.5,
        entropy_coef=0.01,
        max_grad_norm=0.5,
        batch_size=4,  # ä»32å‡å°åˆ°4
        mini_batch_size=2,  # ä»8å‡å°åˆ°2
        ppo_epochs=2,  # ä»4å‡å°åˆ°2
        target_kl=0.01
    )
    
    # åˆ›å»ºRLè®­ç»ƒå™¨
    rl_trainer = RLTrainer(rl_config, llm_manager)
    
    # åˆ›å»ºLLMå†³ç­–å™¨
    decision_maker = LLMDecisionMaker(llm_manager)
    
    # åˆ›å»ºå·¥ä½œæµ
    workflow = SG_Workflow("rl_social_workflow", WorkflowMode.TRADITIONAL, llm_manager)
    
    # åˆ›å»ºç¤¾äº¤ç½‘ç»œæ²™ç›’
    sandbox = SocialNetworkSandbox(
        initial_users=100,
        max_users=1000
    )
    
    # åˆ›å»ºç¤¾äº¤ç½‘ç»œç¯å¢ƒèŠ‚ç‚¹
    def social_env_func(inputs: Dict[str, Any]) -> Dict[str, Any]:
        """ç¤¾äº¤ç½‘ç»œç¯å¢ƒèŠ‚ç‚¹å‡½æ•°"""
        # è·å–å½“å‰çŠ¶æ€
        case = sandbox.case_generator()
        current_state = case["state"]
        
        # ä½¿ç”¨LLMåšå‡ºå†³ç­–
        decision_result = decision_maker.make_decision(current_state)
        decision = decision_result["decision"]  # ä»ç»“æœä¸­æå–å†³ç­–
        
        # æ‰§è¡Œç¤¾äº¤ç½‘ç»œå†³ç­–
        try:
            # éªŒè¯å’Œæ‰§è¡Œå†³ç­–
            score = sandbox.verify_score(
                f"{decision['action']} {decision.get('target', '')}",
                case
            )
            
            # è®¡ç®—å¥–åŠ±
            reward = score * 10
            
            # æ„å»ºçŠ¶æ€ç‰¹å¾
            state_features = {
                "active_users": current_state["user_behavior"]["active_users"],
                "engagement_rate": _calculate_engagement_rate(current_state),
                "content_quality": current_state["content_metrics"]["quality_score"],
                "network_growth": _calculate_network_growth(current_state),
                "decision_type": _encode_decision_type(decision["action"])
            }
            
            # æ·»åŠ åˆ°RLè®­ç»ƒå™¨
            rl_trainer.add_experience(
                state=state_features,
                action=json.dumps(decision),
                reward=reward,
                done=False
            )
            
            # æ›´æ–°ç­–ç•¥
            update_result = rl_trainer.update_policy()
            
            # æ˜¾ç¤ºRLæ›´æ–°çŠ¶æ€
            print(f"RL Update Status: {update_result.get('status', 'unknown')}")
            if update_result.get('status') == 'insufficient_data':
                print(f"  Trajectory Count: {update_result.get('trajectory_count', 0)}")
                print(f"  Required Batch Size: {update_result.get('required_batch_size', 0)}")
            elif update_result.get('status') == 'updated':
                print(f"  Training Step: {update_result.get('training_step', 0)}")
                print(f"  Algorithm: {update_result.get('algorithm', 'unknown')}")
            
            return {
                "state": current_state,
                "decision": decision,
                "llm_response": decision_result["llm_response"],
                "score": score,
                "reward": reward,
                "rl_update": update_result,
                "sandbox_id": sandbox.sandbox_id
            }
            
        except Exception as e:
            print(f"ç¤¾äº¤ç½‘ç»œæ‰§è¡Œé”™è¯¯: {e}")
            return {
                "state": current_state,
                "decision": {"action": "CREATE_POST", "reasoning": f"æ‰§è¡Œé”™è¯¯: {e}"},
                "score": 0.0,
                "reward": 0.0,
                "error": str(e)
            }
    
    # æ·»åŠ ç¤¾äº¤ç½‘ç»œç¯å¢ƒèŠ‚ç‚¹
    social_env_node = EnhancedWorkflowNode(
        "social_environment",
        NodeType.SANDBOX,
        sandbox=sandbox,
        condition=NodeCondition(),
        limits=NodeLimits(max_visits=10, resource_cost={"energy": 10, "tokens": 5})
    )
    workflow.add_node(social_env_node)
    
    return workflow, rl_trainer, decision_maker


def _calculate_engagement_rate(state: Dict[str, Any]) -> float:
    """è®¡ç®—ç”¨æˆ·å‚ä¸ç‡"""
    user_behavior = state.get("user_behavior", {})
    network_state = state.get("network_state", {})
    
    # è·å–åŸºç¡€æ•°æ®
    active_users = user_behavior.get("active_users", 0)
    total_users = len(network_state)
    
    if total_users == 0:
        return 0.0
    
    # è®¡ç®—åŸºç¡€å‚ä¸ç‡
    base_engagement = active_users / total_users
    
    # è€ƒè™‘ç”¨æˆ·è¡Œä¸ºè´¨é‡
    posts_created = user_behavior.get("posts_created", 0)
    likes_given = user_behavior.get("likes_given", 0)
    comments_made = user_behavior.get("comments_made", 0)
    shares_made = user_behavior.get("shares_made", 0)
    
    # è®¡ç®—äº’åŠ¨è´¨é‡åˆ†æ•°
    total_interactions = posts_created + likes_given + comments_made + shares_made
    interaction_quality = min(1.0, total_interactions / (total_users * 10))  # æ¯ä¸ªç”¨æˆ·å¹³å‡10æ¬¡äº’åŠ¨ä¸ºæ»¡åˆ†
    
    # è€ƒè™‘ä¼šè¯æ—¶é—´å’Œç•™å­˜ç‡
    avg_session_time = user_behavior.get("avg_session_time", 0)
    retention_rate = user_behavior.get("retention_rate", 0)
    bounce_rate = user_behavior.get("bounce_rate", 0)
    
    # ä¼šè¯è´¨é‡åˆ†æ•°
    session_quality = min(1.0, avg_session_time / 30.0)  # 30åˆ†é’Ÿä¸ºæ»¡åˆ†
    
    # ç•™å­˜è´¨é‡åˆ†æ•°
    retention_quality = retention_rate * (1 - bounce_rate)
    
    # ç»¼åˆå‚ä¸ç‡è®¡ç®—
    engagement_rate = (
        base_engagement * 0.4 +           # åŸºç¡€å‚ä¸ç‡æƒé‡40%
        interaction_quality * 0.3 +       # äº’åŠ¨è´¨é‡æƒé‡30%
        session_quality * 0.2 +           # ä¼šè¯è´¨é‡æƒé‡20%
        retention_quality * 0.1           # ç•™å­˜è´¨é‡æƒé‡10%
    )
    
    return min(1.0, max(0.0, engagement_rate))


def _calculate_network_growth(state: Dict[str, Any]) -> float:
    """è®¡ç®—ç½‘ç»œå¢é•¿ç‡"""
    network_state = state.get("network_state", {})
    total_users = len(network_state)
    
    # åŸºäºç”¨æˆ·æ•°é‡å’Œè¿æ¥åº¦è®¡ç®—å¢é•¿ç‡
    total_connections = 0
    for user_data in network_state.values():
        total_connections += user_data.get("followers", 0) + user_data.get("following", 0)
    
    if total_users == 0:
        return 0.0
    
    avg_connections = total_connections / total_users
    return min(1.0, avg_connections / 100.0)  # å½’ä¸€åŒ–


def _encode_decision_type(action: str) -> int:
    """ç¼–ç å†³ç­–ç±»å‹"""
    action_map = {
        "CREATE_POST": 1,
        "ENCOURAGE_INTERACTION": 2,
        "FEATURE_USER": 3,
        "LAUNCH_CAMPAIGN": 4,
        "IMPROVE_ALGORITHM": 5,
        "ADD_FEATURE": 6,
        "MODERATE_CONTENT": 7,
        "EXPAND_NETWORK": 8
    }
    return action_map.get(action, 0)


def run_rl_social_demo(steps: int = 5, model_name: str = "mistralai/Mistral-7B-Instruct-v0.2"):
    """è¿è¡ŒåŸºäºRLçš„LLMå†³ç­–ç¤¾äº¤ç½‘ç»œæ¼”ç¤º"""
    
    print_section("RL-based LLM Decision Social Network Demo")
    
    # 1. åˆ›å»ºLLMç®¡ç†å™¨
    print(f"\n1. Creating LLM Manager with model: {model_name}")
    llm_manager = create_shared_llm_manager(
        model_name=model_name,
        backend="huggingface",
        temperature=0.7,
        max_length=512,
        device="auto",
        torch_dtype="float16"
    )
    
    # 2. åˆ›å»ºå·¥ä½œæµå’ŒRLè®­ç»ƒå™¨
    print("\n2. Creating RL Social Network Workflow")
    workflow, rl_trainer, decision_maker = create_rl_social_workflow(llm_manager)
    
    # 3. æ‰§è¡Œå¤šæ­¥ç¤¾äº¤ç½‘ç»œç®¡ç†
    print(f"\n3. Executing {steps} Social Network Management Steps")
    
    results = []
    for step in range(steps):
        print(f"\n--- ç¬¬ {step + 1} æ­¥ ---")
        
        try:
            # ç›´æ¥æ‰§è¡Œç¤¾äº¤ç½‘ç»œç¯å¢ƒèŠ‚ç‚¹
            node = workflow.nodes.get("social_environment")
            if node and node.sandbox:
                # è·å–å½“å‰çŠ¶æ€
                case = node.sandbox.case_generator()
                current_state = case["state"]
                
                # ä½¿ç”¨LLMåšå‡ºå†³ç­–
                decision_result = decision_maker.make_decision(current_state)
                decision = decision_result["decision"]  # ä»ç»“æœä¸­æå–å†³ç­–
                
                # æ‰§è¡Œç¤¾äº¤ç½‘ç»œå†³ç­–
                try:
                    # éªŒè¯å’Œæ‰§è¡Œå†³ç­–
                    score = node.sandbox.verify_score(
                        f"{decision['action']} {decision.get('target', '')}",
                        case
                    )
                    
                    # è®¡ç®—å¥–åŠ±
                    reward = score * 10
                    
                    # æ„å»ºçŠ¶æ€ç‰¹å¾
                    state_features = {
                        "active_users": current_state["user_behavior"]["active_users"],
                        "engagement_rate": _calculate_engagement_rate(current_state),
                        "content_quality": current_state["content_metrics"]["quality_score"],
                        "network_growth": _calculate_network_growth(current_state),
                        "decision_type": _encode_decision_type(decision["action"])
                    }
                    
                    # æ·»åŠ åˆ°RLè®­ç»ƒå™¨
                    rl_trainer.add_experience(
                        state=state_features,
                        action=json.dumps(decision),
                        reward=reward,
                        done=False
                    )
                    
                    # æ›´æ–°ç­–ç•¥
                    update_result = rl_trainer.update_policy()
                    
                    result = {
                        "step": step + 1,
                        "state": current_state,
                        "decision": decision,
                        "llm_response": decision_result["llm_response"],
                        "score": score,
                        "reward": reward,
                        "rl_update": update_result
                    }
                    
                    results.append(result)
                    
                    # æ‰“å°ç»“æœ
                    print(f"Decision: {decision['action']}")
                    print(f"Target: {decision.get('target', 'N/A')}")
                    print(f"Reasoning: {decision['reasoning']}")
                    print(f"Score: {score:.2f}")
                    print(f"Reward: {reward:.2f}")
                    print(f"Active Users: {current_state['user_behavior']['active_users']}")
                    print(f"Engagement Rate: {_calculate_engagement_rate(current_state):.3f}")
                    
                except Exception as e:
                    print(f"æ‰§è¡Œé”™è¯¯: {e}")
                    result = {
                        "step": step + 1,
                        "error": str(e),
                        "decision": {"action": "CREATE_POST", "reasoning": f"æ‰§è¡Œé”™è¯¯: {e}"}
                    }
                    results.append(result)
            
        except Exception as e:
            print(f"æ­¥éª¤ {step + 1} æ‰§è¡Œå¤±è´¥: {e}")
            result = {
                "step": step + 1,
                "error": str(e)
            }
            results.append(result)
    
    # 4. æ˜¾ç¤ºæœ€ç»ˆç»“æœ
    print_section("Final Results")
    
    successful_steps = [r for r in results if "error" not in r]
    if successful_steps:
        avg_score = sum(r["score"] for r in successful_steps) / len(successful_steps)
        avg_reward = sum(r["reward"] for r in successful_steps) / len(successful_steps)
        final_engagement = _calculate_engagement_rate(successful_steps[-1]["state"])
        
        print(f"Average Score: {avg_score:.2f}")
        print(f"Average Reward: {avg_reward:.2f}")
        print(f"Final Engagement Rate: {final_engagement:.3f}")
        print(f"Successful Steps: {len(successful_steps)}/{steps}")
    
    # 5. æ˜¾ç¤ºRLè®­ç»ƒç»Ÿè®¡
    print_section("RL Training Statistics")
    training_stats = rl_trainer.get_training_stats()
    print(f"Training Steps: {training_stats['training_step']}")
    print(f"Algorithm: {training_stats['algorithm']}")
    print(f"Recent Updates: {len(training_stats['recent_updates'])}")
    
    return results


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Sandbox-RL Social Network Demo")
    parser.add_argument("--steps", type=int, default=5, help="Number of steps to run")
    parser.add_argument("--model", type=str, default="mistralai/Mistral-7B-Instruct-v0.2", help="LLM model to use")
    
    args = parser.parse_args()
    
    print("ğŸ”¥ Sandbox-RL Social Network Demo")
    print("=" * 60)
    print(f"Steps: {args.steps}")
    print(f"Model: {args.model}")
    
    # æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
    supported_models = [
        "Qwen/Qwen-7B-Chat",
        "Qwen/Qwen-1_8B-Chat", 
        "microsoft/Phi-2",
        "google/gemma-2b-it",
        "01-ai/Yi-6B-Chat",
        "mistralai/Mistral-7B-Instruct-v0.2",
        "THUDM/chatglm3-6b",
        "baichuan-inc/Baichuan2-7B-Chat"
    ]
    
    if args.model not in supported_models:
        print(f"\nâš ï¸  Warning: Model {args.model} not in supported list.")
        print(f"Supported models: {', '.join(supported_models)}")
        print("Continuing anyway...")
    
    try:
        results = run_rl_social_demo(args.steps, args.model)
        print("\nâœ… Demo completed successfully!")
        
    except Exception as e:
        print(f"\nâŒ Demo failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 