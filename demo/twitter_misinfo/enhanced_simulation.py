#!/usr/bin/env python3
"""
Enhanced Twitter Misinformation Simulation with vLLM
==================================================

åŸºäºvLLMçš„Twitterè™šå‡ä¿¡æ¯ä¼ æ’­ä»¿çœŸï¼Œå‚è€ƒOASISæ¡†æ¶è®¾è®¡
"""

import asyncio
import random
import time
import json
import logging
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class BeliefType(Enum):
    """ä¿¡ä»°ç±»å‹"""
    TRUMP = "TRUMP"
    BIDEN = "BIDEN"
    NEUTRAL = "NEUTRAL"
    SWING = "SWING"

@dataclass
class SimulationConfig:
    """ä»¿çœŸé…ç½®"""
    num_agents: int = 50
    trump_ratio: float = 0.5
    num_steps: int = 30
    vllm_url: str = "http://localhost:8001/v1"
    model_name: str = "qwen2.5-7b-instruct"
    use_mock: bool = False  # æ˜¯å¦ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼

class MockLLM:
    """æ¨¡æ‹ŸLLMï¼Œå½“vLLMä¸å¯ç”¨æ—¶ä½¿ç”¨"""
    
    def __init__(self):
        self.responses = [
            "I will post TRUMP content to support my group.",
            "I will share BIDEN information to spread awareness.",
            "I will stay neutral and observe the situation.",
            "I will forward TRUMP messages to my network.",
            "I will post BIDEN content to counter misinformation."
        ]
    
    def generate(self, prompt: str) -> str:
        """ç”Ÿæˆæ¨¡æ‹Ÿå“åº”"""
        if "TRUMP" in prompt and "BIDEN" in prompt:
            return random.choice([
                "I will post TRUMP content to support my group.",
                "I will share BIDEN information to spread awareness."
            ])
        elif "TRUMP" in prompt:
            return "I will post TRUMP content to support my group."
        elif "BIDEN" in prompt:
            return "I will share BIDEN information to spread awareness."
        else:
            return random.choice(self.responses)

class VLLMClient:
    """vLLMå®¢æˆ·ç«¯"""
    
    def __init__(self, base_url: str, model_name: str, use_mock: bool = False):
        self.base_url = base_url
        self.model_name = model_name
        self.use_mock = use_mock
        self.session = None
        
        if use_mock:
            self.llm = MockLLM()
        else:
            self.llm = None
    
    async def __aenter__(self):
        if not self.use_mock:
            import aiohttp
            self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    def generate(self, prompt: str) -> str:
        """ç”Ÿæˆæ–‡æœ¬"""
        if self.use_mock:
            return self.llm.generate(prompt)
        
        if not self.session:
            raise RuntimeError("Client not initialized. Use async context manager.")
        
        # è¿™é‡Œåº”è¯¥å®ç°çœŸæ­£çš„vLLM APIè°ƒç”¨
        # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¨¡æ‹Ÿå“åº”
        return self._generate_mock_response(prompt)
    
    def _generate_mock_response(self, prompt: str) -> str:
        """ç”Ÿæˆæ¨¡æ‹Ÿå“åº”"""
        if "TRUMP" in prompt and "BIDEN" in prompt:
            return random.choice([
                "I will post TRUMP content to support my group.",
                "I will share BIDEN information to spread awareness."
            ])
        elif "TRUMP" in prompt:
            return "I will post TRUMP content to support my group."
        elif "BIDEN" in prompt:
            return "I will share BIDEN information to spread awareness."
        else:
            return "I will stay neutral and observe the situation."

class Agent:
    """Agentç±»"""
    
    def __init__(self, agent_id: int, group: str, neighbors: List[int] = None):
        self.agent_id = agent_id
        self.group = group
        self.neighbors = neighbors or []
        self.influence_score = random.uniform(0.1, 1.0)
        self.skepticism_level = random.uniform(0.1, 0.9)
        self.post_history = []
        self.switch_history = []
    
    def get_neighbors(self) -> List['Agent']:
        """è·å–é‚»å±…agentsï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰"""
        return [self]  # ç®€åŒ–å®ç°
    
    def switch_group(self, new_group: str):
        """åˆ‡æ¢ä¿¡ä»°ç»„"""
        old_group = self.group
        self.group = new_group
        self.switch_history.append({
            'step': len(self.switch_history),
            'from': old_group,
            'to': new_group,
            'timestamp': time.time()
        })
        logger.info(f"Agent {self.agent_id} switched from {old_group} to {new_group}")

class AgentGraph:
    """Agentå›¾"""
    
    def __init__(self):
        self.agents = {}
        self.edges = set()
    
    def add_agent(self, agent: Agent):
        """æ·»åŠ agent"""
        self.agents[agent.agent_id] = agent
    
    def get_agents(self, agent_ids: List[int] = None):
        """è·å–agents"""
        if agent_ids:
            return [(aid, self.agents[aid]) for aid in agent_ids if aid in self.agents]
        return [(aid, agent) for aid, agent in self.agents.items()]
    
    def get_agent(self, agent_id: int) -> Agent:
        """è·å–æŒ‡å®šagent"""
        return self.agents[agent_id]
    
    def add_edge(self, src: int, dst: int):
        """æ·»åŠ è¾¹"""
        self.edges.add((src, dst))

class TwitterMisinfoSimulation:
    """Twitterè™šå‡ä¿¡æ¯ä¼ æ’­ä»¿çœŸ"""
    
    def __init__(self, config: SimulationConfig):
        self.config = config
        self.agent_graph = AgentGraph()
        self.llm = None
        self.history = []
        
        self._initialize_agents()
        self._initialize_network()
    
    def _initialize_agents(self):
        """åˆå§‹åŒ–agents"""
        agent_ids = list(range(self.config.num_agents))
        trump_agents = set(random.sample(agent_ids, int(len(agent_ids) * self.config.trump_ratio)))
        
        for agent_id in agent_ids:
            group = "TRUMP" if agent_id in trump_agents else "BIDEN"
            agent = Agent(agent_id, group)
            self.agent_graph.add_agent(agent)
        
        logger.info(f"Initialized {self.config.num_agents} agents")
        logger.info(f"TRUMP: {len(trump_agents)}, BIDEN: {self.config.num_agents - len(trump_agents)}")
    
    def _initialize_network(self):
        """åˆå§‹åŒ–ç¤¾äº¤ç½‘ç»œ"""
        agents = list(self.agent_graph.agents.values())
        
        for agent in agents:
            # ä¸ºæ¯ä¸ªagentåˆ†é…3-8ä¸ªé‚»å±…
            num_connections = random.randint(3, 8)
            other_agents = [a for a in agents if a.agent_id != agent.agent_id]
            
            if other_agents:
                connections = random.sample(other_agents, min(num_connections, len(other_agents)))
                agent.neighbors = [a.agent_id for a in connections]
                
                for connected_agent in connections:
                    self.agent_graph.add_edge(agent.agent_id, connected_agent.agent_id)
    
    async def run_simulation(self):
        """è¿è¡Œä»¿çœŸ"""
        logger.info(f"å¼€å§‹è¿è¡Œ {self.config.num_steps} æ­¥ä»¿çœŸ...")
        
        async with VLLMClient(
            base_url=self.config.vllm_url,
            model_name=self.config.model_name,
            use_mock=self.config.use_mock
        ) as llm:
            self.llm = llm
            
            for step in range(self.config.num_steps):
                step_result = await self._simulate_step(step)
                self.history.append(step_result)
                
                # æ¯5æ­¥æ‰“å°ä¸€æ¬¡ç»Ÿè®¡
                if (step + 1) % 5 == 0:
                    self._print_statistics(step + 1)
        
        logger.info("ä»¿çœŸå®Œæˆ")
        return self.history
    
    async def _simulate_step(self, step: int) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿå•æ­¥"""
        actions = {}
        
        # ä¸ºæ¯ä¸ªagentç”ŸæˆLLMå†³ç­–
        for agent_id, agent in self.agent_graph.get_agents():
            neighbors = agent.get_neighbors()
            neighbor_groups = [n.group for n in neighbors]
            
            prompt = (
                f"You are a {agent.group} supporter. "
                f"Your goal is to convince others that '{agent.group} won the election'. "
                f"Your neighbors' groups: {neighbor_groups}. "
                f"Your influence score: {agent.influence_score:.2f}. "
                f"Your skepticism level: {agent.skepticism_level:.2f}. "
                "What will you post or forward to maximize your group's influence?"
            )
            
            # LLMå†³ç­–
            resp = self.llm.generate(prompt)
            logger.info(f"[LLM][Agent {agent_id}][{agent.group}] Output: {resp}")
            
            # ç®€å•å†³ç­–è§„åˆ™ï¼šå¦‚æœLLMè¾“å‡ºåŒ…å«å¯¹æ–¹groupï¼Œåˆ™è§†ä¸ºè¢«è¯´æœ
            if agent.group == "TRUMP" and "BIDEN" in resp.upper():
                actions[agent_id] = "SWITCH"
            elif agent.group == "BIDEN" and "TRUMP" in resp.upper():
                actions[agent_id] = "SWITCH"
            else:
                actions[agent_id] = "STAY"
        
        # ä¼ æ’­ä¸ä¿¡ä»°è½¬å˜
        switches = 0
        for agent_id, agent in self.agent_graph.get_agents():
            if actions[agent_id] == "SWITCH":
                new_group = "BIDEN" if agent.group == "TRUMP" else "TRUMP"
                agent.switch_group(new_group)
                switches += 1
        
        # ç»Ÿè®¡å„ç»„äººæ•°
        trump_count = sum(1 for _, agent in self.agent_graph.get_agents() if agent.group == "TRUMP")
        biden_count = sum(1 for _, agent in self.agent_graph.get_agents() if agent.group == "BIDEN")
        
        step_result = {
            "step": step,
            "trump_count": trump_count,
            "biden_count": biden_count,
            "switches": switches,
            "timestamp": time.time()
        }
        
        logger.info(f"Step {step + 1}: TRUMP={trump_count}, BIDEN={biden_count}, Switches={switches}")
        
        return step_result
    
    def _print_statistics(self, step: int):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        if not self.history:
            return
        
        latest = self.history[-1]
        total_switches = sum(h["switches"] for h in self.history)
        
        logger.info(f"Step {step} ç»Ÿè®¡:")
        logger.info(f"  TRUMP: {latest['trump_count']}")
        logger.info(f"  BIDEN: {latest['biden_count']}")
        logger.info(f"  æœ¬è½®åˆ‡æ¢: {latest['switches']}")
        logger.info(f"  æ€»åˆ‡æ¢æ¬¡æ•°: {total_switches}")
    
    def save_results(self, filename: str):
        """ä¿å­˜ç»“æœ"""
        results = {
            "config": {
                "num_agents": self.config.num_agents,
                "trump_ratio": self.config.trump_ratio,
                "num_steps": self.config.num_steps,
                "vllm_url": self.config.vllm_url,
                "model_name": self.config.model_name,
                "use_mock": self.config.use_mock
            },
            "history": self.history,
            "final_statistics": {
                "total_switches": sum(h["switches"] for h in self.history),
                "final_trump_count": self.history[-1]["trump_count"] if self.history else 0,
                "final_biden_count": self.history[-1]["biden_count"] if self.history else 0
            }
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ç»“æœå·²ä¿å­˜åˆ° {filename}")

async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¯åŠ¨Twitterè™šå‡ä¿¡æ¯ä¼ æ’­ä»¿çœŸ")
    
    # é…ç½®ä»¿çœŸå‚æ•°
    config = SimulationConfig(
        num_agents=50,
        trump_ratio=0.5,
        num_steps=30,
        vllm_url="http://localhost:8001/v1",
        model_name="qwen2.5-7b-instruct",
        use_mock=True  # è®¾ç½®ä¸ºTrueä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ï¼ŒFalseä½¿ç”¨çœŸå®vLLM
    )
    
    # åˆ›å»ºå¹¶è¿è¡Œä»¿çœŸ
    simulation = TwitterMisinfoSimulation(config)
    history = await simulation.run_simulation()
    
    # ä¿å­˜ç»“æœ
    simulation.save_results("twitter_misinfo_simulation_results.json")
    
    logger.info("âœ… ä»¿çœŸå®Œæˆ")

if __name__ == "__main__":
    asyncio.run(main()) 