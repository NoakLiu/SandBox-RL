#!/usr/bin/env python3
"""
Misinformation Propagation Simulation
====================================

åŸºäºgroup chat simulationçš„misinformationä¼ æ’­è§„åˆ™ç³»ç»Ÿã€‚
åŒ…å«å¤šç§ä¼ æ’­ç­–ç•¥ã€ä¿¡ä»»æœºåˆ¶ã€éªŒè¯æœºåˆ¶ç­‰ã€‚
"""

import asyncio
import os
import random
import logging
import json
import time
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from enum import Enum
from collections import defaultdict, deque

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æ¨¡æ‹Ÿçš„ActionTypeæšä¸¾
class ActionType:
    CREATE_POST = "create_post"
    LIKE_POST = "like_post"
    REPOST = "repost"
    FOLLOW = "follow"
    DO_NOTHING = "do_nothing"
    QUOTE_POST = "quote_post"
    JOIN_GROUP = "join_group"
    LEAVE_GROUP = "leave_group"
    SEND_TO_GROUP = "send_to_group"
    LISTEN_FROM_GROUP = "listen_from_group"

class MisinfoType(Enum):
    """Misinformationç±»å‹"""
    CONSPIRACY = "conspiracy"  # é˜´è°‹è®º
    PSEUDOSCIENCE = "pseudoscience"  # ä¼ªç§‘å­¦
    POLITICAL = "political"  # æ”¿æ²»è°£è¨€
    HEALTH = "health"  # å¥åº·è°£è¨€
    FINANCIAL = "financial"  # é‡‘èè°£è¨€
    SOCIAL = "social"  # ç¤¾ä¼šè°£è¨€

class AgentBelief(Enum):
    """Agentä¿¡å¿µç±»å‹"""
    BELIEVER = "believer"  # ç›¸ä¿¡è€…
    SKEPTIC = "skeptic"  # æ€€ç–‘è€…
    NEUTRAL = "neutral"  # ä¸­ç«‹è€…
    FACT_CHECKER = "fact_checker"  # äº‹å®æ ¸æŸ¥è€…

class PropagationStrategy(Enum):
    """ä¼ æ’­ç­–ç•¥"""
    VIRAL = "viral"  # ç—…æ¯’å¼ä¼ æ’­
    TARGETED = "targeted"  # å®šå‘ä¼ æ’­
    STEALTH = "stealth"  # éšè”½ä¼ æ’­
    AGGRESSIVE = "aggressive"  # æ¿€è¿›ä¼ æ’­

@dataclass
class MisinfoContent:
    """Misinformationå†…å®¹"""
    id: str
    type: MisinfoType
    content: str
    source: str
    credibility: float  # 0-1, å¯ä¿¡åº¦
    virality: float  # 0-1, ä¼ æ’­æ€§
    emotional_impact: float  # 0-1, æƒ…æ„Ÿå½±å“
    target_audience: List[str] = field(default_factory=list)
    keywords: List[str] = field(default_factory=list)
    created_time: float = field(default_factory=time.time)

@dataclass
class AgentProfile:
    """Agentä¸ªäººèµ„æ–™"""
    agent_id: int
    name: str
    belief: AgentBelief
    trust_threshold: float  # ä¿¡ä»»é˜ˆå€¼
    skepticism_level: float  # æ€€ç–‘ç¨‹åº¦
    influence_score: float  # å½±å“åŠ›åˆ†æ•°
    social_network: List[int] = field(default_factory=list)  # ç¤¾äº¤ç½‘ç»œ
    groups: List[int] = field(default_factory=list)  # æ‰€å±ç¾¤ç»„
    exposure_history: List[str] = field(default_factory=list)  # æ¥è§¦å†å²
    verification_history: List[Dict] = field(default_factory=list)  # éªŒè¯å†å²

class MisinfoPropagationRules:
    """Misinformationä¼ æ’­è§„åˆ™å¼•æ“"""
    
    def __init__(self):
        self.propagation_rules = {
            "viral": self._viral_propagation,
            "targeted": self._targeted_propagation,
            "stealth": self._stealth_propagation,
            "aggressive": self._aggressive_propagation
        }
        
        self.verification_rules = {
            "fact_check": self._fact_check_verification,
            "source_verification": self._source_verification,
            "peer_verification": self._peer_verification
        }
        
        self.belief_update_rules = {
            "exposure": self._belief_update_by_exposure,
            "social_influence": self._belief_update_by_social_influence,
            "verification": self._belief_update_by_verification
        }
    
    def _viral_propagation(self, agent: AgentProfile, content: MisinfoContent, 
                          network: Dict[int, AgentProfile]) -> float:
        """ç—…æ¯’å¼ä¼ æ’­è§„åˆ™"""
        # åŸºäºæƒ…æ„Ÿå½±å“å’Œä¼ æ’­æ€§
        base_prob = content.virality * content.emotional_impact
        
        # ç¤¾äº¤ç½‘ç»œæ”¾å¤§æ•ˆåº”
        network_amplification = len(agent.social_network) * 0.1
        
        # å½±å“åŠ›æ”¾å¤§
        influence_amplification = agent.influence_score * 0.2
        
        return min(1.0, base_prob + network_amplification + influence_amplification)
    
    def _targeted_propagation(self, agent: AgentProfile, content: MisinfoContent,
                             network: Dict[int, AgentProfile]) -> float:
        """å®šå‘ä¼ æ’­è§„åˆ™"""
        # æ£€æŸ¥ç›®æ ‡å—ä¼—åŒ¹é…åº¦
        audience_match = 1.0 if agent.name in content.target_audience else 0.3
        
        # åŸºäºä¿¡å¿µç±»å‹çš„åŒ¹é…
        belief_match = {
            AgentBelief.BELIEVER: 0.8,
            AgentBelief.SKEPTIC: 0.2,
            AgentBelief.NEUTRAL: 0.5,
            AgentBelief.FACT_CHECKER: 0.1
        }.get(agent.belief, 0.5)
        
        # å…³é”®è¯åŒ¹é…
        keyword_match = sum(1 for keyword in content.keywords 
                          if keyword.lower() in agent.name.lower()) / len(content.keywords) if content.keywords else 0
        
        return min(1.0, audience_match * belief_match * (0.7 + 0.3 * keyword_match))
    
    def _stealth_propagation(self, agent: AgentProfile, content: MisinfoContent,
                            network: Dict[int, AgentProfile]) -> float:
        """éšè”½ä¼ æ’­è§„åˆ™"""
        # é™ä½æ€€ç–‘è€…çš„æ£€æµ‹æ¦‚ç‡
        if agent.belief == AgentBelief.SKEPTIC:
            stealth_factor = 0.3
        elif agent.belief == AgentBelief.FACT_CHECKER:
            stealth_factor = 0.1
        else:
            stealth_factor = 0.8
        
        # åŸºäºå†…å®¹å¯ä¿¡åº¦çš„éšè”½æ€§
        credibility_stealth = content.credibility * 0.5
        
        # ç¤¾äº¤ç½‘ç»œéšè”½æ€§
        network_stealth = 1.0 - (len(agent.social_network) * 0.05)
        
        return min(1.0, stealth_factor * credibility_stealth * network_stealth)
    
    def _aggressive_propagation(self, agent: AgentProfile, content: MisinfoContent,
                               network: Dict[int, AgentProfile]) -> float:
        """æ¿€è¿›ä¼ æ’­è§„åˆ™"""
        # é«˜æƒ…æ„Ÿå½±å“
        emotional_boost = content.emotional_impact * 0.5
        
        # ç¤¾äº¤å‹åŠ›
        social_pressure = len(agent.social_network) * 0.15
        
        # ç¾¤ä½“æ•ˆåº”
        group_effect = len(agent.groups) * 0.1
        
        # é™ä½æ€€ç–‘é˜ˆå€¼
        reduced_skepticism = 1.0 - agent.skepticism_level * 0.3
        
        return min(1.0, (emotional_boost + social_pressure + group_effect) * reduced_skepticism)
    
    def _fact_check_verification(self, agent: AgentProfile, content: MisinfoContent) -> Dict:
        """äº‹å®æ ¸æŸ¥éªŒè¯"""
        verification_result = {
            "verified": False,
            "confidence": 0.0,
            "evidence": [],
            "sources": []
        }
        
        # åŸºäºagentçš„æ€€ç–‘ç¨‹åº¦è¿›è¡ŒéªŒè¯
        if agent.belief == AgentBelief.FACT_CHECKER:
            verification_result["verified"] = random.random() < 0.8
            verification_result["confidence"] = 0.8
        elif agent.belief == AgentBelief.SKEPTIC:
            verification_result["verified"] = random.random() < 0.6
            verification_result["confidence"] = 0.6
        else:
            verification_result["verified"] = random.random() < 0.3
            verification_result["confidence"] = 0.3
        
        return verification_result
    
    def _source_verification(self, agent: AgentProfile, content: MisinfoContent) -> Dict:
        """æ¥æºéªŒè¯"""
        # åŸºäºæ¥æºå¯ä¿¡åº¦çš„éªŒè¯
        source_credibility = {
            "official": 0.9,
            "verified": 0.7,
            "unknown": 0.3,
            "suspicious": 0.1
        }.get(content.source, 0.5)
        
        return {
            "verified": random.random() < source_credibility,
            "confidence": source_credibility,
            "source_credibility": source_credibility
        }
    
    def _peer_verification(self, agent: AgentProfile, content: MisinfoContent,
                          network: Dict[int, AgentProfile]) -> Dict:
        """åŒè¡ŒéªŒè¯"""
        # åŸºäºç¤¾äº¤ç½‘ç»œçš„åŒè¡ŒéªŒè¯
        peer_opinions = []
        for neighbor_id in agent.social_network[:5]:  # å–å‰5ä¸ªé‚»å±…
            if neighbor_id in network:
                neighbor = network[neighbor_id]
                if content.id in neighbor.exposure_history:
                    peer_opinions.append(neighbor.belief)
        
        if not peer_opinions:
            return {"verified": False, "confidence": 0.0, "peer_consensus": 0.0}
        
        # è®¡ç®—åŒè¡Œå…±è¯†
        believer_count = sum(1 for belief in peer_opinions if belief == AgentBelief.BELIEVER)
        skeptic_count = sum(1 for belief in peer_opinions if belief == AgentBelief.SKEPTIC)
        
        total_peers = len(peer_opinions)
        consensus = believer_count / total_peers if total_peers > 0 else 0.0
        
        return {
            "verified": consensus > 0.5,
            "confidence": consensus,
            "peer_consensus": consensus,
            "peer_count": total_peers
        }
    
    def _belief_update_by_exposure(self, agent: AgentProfile, content: MisinfoContent) -> AgentBelief:
        """åŸºäºæ¥è§¦çš„ä¿¡å¿µæ›´æ–°"""
        # è®¡ç®—æ¥è§¦åçš„ä¿¡å¿µå˜åŒ–æ¦‚ç‡
        exposure_effect = content.emotional_impact * content.credibility
        
        # åŸºäºå½“å‰ä¿¡å¿µçš„æŠµæŠ—åŠ›
        resistance = {
            AgentBelief.BELIEVER: 0.1,
            AgentBelief.SKEPTIC: 0.8,
            AgentBelief.NEUTRAL: 0.5,
            AgentBelief.FACT_CHECKER: 0.9
        }.get(agent.belief, 0.5)
        
        # ä¿¡å¿µå˜åŒ–æ¦‚ç‡
        change_prob = exposure_effect * (1 - resistance)
        
        if random.random() < change_prob:
            # å‘believeræ–¹å‘å˜åŒ–
            if agent.belief == AgentBelief.SKEPTIC:
                return AgentBelief.NEUTRAL
            elif agent.belief == AgentBelief.NEUTRAL:
                return AgentBelief.BELIEVER
            elif agent.belief == AgentBelief.FACT_CHECKER:
                return AgentBelief.SKEPTIC
        
        return agent.belief
    
    def _belief_update_by_social_influence(self, agent: AgentProfile, 
                                         network: Dict[int, AgentProfile]) -> AgentBelief:
        """åŸºäºç¤¾äº¤å½±å“çš„ä¿¡å¿µæ›´æ–°"""
        if not agent.social_network:
            return agent.belief
        
        # ç»Ÿè®¡é‚»å±…çš„ä¿¡å¿µåˆ†å¸ƒ
        neighbor_beliefs = []
        for neighbor_id in agent.social_network:
            if neighbor_id in network:
                neighbor_beliefs.append(network[neighbor_id].belief)
        
        if not neighbor_beliefs:
            return agent.belief
        
        # è®¡ç®—ä¸»æµä¿¡å¿µ
        belief_counts = defaultdict(int)
        for belief in neighbor_beliefs:
            belief_counts[belief] += 1
        
        dominant_belief = max(belief_counts.items(), key=lambda x: x[1])[0]
        
        # ç¤¾äº¤å½±å“æ¦‚ç‡
        influence_prob = len(neighbor_beliefs) * 0.1 * agent.influence_score
        
        if random.random() < influence_prob:
            return dominant_belief
        
        return agent.belief
    
    def _belief_update_by_verification(self, agent: AgentProfile, 
                                     verification_result: Dict) -> AgentBelief:
        """åŸºäºéªŒè¯ç»“æœçš„ä¿¡å¿µæ›´æ–°"""
        if verification_result.get("verified", False):
            # éªŒè¯ä¸ºçœŸï¼Œå‘skepticæ–¹å‘å˜åŒ–
            if agent.belief == AgentBelief.BELIEVER:
                return AgentBelief.NEUTRAL
            elif agent.belief == AgentBelief.NEUTRAL:
                return AgentBelief.SKEPTIC
        else:
            # éªŒè¯ä¸ºå‡ï¼Œå‘believeræ–¹å‘å˜åŒ–
            if agent.belief == AgentBelief.SKEPTIC:
                return AgentBelief.NEUTRAL
            elif agent.belief == AgentBelief.NEUTRAL:
                return AgentBelief.BELIEVER
        
        return agent.belief

class MisinfoSimulation:
    """Misinformationä¼ æ’­æ¨¡æ‹Ÿå™¨"""
    
    def __init__(self, num_agents: int = 100):
        self.num_agents = num_agents
        self.agents: Dict[int, AgentProfile] = {}
        self.network: Dict[int, List[int]] = defaultdict(list)
        self.groups: Dict[int, List[int]] = defaultdict(list)
        self.misinfo_contents: List[MisinfoContent] = []
        self.propagation_rules = MisinfoPropagationRules()
        self.simulation_history: List[Dict] = []
        
        self._initialize_agents()
        self._initialize_network()
        self._initialize_misinfo_content()
    
    def _initialize_agents(self):
        """åˆå§‹åŒ–agents"""
        belief_distribution = {
            AgentBelief.BELIEVER: 0.2,
            AgentBelief.SKEPTIC: 0.3,
            AgentBelief.NEUTRAL: 0.4,
            AgentBelief.FACT_CHECKER: 0.1
        }
        
        for i in range(self.num_agents):
            # éšæœºåˆ†é…ä¿¡å¿µç±»å‹
            belief = random.choices(
                list(belief_distribution.keys()),
                weights=list(belief_distribution.values())
            )[0]
            
            agent = AgentProfile(
                agent_id=i,
                name=f"Agent_{i}",
                belief=belief,
                trust_threshold=random.uniform(0.3, 0.8),
                skepticism_level=random.uniform(0.1, 0.9),
                influence_score=random.uniform(0.1, 1.0)
            )
            
            self.agents[i] = agent
    
    def _initialize_network(self):
        """åˆå§‹åŒ–ç¤¾äº¤ç½‘ç»œ"""
        # åˆ›å»ºéšæœºç¤¾äº¤ç½‘ç»œ
        for agent_id in self.agents:
            # æ¯ä¸ªagentéšæœºè¿æ¥3-8ä¸ªå…¶ä»–agent
            num_connections = random.randint(3, 8)
            connections = random.sample(
                [aid for aid in self.agents.keys() if aid != agent_id],
                min(num_connections, self.num_agents - 1)
            )
            
            self.network[agent_id] = connections
            self.agents[agent_id].social_network = connections
    
    def _initialize_misinfo_content(self):
        """åˆå§‹åŒ–misinformationå†…å®¹"""
        misinfo_templates = [
            MisinfoContent(
                id="misinfo_001",
                type=MisinfoType.CONSPIRACY,
                content="æ”¿åºœæ­£åœ¨ç§˜å¯†ç›‘æ§æ‰€æœ‰å…¬æ°‘çš„ç¤¾äº¤åª’ä½“æ´»åŠ¨",
                source="anonymous",
                credibility=0.2,
                virality=0.8,
                emotional_impact=0.9,
                keywords=["æ”¿åºœ", "ç›‘æ§", "ç§˜å¯†", "ç¤¾äº¤åª’ä½“"]
            ),
            MisinfoContent(
                id="misinfo_002",
                type=MisinfoType.HEALTH,
                content="æŸç§å¤©ç„¶è‰è¯å¯ä»¥å®Œå…¨æ²»æ„ˆç™Œç—‡ï¼ŒåŒ»ç”Ÿä»¬éƒ½åœ¨éšç’è¿™ä¸ªäº‹å®",
                source="health_blog",
                credibility=0.3,
                virality=0.7,
                emotional_impact=0.8,
                keywords=["å¤©ç„¶", "è‰è¯", "ç™Œç—‡", "æ²»æ„ˆ", "åŒ»ç”Ÿ"]
            ),
            MisinfoContent(
                id="misinfo_003",
                type=MisinfoType.FINANCIAL,
                content="æŸçŸ¥åå…¬å¸å³å°†ç ´äº§ï¼Œè‚¡ä»·ä¼šæš´è·Œï¼Œå†…éƒ¨äººå£«éƒ½åœ¨æŠ›å”®è‚¡ç¥¨",
                source="finance_insider",
                credibility=0.4,
                virality=0.6,
                emotional_impact=0.7,
                keywords=["ç ´äº§", "è‚¡ä»·", "æš´è·Œ", "æŠ›å”®", "è‚¡ç¥¨"]
            )
        ]
        
        self.misinfo_contents = misinfo_templates
    
    def run_simulation(self, steps: int = 50, propagation_strategy: PropagationStrategy = PropagationStrategy.VIRAL):
        """è¿è¡Œæ¨¡æ‹Ÿ"""
        logger.info(f"å¼€å§‹misinformationä¼ æ’­æ¨¡æ‹Ÿï¼Œå…±{steps}æ­¥")
        
        for step in range(steps):
            step_result = self._simulate_step(step, propagation_strategy)
            self.simulation_history.append(step_result)
            
            # æ¯10æ­¥è¾“å‡ºä¸€æ¬¡ç»Ÿè®¡
            if (step + 1) % 10 == 0:
                self._print_statistics(step + 1)
        
        logger.info("æ¨¡æ‹Ÿå®Œæˆ")
        return self.simulation_history
    
    def _simulate_step(self, step: int, strategy: PropagationStrategy) -> Dict:
        """æ¨¡æ‹Ÿå•æ­¥ä¼ æ’­"""
        step_result = {
            "step": step,
            "timestamp": time.time(),
            "propagations": [],
            "verifications": [],
            "belief_changes": [],
            "statistics": {}
        }
        
        # éšæœºé€‰æ‹©ä¸€ä¸ªmisinfoå†…å®¹
        content = random.choice(self.misinfo_contents)
        
        # éšæœºé€‰æ‹©ä¼ æ’­æº
        source_agent_id = random.choice(list(self.agents.keys()))
        source_agent = self.agents[source_agent_id]
        
        # æ‰§è¡Œä¼ æ’­
        propagations = self._propagate_misinfo(content, source_agent, strategy)
        step_result["propagations"] = propagations
        
        # æ‰§è¡ŒéªŒè¯
        verifications = self._verify_misinfo(content)
        step_result["verifications"] = verifications
        
        # æ›´æ–°ä¿¡å¿µ
        belief_changes = self._update_beliefs(content)
        step_result["belief_changes"] = belief_changes
        
        # è®¡ç®—ç»Ÿè®¡
        step_result["statistics"] = self._calculate_statistics()
        
        return step_result
    
    def _propagate_misinfo(self, content: MisinfoContent, source_agent: AgentProfile, 
                          strategy: PropagationStrategy) -> List[Dict]:
        """ä¼ æ’­misinformation"""
        propagations = []
        
        # è·å–ä¼ æ’­è§„åˆ™
        propagation_func = self.propagation_rules.propagation_rules.get(strategy.value)
        if not propagation_func:
            return propagations
        
        # å¯¹æ¯ä¸ªagentè®¡ç®—ä¼ æ’­æ¦‚ç‡
        for agent_id, agent in self.agents.items():
            if agent_id == source_agent.agent_id:
                continue
            
            # è®¡ç®—ä¼ æ’­æ¦‚ç‡
            propagation_prob = propagation_func(agent, content, self.agents)
            
            # éšæœºå†³å®šæ˜¯å¦ä¼ æ’­
            if random.random() < propagation_prob:
                # è®°å½•ä¼ æ’­
                propagation_record = {
                    "source_agent": source_agent.agent_id,
                    "target_agent": agent_id,
                    "content_id": content.id,
                    "probability": propagation_prob,
                    "strategy": strategy.value
                }
                propagations.append(propagation_record)
                
                # æ›´æ–°agentçš„æ¥è§¦å†å²
                agent.exposure_history.append(content.id)
                
                logger.debug(f"Agent {source_agent.agent_id} å‘ Agent {agent_id} ä¼ æ’­äº† {content.id}")
        
        return propagations
    
    def _verify_misinfo(self, content: MisinfoContent) -> List[Dict]:
        """éªŒè¯misinformation"""
        verifications = []
        
        # é€‰æ‹©ä¸€äº›agentè¿›è¡ŒéªŒè¯
        verifier_agents = [aid for aid, agent in self.agents.items() 
                          if agent.belief in [AgentBelief.SKEPTIC, AgentBelief.FACT_CHECKER]]
        
        for agent_id in random.sample(verifier_agents, min(5, len(verifier_agents))):
            agent = self.agents[agent_id]
            
            # æ‰§è¡Œä¸åŒç±»å‹çš„éªŒè¯
            verification_methods = [
                self.propagation_rules._fact_check_verification,
                self.propagation_rules._source_verification,
                self.propagation_rules._peer_verification
            ]
            
            for method in verification_methods:
                if method == self.propagation_rules._peer_verification:
                    result = method(agent, content, self.agents)
                else:
                    result = method(agent, content)
                
                verification_record = {
                    "agent_id": agent_id,
                    "content_id": content.id,
                    "method": method.__name__,
                    "result": result
                }
                verifications.append(verification_record)
                
                # æ›´æ–°éªŒè¯å†å²
                agent.verification_history.append(verification_record)
        
        return verifications
    
    def _update_beliefs(self, content: MisinfoContent) -> List[Dict]:
        """æ›´æ–°ä¿¡å¿µ"""
        belief_changes = []
        
        for agent_id, agent in self.agents.items():
            old_belief = agent.belief
            
            # åŸºäºæ¥è§¦æ›´æ–°ä¿¡å¿µ
            if content.id in agent.exposure_history:
                new_belief = self.propagation_rules._belief_update_by_exposure(agent, content)
                if new_belief != old_belief:
                    agent.belief = new_belief
                    belief_changes.append({
                        "agent_id": agent_id,
                        "old_belief": old_belief.value,
                        "new_belief": new_belief.value,
                        "reason": "exposure"
                    })
            
            # åŸºäºç¤¾äº¤å½±å“æ›´æ–°ä¿¡å¿µ
            new_belief = self.propagation_rules._belief_update_by_social_influence(agent, self.agents)
            if new_belief != agent.belief:
                old_belief = agent.belief
                agent.belief = new_belief
                belief_changes.append({
                    "agent_id": agent_id,
                    "old_belief": old_belief.value,
                    "new_belief": new_belief.value,
                    "reason": "social_influence"
                })
        
        return belief_changes
    
    def _calculate_statistics(self) -> Dict:
        """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        belief_counts = defaultdict(int)
        for agent in self.agents.values():
            belief_counts[agent.belief.value] += 1
        
        total_agents = len(self.agents)
        belief_percentages = {
            belief: count / total_agents * 100 
            for belief, count in belief_counts.items()
        }
        
        return {
            "total_agents": total_agents,
            "belief_distribution": belief_percentages,
            "average_influence": sum(agent.influence_score for agent in self.agents.values()) / total_agents,
            "average_skepticism": sum(agent.skepticism_level for agent in self.agents.values()) / total_agents
        }
    
    def _print_statistics(self, step: int):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        stats = self._calculate_statistics()
        logger.info(f"Step {step} ç»Ÿè®¡:")
        logger.info(f"  ä¿¡å¿µåˆ†å¸ƒ: {stats['belief_distribution']}")
        logger.info(f"  å¹³å‡å½±å“åŠ›: {stats['average_influence']:.3f}")
        logger.info(f"  å¹³å‡æ€€ç–‘åº¦: {stats['average_skepticism']:.3f}")
    
    def save_results(self, filename: str):
        """ä¿å­˜ç»“æœ"""
        results = {
            "simulation_config": {
                "num_agents": self.num_agents,
                "steps": len(self.simulation_history)
            },
            "final_statistics": self._calculate_statistics(),
            "simulation_history": self.simulation_history
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ç»“æœå·²ä¿å­˜åˆ° {filename}")

async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¯åŠ¨Misinformationä¼ æ’­æ¨¡æ‹Ÿ")
    
    # åˆ›å»ºæ¨¡æ‹Ÿå™¨
    simulation = MisinfoSimulation(num_agents=100)
    
    # è¿è¡Œæ¨¡æ‹Ÿ
    results = simulation.run_simulation(
        steps=50,
        propagation_strategy=PropagationStrategy.VIRAL
    )
    
    # ä¿å­˜ç»“æœ
    simulation.save_results("misinformation_simulation_results.json")
    
    logger.info("âœ… æ¨¡æ‹Ÿå®Œæˆ")

if __name__ == "__main__":
    asyncio.run(main()) 