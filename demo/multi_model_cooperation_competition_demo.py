#!/usr/bin/env python3
"""
å¤šæ¨¡å‹åˆä½œä¸å¯¹æŠ—æ¼”ç¤º

è¿™ä¸ªæ¼”ç¤ºå±•ç¤ºäº†SandGraphçš„å¤šæ¨¡å‹è°ƒåº¦ç³»ç»Ÿï¼ŒåŒ…æ‹¬ï¼š
1. æ¨¡å‹é—´çš„åˆä½œæœºåˆ¶ - è§‚å¯ŸåŠŸèƒ½åˆ†åŒ–ç°è±¡
2. æ¨¡å‹é—´çš„å¯¹æŠ—æœºåˆ¶ - äº§ç”Ÿ"å·ç‹"ç°è±¡
3. åŠ¨æ€èµ„æºåˆ†é…å’Œç«äº‰
4. èƒ½åŠ›åˆ†æå’Œä¸“ä¸šåŒ–è¶‹åŠ¿
"""

import asyncio
import time
import random
import logging
from typing import Dict, List
import json

# å¯¼å…¥SandGraphæ ¸å¿ƒç»„ä»¶
from sandgraph.core import (
    MultiModelScheduler,
    ModelProfile,
    ModelRole,
    InteractionType,
    TaskDefinition,
    create_multi_model_scheduler,
    create_competitive_scheduler,
    create_cooperative_scheduler,
    BaseLLM,
    MockLLM
)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class DemoLLM(BaseLLM):
    """æ¼”ç¤ºç”¨çš„LLMæ¨¡å‹"""
    
    def __init__(self, model_id: str, specialization: str = "general"):
        super().__init__()
        self.model_id = model_id
        self.specialization = specialization
        self.response_count = 0
    
    def generate(self, prompt: str) -> str:
        """ç”Ÿæˆå“åº”"""
        self.response_count += 1
        
        # åŸºäºä¸“ä¸šåŒ–å’Œæç¤ºç”Ÿæˆå“åº”
        if "æ¨ç†" in prompt or "reasoning" in prompt.lower():
            if self.specialization == "reasoning":
                return f"[{self.model_id}] æ·±åº¦æ¨ç†ç»“æœ: é€šè¿‡é€»è¾‘åˆ†æå¾—å‡ºæœ€ä¼˜è§£"
            else:
                return f"[{self.model_id}] åŸºç¡€æ¨ç†: ä½¿ç”¨æ ‡å‡†æ–¹æ³•è§£å†³é—®é¢˜"
        
        elif "åˆ›æ„" in prompt or "creativity" in prompt.lower():
            if self.specialization == "creativity":
                return f"[{self.model_id}] åˆ›æ–°æƒ³æ³•: æå‡ºçªç ´æ€§è§£å†³æ–¹æ¡ˆ"
            else:
                return f"[{self.model_id}] å¸¸è§„åˆ›æ„: åŸºäºç°æœ‰æ¨¡å¼æ”¹è¿›"
        
        elif "æ•ˆç‡" in prompt or "efficiency" in prompt.lower():
            if self.specialization == "efficiency":
                return f"[{self.model_id}] é«˜æ•ˆæ‰§è¡Œ: ä¼˜åŒ–æµç¨‹ï¼Œå¿«é€Ÿå®Œæˆ"
            else:
                return f"[{self.model_id}] æ ‡å‡†æ‰§è¡Œ: æŒ‰å¸¸è§„æµç¨‹å¤„ç†"
        
        elif "ç«äº‰" in prompt or "competition" in prompt.lower():
            # ç«äº‰æ¨¡å¼ä¸‹ï¼Œæ¨¡å‹ä¼šå°è¯•å±•ç¤ºä¼˜åŠ¿
            if self.specialization == "reasoning":
                return f"[{self.model_id}] ç«äº‰å“åº”: æˆ‘çš„é€»è¾‘åˆ†æèƒ½åŠ›æœ€å¼ºï¼"
            elif self.specialization == "creativity":
                return f"[{self.model_id}] ç«äº‰å“åº”: æˆ‘çš„åˆ›æ–°èƒ½åŠ›æ— äººèƒ½åŠï¼"
            elif self.specialization == "efficiency":
                return f"[{self.model_id}] ç«äº‰å“åº”: æˆ‘çš„æ‰§è¡Œæ•ˆç‡æœ€é«˜ï¼"
            else:
                return f"[{self.model_id}] ç«äº‰å“åº”: æˆ‘å„æ–¹é¢éƒ½å¾ˆå‡è¡¡ï¼"
        
        else:
            return f"[{self.model_id}] é€šç”¨å“åº”: å¤„ç†ä»»åŠ¡ä¸­..."


def create_demo_models() -> List[DemoLLM]:
    """åˆ›å»ºæ¼”ç¤ºæ¨¡å‹"""
    models = [
        DemoLLM("model_1", "reasoning"),
        DemoLLM("model_2", "creativity"),
        DemoLLM("model_3", "efficiency"),
        DemoLLM("model_4", "general"),
        DemoLLM("model_5", "reasoning"),
        DemoLLM("model_6", "creativity")
    ]
    return models


def create_demo_tasks() -> List[TaskDefinition]:
    """åˆ›å»ºæ¼”ç¤ºä»»åŠ¡"""
    tasks = [
        # åˆä½œä»»åŠ¡ - éœ€è¦å¤šä¸ªæ¨¡å‹åä½œ
        TaskDefinition(
            task_id="cooperation_task_1",
            task_type="å¤æ‚é—®é¢˜è§£å†³",
            complexity=0.8,
            required_capabilities=["reasoning", "creativity", "efficiency"],
            collaboration_required=True,
            competition_allowed=False
        ),
        
        # ç«äº‰ä»»åŠ¡ - æ¨¡å‹é—´ç«äº‰
        TaskDefinition(
            task_id="competition_task_1",
            task_type="æœ€ä½³æ–¹æ¡ˆè¯„é€‰",
            complexity=0.7,
            required_capabilities=["reasoning", "creativity"],
            collaboration_required=False,
            competition_allowed=True
        ),
        
        # ä¸­æ€§ä»»åŠ¡ - å¹¶è¡Œæ‰§è¡Œ
        TaskDefinition(
            task_id="neutral_task_1",
            task_type="æ•°æ®åˆ†æ",
            complexity=0.5,
            required_capabilities=["efficiency"],
            collaboration_required=False,
            competition_allowed=False
        ),
        
        # é«˜å¤æ‚åº¦åˆä½œä»»åŠ¡
        TaskDefinition(
            task_id="cooperation_task_2",
            task_type="ç³»ç»Ÿæ¶æ„è®¾è®¡",
            complexity=0.9,
            required_capabilities=["reasoning", "creativity", "efficiency", "accuracy"],
            collaboration_required=True,
            competition_allowed=False
        ),
        
        # èµ„æºå¯†é›†å‹ç«äº‰ä»»åŠ¡
        TaskDefinition(
            task_id="competition_task_2",
            task_type="æ€§èƒ½ä¼˜åŒ–ç«èµ›",
            complexity=0.8,
            required_capabilities=["efficiency", "accuracy"],
            collaboration_required=False,
            competition_allowed=True
        )
    ]
    return tasks


async def run_cooperation_demo():
    """è¿è¡Œåˆä½œæ¼”ç¤º"""
    logger.info("=" * 60)
    logger.info("ğŸš€ å¼€å§‹å¤šæ¨¡å‹åˆä½œæ¼”ç¤º")
    logger.info("=" * 60)
    
    # åˆ›å»ºåˆä½œå¯¼å‘çš„è°ƒåº¦å™¨
    scheduler = create_cooperative_scheduler(
        resource_config={'compute': 50.0, 'memory': 50.0},
        max_concurrent_tasks=5
    )
    
    # æ³¨å†Œæ¨¡å‹
    models = create_demo_models()
    for i, model in enumerate(models):
        role = ModelRole.COLLABORATOR if i < 3 else ModelRole.GENERALIST
        scheduler.register_model(
            model_id=model.model_id,
            model=model,
            role=role,
            initial_capabilities={
                'reasoning': 0.8 if model.specialization == "reasoning" else 0.4,
                'creativity': 0.8 if model.specialization == "creativity" else 0.4,
                'efficiency': 0.8 if model.specialization == "efficiency" else 0.4,
                'accuracy': 0.6,
                'adaptability': 0.7
            }
        )
    
    # åˆ›å»ºåˆä½œä»»åŠ¡
    tasks = [
        TaskDefinition(
            task_id="cooperation_demo_1",
            task_type="å¤æ‚ç³»ç»Ÿè®¾è®¡",
            complexity=0.9,
            required_capabilities=["reasoning", "creativity", "efficiency"],
            collaboration_required=True,
            competition_allowed=False
        ),
        TaskDefinition(
            task_id="cooperation_demo_2",
            task_type="åˆ›æ–°äº§å“å¼€å‘",
            complexity=0.8,
            required_capabilities=["creativity", "reasoning"],
            collaboration_required=True,
            competition_allowed=False
        )
    ]
    
    # æäº¤ä»»åŠ¡
    for task in tasks:
        await scheduler.submit_task(task)
        logger.info(f"æäº¤åˆä½œä»»åŠ¡: {task.task_id}")
    
    # ç­‰å¾…ä»»åŠ¡å®Œæˆ
    await asyncio.sleep(2)
    
    # åˆ†æç»“æœ
    stats = scheduler.get_system_statistics()
    functional_diff = scheduler.get_functional_differentiation_analysis()
    
    logger.info("\nğŸ“Š åˆä½œæ¼”ç¤ºç»“æœ:")
    logger.info(f"æ€»ä»»åŠ¡æ•°: {stats['task_statistics']['total_tasks']}")
    logger.info(f"åˆä½œä»»åŠ¡æ•°: {stats['task_statistics']['cooperation_tasks']}")
    logger.info(f"åŠŸèƒ½åˆ†åŒ–æ°´å¹³: {functional_diff.get('overall_differentiation', 0.0):.3f}")
    
    # æ˜¾ç¤ºæ¨¡å‹ä¸“ä¸šåŒ–è¶‹åŠ¿
    logger.info("\nğŸ¯ æ¨¡å‹ä¸“ä¸šåŒ–åˆ†æ:")
    for model_id, profile in scheduler.model_profiles.items():
        logger.info(f"  {model_id}: ä¸“ä¸šåŒ–åˆ†æ•° = {profile.specialization_score:.3f}")
    
    return scheduler


async def run_competition_demo():
    """è¿è¡Œç«äº‰æ¼”ç¤º"""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ† å¼€å§‹å¤šæ¨¡å‹ç«äº‰æ¼”ç¤º")
    logger.info("=" * 60)
    
    # åˆ›å»ºç«äº‰å¯¼å‘çš„è°ƒåº¦å™¨
    scheduler = create_competitive_scheduler(
        resource_config={'compute': 30.0, 'memory': 30.0},  # é™åˆ¶èµ„æºä»¥å¢åŠ ç«äº‰
        max_concurrent_tasks=5
    )
    
    # æ³¨å†Œæ¨¡å‹
    models = create_demo_models()
    for i, model in enumerate(models):
        role = ModelRole.COMPETITOR if i < 3 else ModelRole.GENERALIST
        scheduler.register_model(
            model_id=model.model_id,
            model=model,
            role=role,
            initial_capabilities={
                'reasoning': 0.7 if model.specialization == "reasoning" else 0.5,
                'creativity': 0.7 if model.specialization == "creativity" else 0.5,
                'efficiency': 0.7 if model.specialization == "efficiency" else 0.5,
                'accuracy': 0.6,
                'adaptability': 0.8  # ç«äº‰ç¯å¢ƒä¸‹éœ€è¦é«˜é€‚åº”æ€§
            }
        )
    
    # åˆ›å»ºç«äº‰ä»»åŠ¡
    tasks = [
        TaskDefinition(
            task_id="competition_demo_1",
            task_type="æœ€ä½³ç®—æ³•ç«èµ›",
            complexity=0.8,
            required_capabilities=["reasoning", "efficiency"],
            collaboration_required=False,
            competition_allowed=True
        ),
        TaskDefinition(
            task_id="competition_demo_2",
            task_type="åˆ›æ–°æ–¹æ¡ˆè¯„é€‰",
            complexity=0.7,
            required_capabilities=["creativity", "reasoning"],
            collaboration_required=False,
            competition_allowed=True
        ),
        TaskDefinition(
            task_id="competition_demo_3",
            task_type="æ€§èƒ½ä¼˜åŒ–ç«èµ›",
            complexity=0.9,
            required_capabilities=["efficiency", "accuracy"],
            collaboration_required=False,
            competition_allowed=True
        )
    ]
    
    # æäº¤ä»»åŠ¡
    for task in tasks:
        await scheduler.submit_task(task)
        logger.info(f"æäº¤ç«äº‰ä»»åŠ¡: {task.task_id}")
    
    # ç­‰å¾…ä»»åŠ¡å®Œæˆ
    await asyncio.sleep(3)
    
    # åˆ†æç»“æœ
    stats = scheduler.get_system_statistics()
    competition_analysis = scheduler.get_competition_analysis()
    
    logger.info("\nğŸ“Š ç«äº‰æ¼”ç¤ºç»“æœ:")
    logger.info(f"æ€»ä»»åŠ¡æ•°: {stats['task_statistics']['total_tasks']}")
    logger.info(f"ç«äº‰ä»»åŠ¡æ•°: {stats['task_statistics']['competition_tasks']}")
    logger.info(f"ç«äº‰å¼ºåº¦: {competition_analysis['competition_intensity']:.3f}")
    logger.info(f"èµ„æºç«äº‰æ°´å¹³: {competition_analysis['resource_contention_level']:.3f}")
    logger.info(f"å·ç‹ç°è±¡: {'æ˜¯' if competition_analysis['volume_king_phenomenon'] else 'å¦'}")
    
    # æ˜¾ç¤ºç«äº‰ç»“æœ
    logger.info("\nğŸ† ç«äº‰ç»“æœåˆ†æ:")
    for task_info in scheduler.task_history:
        if task_info['interaction_type'] == 'competition':
            results = task_info['results']
            if 'winner' in results:
                logger.info(f"  ä»»åŠ¡ {task_info['task_id']}: è·èƒœè€… = {results['winner']}")
    
    return scheduler


async def run_mixed_demo():
    """è¿è¡Œæ··åˆæ¨¡å¼æ¼”ç¤º"""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ”„ å¼€å§‹æ··åˆæ¨¡å¼æ¼”ç¤º")
    logger.info("=" * 60)
    
    # åˆ›å»ºæ··åˆè°ƒåº¦å™¨
    scheduler = create_multi_model_scheduler(
        resource_config={'compute': 80.0, 'memory': 80.0},
        max_concurrent_tasks=10,
        enable_competition=True,
        enable_cooperation=True
    )
    
    # æ³¨å†Œæ¨¡å‹
    models = create_demo_models()
    for i, model in enumerate(models):
        if i < 2:
            role = ModelRole.COLLABORATOR
        elif i < 4:
            role = ModelRole.COMPETITOR
        else:
            role = ModelRole.GENERALIST
        
        scheduler.register_model(
            model_id=model.model_id,
            model=model,
            role=role,
            initial_capabilities={
                'reasoning': 0.7 if model.specialization == "reasoning" else 0.5,
                'creativity': 0.7 if model.specialization == "creativity" else 0.5,
                'efficiency': 0.7 if model.specialization == "efficiency" else 0.5,
                'accuracy': 0.6,
                'adaptability': 0.8
            }
        )
    
    # åˆ›å»ºæ··åˆä»»åŠ¡
    tasks = create_demo_tasks()
    
    # æäº¤ä»»åŠ¡
    for task in tasks:
        await scheduler.submit_task(task)
        logger.info(f"æäº¤ä»»åŠ¡: {task.task_id} ({task.task_type})")
    
    # ç­‰å¾…ä»»åŠ¡å®Œæˆ
    await asyncio.sleep(4)
    
    # åˆ†æç»“æœ
    stats = scheduler.get_system_statistics()
    functional_diff = scheduler.get_functional_differentiation_analysis()
    competition_analysis = scheduler.get_competition_analysis()
    
    logger.info("\nğŸ“Š æ··åˆæ¨¡å¼ç»“æœ:")
    logger.info(f"æ€»ä»»åŠ¡æ•°: {stats['task_statistics']['total_tasks']}")
    logger.info(f"åˆä½œä»»åŠ¡æ•°: {stats['task_statistics']['cooperation_tasks']}")
    logger.info(f"ç«äº‰ä»»åŠ¡æ•°: {stats['task_statistics']['competition_tasks']}")
    logger.info(f"ä¸­æ€§ä»»åŠ¡æ•°: {stats['task_statistics']['neutral_tasks']}")
    logger.info(f"åŠŸèƒ½åˆ†åŒ–æ°´å¹³: {functional_diff.get('overall_differentiation', 0.0):.3f}")
    logger.info(f"ç«äº‰å¼ºåº¦: {competition_analysis['competition_intensity']:.3f}")
    logger.info(f"å·ç‹ç°è±¡: {'æ˜¯' if competition_analysis['volume_king_phenomenon'] else 'å¦'}")
    
    return scheduler


def analyze_differentiation_phenomenon(scheduler: MultiModelScheduler):
    """åˆ†æåŠŸèƒ½åˆ†åŒ–ç°è±¡"""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ”¬ åŠŸèƒ½åˆ†åŒ–ç°è±¡åˆ†æ")
    logger.info("=" * 60)
    
    functional_diff = scheduler.get_functional_differentiation_analysis()
    
    if 'capability_matrix' in functional_diff:
        logger.info("ğŸ“ˆ èƒ½åŠ›çŸ©é˜µåˆ†æ:")
        for capability, scores in functional_diff['capability_matrix'].items():
            variance = functional_diff['differentiation_metrics'][capability]['variance']
            specialization_index = functional_diff['differentiation_metrics'][capability]['specialization_index']
            logger.info(f"  {capability}: æ–¹å·®={variance:.3f}, ä¸“ä¸šåŒ–æŒ‡æ•°={specialization_index:.3f}")
    
    logger.info(f"\nğŸ¯ æ•´ä½“åˆ†åŒ–æ°´å¹³: {functional_diff.get('overall_differentiation', 0.0):.3f}")
    
    # åˆ†ææ¨¡å‹ä¸“ä¸šåŒ–è¶‹åŠ¿
    logger.info("\nğŸ“Š æ¨¡å‹ä¸“ä¸šåŒ–è¶‹åŠ¿:")
    for model_id, profile in scheduler.model_profiles.items():
        logger.info(f"  {model_id}:")
        logger.info(f"    ä¸“ä¸šåŒ–åˆ†æ•°: {profile.specialization_score:.3f}")
        logger.info(f"    èƒ½åŠ›åˆ†å¸ƒ: {profile.capabilities}")
        logger.info(f"    è§’è‰²: {profile.role.value}")


def analyze_volume_king_phenomenon(scheduler: MultiModelScheduler):
    """åˆ†æå·ç‹ç°è±¡"""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ‘‘ å·ç‹ç°è±¡åˆ†æ")
    logger.info("=" * 60)
    
    competition_analysis = scheduler.get_competition_analysis()
    
    logger.info(f"ğŸ“Š ç«äº‰ç»Ÿè®¡:")
    logger.info(f"  æ€»ç«äº‰æ¬¡æ•°: {competition_analysis['competition_stats']['total_competitions']}")
    logger.info(f"  ç«äº‰å¼ºåº¦: {competition_analysis['competition_intensity']:.3f}")
    logger.info(f"  èµ„æºç«äº‰æ°´å¹³: {competition_analysis['resource_contention_level']:.3f}")
    logger.info(f"  å·ç‹ç°è±¡: {'æ˜¯' if competition_analysis['volume_king_phenomenon'] else 'å¦'}")
    
    # åˆ†æèµ„æºç«äº‰è¯¦æƒ…
    logger.info("\nğŸ’¾ èµ„æºç«äº‰è¯¦æƒ…:")
    for resource_type, allocation_rate in competition_analysis['competition_stats']['allocation_rates'].items():
        logger.info(f"  {resource_type}: åˆ†é…ç‡ = {allocation_rate:.3f}")
    
    # åˆ†æè·èƒœè€…æ¨¡å¼
    logger.info("\nğŸ† è·èƒœè€…åˆ†æ:")
    winners = {}
    for task_info in scheduler.task_history:
        if task_info['interaction_type'] == 'competition':
            results = task_info['results']
            if 'winner' in results and results['winner'] != 'none':
                winner = results['winner']
                winners[winner] = winners.get(winner, 0) + 1
    
    for winner, count in sorted(winners.items(), key=lambda x: x[1], reverse=True):
        logger.info(f"  {winner}: è·èƒœ {count} æ¬¡")


async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¤šæ¨¡å‹åˆä½œä¸å¯¹æŠ—æ¼”ç¤ºå¼€å§‹")
    
    try:
        # 1. åˆä½œæ¼”ç¤º
        cooperation_scheduler = await run_cooperation_demo()
        analyze_differentiation_phenomenon(cooperation_scheduler)
        
        # 2. ç«äº‰æ¼”ç¤º
        competition_scheduler = await run_competition_demo()
        analyze_volume_king_phenomenon(competition_scheduler)
        
        # 3. æ··åˆæ¨¡å¼æ¼”ç¤º
        mixed_scheduler = await run_mixed_demo()
        
        # 4. ç»¼åˆåˆ†æ
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“‹ ç»¼åˆå¯¹æ¯”åˆ†æ")
        logger.info("=" * 60)
        
        cooperation_stats = cooperation_scheduler.get_system_statistics()
        competition_stats = competition_scheduler.get_system_statistics()
        mixed_stats = mixed_scheduler.get_system_statistics()
        
        logger.info("ğŸ“Š æ¨¡å¼å¯¹æ¯”:")
        logger.info(f"  åˆä½œæ¨¡å¼ - åŠŸèƒ½åˆ†åŒ–: {cooperation_scheduler.get_functional_differentiation_analysis().get('overall_differentiation', 0.0):.3f}")
        logger.info(f"  ç«äº‰æ¨¡å¼ - ç«äº‰å¼ºåº¦: {competition_scheduler.get_competition_analysis()['competition_intensity']:.3f}")
        logger.info(f"  æ··åˆæ¨¡å¼ - å¹³è¡¡æ€§: {(mixed_stats['task_statistics']['cooperation_tasks'] + mixed_stats['task_statistics']['competition_tasks']) / max(mixed_stats['task_statistics']['total_tasks'], 1):.3f}")
        
        # ä¿å­˜ç»“æœ
        results = {
            'cooperation_demo': cooperation_stats,
            'competition_demo': competition_stats,
            'mixed_demo': mixed_stats,
            'functional_differentiation': cooperation_scheduler.get_functional_differentiation_analysis(),
            'volume_king_analysis': competition_scheduler.get_competition_analysis()
        }
        
        with open('multi_model_demo_results.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info("\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ° multi_model_demo_results.json")
        
        # å…³é—­è°ƒåº¦å™¨
        await cooperation_scheduler.shutdown()
        await competition_scheduler.shutdown()
        await mixed_scheduler.shutdown()
        
        logger.info("\nğŸ‰ å¤šæ¨¡å‹åˆä½œä¸å¯¹æŠ—æ¼”ç¤ºå®Œæˆï¼")
        
    except Exception as e:
        logger.error(f"æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
