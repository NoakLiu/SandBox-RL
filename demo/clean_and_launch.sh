#!/usr/bin/env bash
set -euo pipefail

MODEL_PATH="/cpfs04/shared/kilab/hf-hub/Qwen2.5-7B-Instruct"
BASE_PORT=8001

echo "ğŸ§¹ æ¸…ç†vLLMç¼“å­˜å’Œè¿›ç¨‹..."

# åœæ­¢æ‰€æœ‰vLLMè¿›ç¨‹
echo "ğŸ›‘ åœæ­¢vLLMè¿›ç¨‹..."
pkill -f "vllm serve" || true
sleep 3

# æ¸…ç†ç¼–è¯‘ç¼“å­˜
echo "ğŸ—‘ï¸ æ¸…ç†ç¼–è¯‘ç¼“å­˜..."
rm -rf ~/.cache/vllm/torch_compile_cache || true
rm -rf ~/.cache/torch/compiled_cache || true

echo "â³ ç­‰å¾…æ¸…ç†å®Œæˆ..."
sleep 5

echo "ğŸš€ å¯åŠ¨å•ä¸ªæµ‹è¯•å®ä¾‹..."

# å¯åŠ¨å•ä¸ªæµ‹è¯•å®ä¾‹
CUDA_VISIBLE_DEVICES=0 \
vllm serve "${MODEL_PATH}" \
  --port "${BASE_PORT}" \
  --gpu-memory-utilization 0.3 \
  --max-model-len 8192 \
  --max-num-seqs 64 \
  --served-model-name qwen-2 \
  > test_clean.log 2>&1 &

echo "â³ ç­‰å¾…å®ä¾‹å¯åŠ¨..."
sleep 30

echo "ğŸ” æ£€æŸ¥å®ä¾‹çŠ¶æ€..."
if curl -s "http://localhost:${BASE_PORT}/health" > /dev/null 2>&1; then
  echo "âœ… æ¸…ç†åå¯åŠ¨æˆåŠŸï¼"
  echo "ğŸ“Š å¥åº·æ£€æŸ¥å“åº”:"
  curl -s "http://localhost:${BASE_PORT}/health"
else
  echo "âŒ å¯åŠ¨å¤±è´¥"
  echo "ğŸ“ æŸ¥çœ‹æ—¥å¿—:"
  tail -20 test_clean.log
fi

echo ""
echo "ğŸ§¹ æ¸…ç†æµ‹è¯•å®ä¾‹..."
pkill -f "vllm serve" || true
