#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è®¾ç½®LoRAç›®å½•ç»“æ„
"""

import os
import json
import shutil
from pathlib import Path

# é…ç½®
CPFS_BASE = "/cpfs04/shared/kilab/liudong"

def create_mock_lora_checkpoint(lora_id: int, output_dir: str):
    """åˆ›å»ºæ¨¡æ‹Ÿçš„LoRA checkpoint"""
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºadapter_config.json
    config = {
        "base_model_name_or_path": "qwen-2",
        "bias": "none",
        "enable_lora": None,
        "fan_in_fan_out": False,
        "inference_mode": True,
        "lora_alpha": 16.0,
        "lora_dropout": 0.1,
        "modules_to_save": None,
        "peft_type": "LORA",
        "r": 8,
        "target_modules": ["q_proj", "v_proj"],
        "task_type": "CAUSAL_LM"
    }
    
    with open(output_path / "adapter_config.json", "w") as f:
        json.dump(config, f, indent=2)
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„adapter_model.binï¼ˆå®é™…åº”è¯¥æ˜¯çœŸå®çš„æƒé‡æ–‡ä»¶ï¼‰
    with open(output_path / "adapter_model.bin", "wb") as f:
        f.write(b"mock_lora_weights_for_demo")
    
    print(f"âœ… åˆ›å»ºLoRA {lora_id}: {output_path}")

def setup_lora_directories():
    """è®¾ç½®LoRAç›®å½•ç»“æ„"""
    print(f"ğŸ”§ è®¾ç½®LoRAç›®å½•ç»“æ„: {CPFS_BASE}")
    
    # åˆ›å»ºåŸºç¡€ç›®å½•
    base_path = Path(CPFS_BASE)
    base_path.mkdir(parents=True, exist_ok=True)
    print(f"âœ… åˆ›å»ºåŸºç¡€ç›®å½•: {base_path}")
    
    # ä¸ºæ¯ä¸ªLoRAåˆ›å»ºç›®å½•å’Œcheckpoint
    for i in range(1, 9):
        lora_dir = base_path / f"lora{i}"
        create_mock_lora_checkpoint(i, str(lora_dir))
    
    print(f"\nğŸ‰ LoRAç›®å½•è®¾ç½®å®Œæˆï¼")
    print(f"ğŸ“ ç›®å½•ç»“æ„:")
    for i in range(1, 9):
        lora_dir = base_path / f"lora{i}"
        print(f"   lora{i}: {lora_dir}")
        if (lora_dir / "adapter_config.json").exists():
            print(f"     âœ… adapter_config.json")
        if (lora_dir / "adapter_model.bin").exists():
            print(f"     âœ… adapter_model.bin")

if __name__ == "__main__":
    setup_lora_directories()
