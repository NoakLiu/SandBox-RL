#!/usr/bin/env python3
"""
SandGraph OASIS APIé›†æˆæ¼”ç¤º - åŸºäºçœŸå®OASIS API

é›†æˆçœŸå®çš„OASIS (Open Agent Social Interaction Simulations) APIåˆ°SandGraphæ¡†æ¶ï¼š
1. ä½¿ç”¨çœŸå®çš„OASIS APIè¿›è¡Œå¤§è§„æ¨¡ç¤¾äº¤ç½‘ç»œæ¨¡æ‹Ÿ
2. æ™ºèƒ½ä½“è¡Œä¸ºåˆ†æå’Œä¼˜åŒ–
3. ç¤¾äº¤ç½‘ç»œåŠ¨æ€ç ”ç©¶
4. ä¸SandGraphçš„RLä¼˜åŒ–æ¡†æ¶é›†æˆ
"""

import sys
import os
import time
import json
import argparse
import asyncio
from typing import Dict, Any, List, Union, Optional
from datetime import datetime, timedelta
import re

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from sandgraph.core.llm_interface import create_shared_llm_manager
from sandgraph.core.sg_workflow import (
    SG_Workflow, WorkflowMode, EnhancedWorkflowNode,
    NodeType, NodeCondition, NodeLimits, GameState
)
from sandgraph.core.rl_algorithms import RLTrainer, RLConfig, RLAlgorithm


class OasisAPISandbox:
    """OASIS APIæ²™ç›’ - é›†æˆçœŸå®OASIS API"""
    
    def __init__(self, 
                 profile_path: str = None,
                 database_path: str = "./data/oasis_simulation.db",
                 platform: str = "reddit",
                 available_actions: List[str] = None):
        
        self.sandbox_id = f"oasis_api_{int(time.time())}"
        self.profile_path = profile_path
        self.database_path = database_path
        self.platform = platform
        self.available_actions = available_actions or [
            "like_post", "dislike_post", "create_post", "create_comment",
            "like_comment", "dislike_comment", "search_posts", "search_user",
            "trend", "refresh", "do_nothing", "follow", "mute"
        ]
        
        # OASISç¯å¢ƒçŠ¶æ€
        self.env = None
        self.agent_graph = None
        self.current_state = {}
        self.interaction_history = []
        
        # åˆå§‹åŒ–OASISç¯å¢ƒ
        self._initialize_oasis_environment()
    
    def _initialize_oasis_environment(self):
        """åˆå§‹åŒ–OASISç¯å¢ƒ"""
        try:
            # å°è¯•å¯¼å…¥OASIS
            import oasis
            from camel.models import ModelFactory
            from camel.types import ModelPlatformType, ModelType
            from oasis import ActionType, LLMAction, ManualAction, generate_reddit_agent_graph
            
            print("âœ… OASIS API å¯¼å…¥æˆåŠŸ")
            
            # åˆ›å»ºé»˜è®¤ç”¨æˆ·é…ç½®æ–‡ä»¶ï¼ˆå¦‚æœæœªæä¾›ï¼‰
            if not self.profile_path:
                self.profile_path = self._create_default_profile()
            
            # å®šä¹‰æ¨¡å‹
            self.model = ModelFactory.create(
                model_platform=ModelPlatformType.OPENAI,
                model_type=ModelType.GPT_4O_MINI,
            )
            
            # è½¬æ¢åŠ¨ä½œç±»å‹
            action_types = []
            for action in self.available_actions:
                if hasattr(ActionType, action.upper()):
                    action_types.append(getattr(ActionType, action.upper()))
            
            # ç”Ÿæˆæ™ºèƒ½ä½“å›¾
            self.agent_graph = asyncio.run(generate_reddit_agent_graph(
                profile_path=self.profile_path,
                model=self.model,
                available_actions=action_types,
            ))
            
            # åˆ›å»ºç¯å¢ƒ
            self.env = oasis.make(
                agent_graph=self.agent_graph,
                platform=oasis.DefaultPlatformType.REDDIT,
                database_path=self.database_path,
            )
            
            print(f"âœ… OASISç¯å¢ƒåˆå§‹åŒ–æˆåŠŸ: {self.platform}")
            
        except ImportError as e:
            print(f"âŒ OASIS API å¯¼å…¥å¤±è´¥: {e}")
            print("è¯·å®‰è£…OASIS: pip install camel-oasis")
            self.env = None
        except Exception as e:
            print(f"âŒ OASISç¯å¢ƒåˆå§‹åŒ–å¤±è´¥: {e}")
            self.env = None
    
    def _create_default_profile(self) -> str:
        """åˆ›å»ºé»˜è®¤ç”¨æˆ·é…ç½®æ–‡ä»¶"""
        import tempfile
        import os
        
        # åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶
        profile_data = {
            "user_id": "default_user",
            "interests": ["technology", "AI", "programming"],
            "personality": {
                "openness": 0.8,
                "conscientiousness": 0.7,
                "extraversion": 0.6,
                "agreeableness": 0.7,
                "neuroticism": 0.3
            },
            "social_network": {
                "followers": [],
                "following": [],
                "posts": [],
                "comments": []
            },
            "behavior_patterns": {
                "post_frequency": 0.3,
                "comment_frequency": 0.5,
                "like_frequency": 0.7,
                "share_frequency": 0.2
            }
        }
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        temp_dir = "./data"
        os.makedirs(temp_dir, exist_ok=True)
        profile_path = os.path.join(temp_dir, "default_user_profile.json")
        
        with open(profile_path, 'w') as f:
            json.dump(profile_data, f, indent=2)
        
        print(f"âœ… åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶: {profile_path}")
        return profile_path
    
    async def reset_environment(self):
        """é‡ç½®OASISç¯å¢ƒ"""
        if self.env:
            try:
                await self.env.reset()
                print("âœ… OASISç¯å¢ƒé‡ç½®æˆåŠŸ")
            except Exception as e:
                print(f"âŒ OASISç¯å¢ƒé‡ç½®å¤±è´¥: {e}")
    
    async def execute_action(self, agent_id: int, action_type: str, action_args: Dict[str, Any] = None):
        """æ‰§è¡ŒOASISåŠ¨ä½œ"""
        if not self.env or not self.agent_graph:
            return {"success": False, "error": "OASISç¯å¢ƒæœªåˆå§‹åŒ–"}
        
        try:
            from oasis import ActionType, LLMAction, ManualAction
            
            # è·å–æ™ºèƒ½ä½“
            agent = self.agent_graph.get_agent(agent_id)
            if not agent:
                return {"success": False, "error": f"æ™ºèƒ½ä½“ {agent_id} ä¸å­˜åœ¨"}
            
            # åˆ›å»ºåŠ¨ä½œ
            if action_args:
                action = ManualAction(
                    action_type=getattr(ActionType, action_type.upper()),
                    action_args=action_args
                )
            else:
                action = LLMAction()
            
            # æ‰§è¡ŒåŠ¨ä½œ
            actions = {agent: action}
            result = await self.env.step(actions)
            
            return {
                "success": True,
                "result": result,
                "agent_id": agent_id,
                "action_type": action_type
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def case_generator(self) -> Dict[str, Any]:
        """ç”Ÿæˆå½“å‰çŠ¶æ€"""
        if not self.env:
            return self._generate_fallback_state()
        
        try:
            # è·å–OASISç¯å¢ƒçŠ¶æ€
            state = {
                "platform": self.platform,
                "agents_count": len(self.agent_graph.get_agents()) if self.agent_graph else 0,
                "database_path": self.database_path,
                "available_actions": self.available_actions,
                "interaction_history": self.interaction_history[-10:],
                "timestamp": datetime.now().isoformat()
            }
            
            return {
                "state": state,
                "metadata": {
                    "sandbox_id": self.sandbox_id,
                    "timestamp": datetime.now().isoformat()
                }
            }
            
        except Exception as e:
            print(f"âŒ è·å–OASISçŠ¶æ€å¤±è´¥: {e}")
            return self._generate_fallback_state()
    
    def _generate_fallback_state(self) -> Dict[str, Any]:
        """ç”Ÿæˆå¤‡ç”¨çŠ¶æ€ï¼ˆå½“OASISä¸å¯ç”¨æ—¶ï¼‰"""
        return {
            "state": {
                "platform": self.platform,
                "agents_count": 0,
                "database_path": self.database_path,
                "available_actions": self.available_actions,
                "interaction_history": [],
                "oasis_available": False,
                "timestamp": datetime.now().isoformat()
            },
            "metadata": {
                "sandbox_id": self.sandbox_id,
                "timestamp": datetime.now().isoformat()
            }
        }
    
    def verify_score(self, action: str, case: Dict[str, Any]) -> float:
        """éªŒè¯OASISåŠ¨ä½œçš„æ•ˆæœ"""
        try:
            # è§£æåŠ¨ä½œ
            action_parts = action.split()
            if len(action_parts) < 2:
                return 0.0
            
            action_type = action_parts[0].lower()
            target = action_parts[1] if len(action_parts) > 1 else "general"
            
            # åŸºç¡€åˆ†æ•°
            base_score = 0.0
            
            # æ ¹æ®åŠ¨ä½œç±»å‹è¯„åˆ†
            if action_type == "create_post":
                base_score = 0.7
            elif action_type == "create_comment":
                base_score = 0.6
            elif action_type == "like_post":
                base_score = 0.4
            elif action_type == "follow":
                base_score = 0.5
            elif action_type == "search_posts":
                base_score = 0.3
            elif action_type == "trend":
                base_score = 0.8
            else:
                base_score = 0.2
            
            # æ ¹æ®ç›®æ ‡è°ƒæ•´åˆ†æ•°
            if target == "engagement":
                base_score *= 1.2
            elif target == "growth":
                base_score *= 1.1
            elif target == "general":
                base_score *= 1.0
            
            # è€ƒè™‘OASISå¯ç”¨æ€§
            current_state = case["state"]
            if not current_state.get("oasis_available", True):
                base_score *= 0.5  # OASISä¸å¯ç”¨æ—¶é™ä½åˆ†æ•°
            
            # é™åˆ¶åˆ†æ•°èŒƒå›´
            return min(1.0, max(0.0, base_score))
            
        except Exception as e:
            print(f"è¯„åˆ†é”™è¯¯: {e}")
            return 0.0
    
    async def execute_oasis_action(self, agent_id: int, action_type: str, action_args: Dict[str, Any] = None) -> Dict[str, Any]:
        """æ‰§è¡ŒOASISåŠ¨ä½œ"""
        result = await self.execute_action(agent_id, action_type, action_args)
        
        # è®°å½•äº¤äº’å†å²
        self.interaction_history.append({
            "timestamp": datetime.now().isoformat(),
            "agent_id": agent_id,
            "action_type": action_type,
            "action_args": action_args,
            "success": result.get("success", False)
        })
        
        return result


class LLMOasisDecisionMaker:
    """LLM OASISå†³ç­–å™¨"""
    
    def __init__(self, llm_manager):
        self.llm_manager = llm_manager
        self.decision_count = 0
        
        # å†å²æ•°æ®ç®¡ç†
        self.decision_history = []
        self.oasis_history = []
        
        # æ³¨å†Œå†³ç­–èŠ‚ç‚¹
        self.llm_manager.register_node("oasis_decision", {
            "role": "OASISç¤¾äº¤ç½‘ç»œè¡Œä¸ºä¸“å®¶",
            "reasoning_type": "strategic",
            "temperature": 0.7,
            "max_length": 512
        })
    
    def make_decision(self, current_state: Dict[str, Any]) -> Dict[str, Any]:
        """åŸºäºå½“å‰çŠ¶æ€åšå‡ºOASISå†³ç­–"""
        self.decision_count += 1
        
        # æ„å»ºå†³ç­–æç¤º
        prompt = self._construct_decision_prompt(current_state)
        
        print("=" * 80)
        print(f"OASIS Decision {self.decision_count} - Complete Prompt Content:")
        print("=" * 80)
        print(prompt)
        print("=" * 80)
        
        try:
            # ç”ŸæˆLLMå“åº”
            response = self.llm_manager.generate_for_node(
                "oasis_decision",
                prompt,
                temperature=0.7,
                max_new_tokens=256,
                do_sample=True
            )
            
            print(f"LLM Response Status: {response.status if hasattr(response, 'status') else 'unknown'}")
            print(f"LLM Complete Response: {response.text}")
            
            # è§£æå“åº”
            decision = self._parse_decision_response(response.text)
            
            # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨æ›´å®½æ¾çš„è§£æ
            if decision is None:
                decision = self._parse_decision_fallback(response.text)
            
            # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å†³ç­–
            if decision is None:
                decision = {
                    "agent_id": 0,
                    "action_type": "create_post",
                    "action_args": {"content": "Hello OASIS world!"},
                    "reasoning": "Fallback decision due to parsing failure"
                }
            
            # æ›´æ–°å†å²æ•°æ®
            self._update_history(current_state, decision, response.text)
            
            return {
                "decision": decision,
                "llm_response": response.text,
                "prompt": prompt,
                "decision_count": self.decision_count
            }
            
        except Exception as e:
            print(f"âŒ OASIS decision generation failed: {e}")
            fallback_decision = {
                "agent_id": 0,
                "action_type": "create_post",
                "action_args": {"content": "Hello OASIS world!"},
                "reasoning": f"Error in decision generation: {str(e)}"
            }
            
            # æ›´æ–°å†å²æ•°æ®ï¼ˆå³ä½¿å¤±è´¥ï¼‰
            self._update_history(current_state, fallback_decision, f"Error: {str(e)}")
            
            return {
                "decision": fallback_decision,
                "llm_response": f"Error: {str(e)}",
                "prompt": prompt,
                "decision_count": self.decision_count
            }
    
    def _update_history(self, state: Dict[str, Any], decision: Dict[str, Any], llm_response: str):
        """æ›´æ–°å†å²æ•°æ®"""
        # è®°å½•å†³ç­–å†å²
        decision_record = {
            "step": self.decision_count,
            "timestamp": datetime.now().isoformat(),
            "decision": decision,
            "llm_response": llm_response,
            "oasis_state": state,
        }
        self.decision_history.append(decision_record)
        
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
        if len(self.decision_history) > 50:
            self.decision_history = self.decision_history[-50:]
    
    def _construct_decision_prompt(self, state: Dict[str, Any]) -> str:
        """æ„é€ å†³ç­–æç¤º"""
        platform = state.get("platform", "reddit")
        agents_count = state.get("agents_count", 0)
        available_actions = state.get("available_actions", [])
        oasis_available = state.get("oasis_available", True)
        
        # æ„å»ºOASISçŠ¶æ€æ‘˜è¦
        oasis_summary = f"""
OASIS Platform Status:
- Platform: {platform}
- Agents Count: {agents_count}
- OASIS Available: {oasis_available}
- Available Actions: {', '.join(available_actions[:5])}...
"""
        
        # æ„å»ºå†³ç­–å†å²æ‘˜è¦
        history_summary = ""
        if self.decision_history:
            recent_decisions = self.decision_history[-3:]  # æœ€è¿‘3ä¸ªå†³ç­–
            history_summary = "\nRecent OASIS Actions:\n"
            for record in recent_decisions:
                decision = record["decision"]
                history_summary += f"- Step {record['step']}: Agent {decision.get('agent_id', '')} {decision.get('action_type', '')} - {decision.get('reasoning', '')[:30]}...\n"
        
        # é‡æ„åçš„ç®€æ´æç¤º
        prompt = f"""You are an OASIS social network behavior expert.

REQUIRED RESPONSE FORMAT:
ACTION: [AGENT_ID] [ACTION_TYPE] [ACTION_ARGS]
REASONING: [brief explanation]

Available Actions: {', '.join(available_actions)}

Available Agents: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9

{oasis_summary.strip()}
{history_summary.strip()}

Choose the best OASIS action to maximize social engagement and network growth. Respond ONLY in the required format above."""
        
        return prompt
    
    def _parse_decision_response(self, response: str) -> Optional[Dict[str, Any]]:
        """è§£æLLMå†³ç­–å“åº”"""
        response = response.strip()
        
        print(f"ğŸ” è§£æå“åº”: {response[:200]}...")
        
        # å°è¯•è§£ææ ‡å‡†æ ¼å¼
        try:
            # æŸ¥æ‰¾ACTIONè¡Œ - æ”¯æŒå¤šç§æ ¼å¼
            action_patterns = [
                # æ ‡å‡†æ ¼å¼: ACTION: 0 create_post {"content": "Hello"}
                r'ACTION:\s*(\d+)\s+([a-z_]+)\s+(.+)',
                # å°å†™æ ¼å¼: action: 0 create_post {"content": "Hello"}
                r'action:\s*(\d+)\s+([a-z_]+)\s+(.+)',
                # é¦–å­—æ¯å¤§å†™æ ¼å¼: Action: 0 Create_Post {"content": "Hello"}
                r'Action:\s*(\d+)\s+([A-Z_]+)\s+(.+)',
            ]
            
            agent_id = None
            action_type = None
            action_args = None
            
            for pattern in action_patterns:
                action_match = re.search(pattern, response, re.IGNORECASE)
                if action_match:
                    agent_id = int(action_match.group(1))
                    action_type = action_match.group(2).lower()
                    action_args_str = action_match.group(3).strip()
                    
                    # å°è¯•è§£æaction_args
                    try:
                        action_args = json.loads(action_args_str)
                    except json.JSONDecodeError:
                        # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œåˆ›å»ºç®€å•çš„å‚æ•°
                        action_args = {"content": action_args_str}
                    
                    print(f"âœ… æ‰¾åˆ°ACTION: Agent {agent_id} {action_type} {action_args}")
                    break
            
            if agent_id is None or action_type is None:
                print("âŒ æœªæ‰¾åˆ°å®Œæ•´çš„ACTIONå­—æ®µ")
                return None
            
            # éªŒè¯æ™ºèƒ½ä½“ID
            if agent_id < 0 or agent_id > 9:
                print(f"âŒ æ— æ•ˆçš„AGENT_ID: {agent_id}")
                return None
            
            # éªŒè¯åŠ¨ä½œç±»å‹
            valid_actions = [
                "like_post", "dislike_post", "create_post", "create_comment",
                "like_comment", "dislike_comment", "search_posts", "search_user",
                "trend", "refresh", "do_nothing", "follow", "mute"
            ]
            
            if action_type not in valid_actions:
                print(f"âŒ æ— æ•ˆçš„ACTION_TYPE: {action_type}")
                return None
            
            # æŸ¥æ‰¾REASONINGè¡Œ
            reasoning_patterns = [
                r'REASONING:\s*(.+?)(?:\n|$)',  # æ ‡å‡†æ ¼å¼
                r'reasoning:\s*(.+?)(?:\n|$)',  # å°å†™
                r'Reasoning:\s*(.+?)(?:\n|$)',  # é¦–å­—æ¯å¤§å†™
            ]
            
            reasoning = "No reasoning provided"
            for pattern in reasoning_patterns:
                reasoning_match = re.search(pattern, response, re.IGNORECASE)
                if reasoning_match:
                    reasoning = reasoning_match.group(1).strip()
                    print(f"âœ… æ‰¾åˆ°REASONING: {reasoning[:50]}...")
                    break
            
            print(f"âœ… è§£ææˆåŠŸ: Agent {agent_id} {action_type} | {reasoning[:30]}...")
            
            return {
                "agent_id": agent_id,
                "action_type": action_type,
                "action_args": action_args,
                "reasoning": reasoning
            }
            
        except Exception as e:
            print(f"âŒ Decision parsing failed: {e}")
            return None
    
    def _parse_decision_fallback(self, response: str) -> Optional[Dict[str, Any]]:
        """å¤‡ç”¨å†³ç­–è§£æé€»è¾‘"""
        # å°è¯•ä»å“åº”ä¸­æå–ä»»ä½•å¯èƒ½çš„åŠ¨ä½œ
        response_upper = response.upper()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä»»ä½•æœ‰æ•ˆåŠ¨ä½œ
        valid_actions = [
            "CREATE_POST", "CREATE_COMMENT", "LIKE_POST", 
            "FOLLOW", "SEARCH_POSTS", "TREND"
        ]
        
        for action in valid_actions:
            if action in response_upper:
                return {
                    "agent_id": 0,
                    "action_type": action.lower(),
                    "action_args": {"content": f"Generated {action.lower()} content"},
                    "reasoning": f"Extracted action '{action}' from response"
                }
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆåŠ¨ä½œï¼Œè¿”å›None
        return None


def create_rl_oasis_api_workflow(llm_manager) -> tuple[SG_Workflow, RLTrainer, LLMOasisDecisionMaker]:
    """åˆ›å»ºåŸºäºRLçš„LLMå†³ç­–OASIS APIå·¥ä½œæµ"""
    
    # åˆ›å»ºRLé…ç½®
    rl_config = RLConfig(
        algorithm=RLAlgorithm.PPO,
        learning_rate=3e-4,
        gamma=0.99,
        gae_lambda=0.95,
        clip_ratio=0.2,
        value_loss_coef=0.5,
        entropy_coef=0.01,
        max_grad_norm=0.5,
        batch_size=32,
        mini_batch_size=8,
        ppo_epochs=4,
        target_kl=0.01
    )
    
    # åˆ›å»ºRLè®­ç»ƒå™¨
    rl_trainer = RLTrainer(rl_config, llm_manager)
    
    # åˆ›å»ºLLMå†³ç­–å™¨
    decision_maker = LLMOasisDecisionMaker(llm_manager)
    
    # åˆ›å»ºå·¥ä½œæµ
    workflow = SG_Workflow("rl_oasis_api_workflow", WorkflowMode.TRADITIONAL, llm_manager)
    
    # åˆ›å»ºOASIS APIæ²™ç›’
    sandbox = OasisAPISandbox(
        profile_path=None,  # ä½¿ç”¨é»˜è®¤é…ç½®æ–‡ä»¶
        database_path="./data/oasis_simulation.db",
        platform="reddit"
    )
    
    return workflow, rl_trainer, decision_maker, sandbox


def _encode_oasis_action(action: str) -> int:
    """ç¼–ç OASISåŠ¨ä½œç±»å‹"""
    action_map = {
        "create_post": 1,
        "create_comment": 2,
        "like_post": 3,
        "follow": 4,
        "search_posts": 5,
        "trend": 6
    }
    return action_map.get(action, 0)


async def run_rl_oasis_api_demo(steps: int = 5):
    """è¿è¡ŒåŸºäºRLçš„LLMå†³ç­–OASIS APIæ¼”ç¤º"""
    
    print("ğŸï¸ SandGraph OASIS API Integration Demo")
    print("=" * 60)
    
    # 1. åˆ›å»ºLLMç®¡ç†å™¨
    print("\n1. Creating LLM Manager")
    llm_manager = create_shared_llm_manager(
        model_name="mistralai/Mistral-7B-Instruct-v0.2",
        backend="huggingface",
        temperature=0.7,
        max_length=512,
        device="auto",
        torch_dtype="float16"
    )
    
    # 2. åˆ›å»ºå·¥ä½œæµå’ŒRLè®­ç»ƒå™¨
    print("\n2. Creating RL OASIS API Workflow")
    workflow, rl_trainer, decision_maker, sandbox = create_rl_oasis_api_workflow(llm_manager)
    
    # 3. åˆå§‹åŒ–OASISç¯å¢ƒ
    print("\n3. Initializing OASIS Environment")
    await sandbox.reset_environment()
    
    # 4. æ‰§è¡Œå¤šæ­¥OASIS APIè°ƒç”¨
    print(f"\n4. Executing {steps} OASIS API Steps")
    
    results = []
    for step in range(steps):
        print(f"\n--- ç¬¬ {step + 1} æ­¥ ---")
        
        try:
            # è·å–å½“å‰çŠ¶æ€
            case = sandbox.case_generator()
            current_state = case["state"]
            
            # ä½¿ç”¨LLMåšå‡ºå†³ç­–
            decision_result = decision_maker.make_decision(current_state)
            decision = decision_result["decision"]
            
            # æ‰§è¡ŒOASISå†³ç­–
            try:
                # æ‰§è¡ŒOASISåŠ¨ä½œ
                action_result = await sandbox.execute_oasis_action(
                    decision["agent_id"],
                    decision["action_type"],
                    decision.get("action_args", {})
                )
                
                # éªŒè¯å’Œæ‰§è¡Œå†³ç­–
                score = sandbox.verify_score(
                    f"{decision['action_type']} {decision.get('action_args', {}).get('content', 'general')}",
                    case
                )
                
                # è®¡ç®—å¥–åŠ±
                reward = score * 10
                
                # æ„å»ºçŠ¶æ€ç‰¹å¾
                state_features = {
                    "agents_count": current_state.get("agents_count", 0),
                    "platform": current_state.get("platform", "reddit"),
                    "oasis_available": current_state.get("oasis_available", True),
                    "decision_type": _encode_oasis_action(decision["action_type"])
                }
                
                # æ·»åŠ åˆ°RLè®­ç»ƒå™¨
                rl_trainer.add_experience(
                    state=state_features,
                    action=json.dumps(decision),
                    reward=reward,
                    done=False
                )
                
                # æ›´æ–°ç­–ç•¥
                update_result = rl_trainer.update_policy()
                
                result = {
                    "state": current_state,
                    "decision": decision,
                    "llm_response": decision_result["llm_response"],
                    "action_result": action_result,
                    "score": score,
                    "reward": reward,
                    "rl_update": update_result,
                    "sandbox_id": sandbox.sandbox_id
                }
                
                print(f"LLM Decision: Agent {decision['agent_id']} {decision['action_type']}")
                print(f"Decision Reason: {decision.get('reasoning', '')}")
                print(f"Action Success: {action_result.get('success', False)}")
                print(f"OASIS Score: {score:.3f}")
                print(f"RL Reward: {reward:.3f}")
                
                # æ˜¾ç¤ºå½“å‰OASISçŠ¶æ€
                print(f"Platform: {current_state.get('platform', 'unknown')}")
                print(f"Agents Count: {current_state.get('agents_count', 0)}")
                print(f"OASIS Available: {current_state.get('oasis_available', True)}")
                
                results.append(result)
                
            except Exception as e:
                print(f"âŒ OASIS Action Execution Error: {e}")
                result = {
                    "state": current_state,
                    "decision": {"action_type": "create_post", "reasoning": f"Execution Error: {e}"},
                    "score": 0.0,
                    "reward": 0.0,
                    "error": str(e)
                }
                results.append(result)
        
        except Exception as e:
            print(f"âŒ Step {step + 1} Execution Error: {e}")
    
    # 5. è¾“å‡ºæœ€ç»ˆç»“æœ
    print("\n5. Final Results")
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    total_reward = sum(r.get("reward", 0) for r in results)
    avg_score = sum(r.get("score", 0) for r in results) / len(results) if results else 0
    decision_count = decision_maker.decision_count
    
    print(f"Total Decisions: {decision_count}")
    print(f"Total Reward: {total_reward:.3f}")
    print(f"Average Score: {avg_score:.3f}")
    
    # æ˜¾ç¤ºRLè®­ç»ƒç»Ÿè®¡
    rl_stats = rl_trainer.get_training_stats()
    print(f"RL Training Steps: {rl_stats['training_step']}")
    print(f"RL Algorithm: {rl_stats['algorithm']}")
    
    return results


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="SandGraph OASIS API Integration Demo")
    parser.add_argument("--steps", type=int, default=5, help="Number of steps to run")
    parser.add_argument("--test", action="store_true", help="Run tests instead of demo")
    parser.add_argument("--profile", type=str, help="Path to user profile file")
    parser.add_argument("--platform", type=str, default="reddit", choices=["reddit", "twitter"], help="OASIS platform")
    
    args = parser.parse_args()
    
    if args.test:
        # è¿è¡Œæµ‹è¯•
        print("ğŸï¸ SandGraph OASIS API Integration Demo æµ‹è¯•")
        print("=" * 80)
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ æµ‹è¯•å‡½æ•°
        print("âœ… æµ‹è¯•åŠŸèƒ½å¾…å®ç°")
    else:
        # è¿è¡Œæ¼”ç¤º
        print("ğŸï¸ SandGraph OASIS API Integration Demo")
        print("=" * 60)
        print(f"Steps: {args.steps}")
        print(f"Platform: {args.platform}")
        if args.profile:
            print(f"Profile: {args.profile}")
        
        try:
            results = asyncio.run(run_rl_oasis_api_demo(args.steps))
            print("\nâœ… Demo completed successfully!")
            
        except Exception as e:
            print(f"\nâŒ Demo failed: {e}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    main() 