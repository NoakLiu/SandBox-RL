#!/usr/bin/env python3
"""
å¤šæ¨¡å‹è®­ç»ƒç³»ç»Ÿè¿è¡Œè„šæœ¬
é…ç½®å¤§å†…å­˜å’Œæœ¬åœ°å­˜å‚¨ï¼Œä¿å­˜è¿è¡Œä¿¡æ¯å’Œæ£€æŸ¥ç‚¹
"""

import os
import sys
import json
import time
import logging
import subprocess
import shutil
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional
import psutil
import gc

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class MultiModelTrainingRunner:
    """å¤šæ¨¡å‹è®­ç»ƒç³»ç»Ÿè¿è¡Œå™¨"""
    
    def __init__(self, 
                 output_dir: str = "./training_outputs",
                 checkpoint_dir: str = "./checkpoints",
                 log_dir: str = "./logs",
                 memory_limit_gb: int = 32,
                 enable_gpu: bool = True):
        
        self.output_dir = Path(output_dir)
        self.checkpoint_dir = Path(checkpoint_dir)
        self.log_dir = Path(log_dir)
        self.memory_limit_gb = memory_limit_gb
        self.enable_gpu = enable_gpu
        
        # åˆ›å»ºç›®å½•
        self.ensure_directories()
        
        # è¿è¡Œé…ç½®
        self.run_config = {
            "start_time": datetime.now().isoformat(),
            "memory_limit_gb": memory_limit_gb,
            "enable_gpu": enable_gpu,
            "output_dir": str(self.output_dir),
            "checkpoint_dir": str(self.checkpoint_dir),
            "log_dir": str(self.log_dir)
        }
        
        # æ€§èƒ½ç›‘æ§
        self.performance_metrics = {
            "memory_usage": [],
            "cpu_usage": [],
            "disk_usage": [],
            "checkpoints": [],
            "training_steps": []
        }
    
    def ensure_directories(self):
        """ç¡®ä¿æ‰€æœ‰å¿…è¦çš„ç›®å½•å­˜åœ¨"""
        directories = [self.output_dir, self.checkpoint_dir, self.log_dir]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
            logger.info(f"ğŸ“ ç¡®ä¿ç›®å½•å­˜åœ¨: {directory}")
    
    def check_system_resources(self) -> Dict[str, Any]:
        """æ£€æŸ¥ç³»ç»Ÿèµ„æº"""
        try:
            # å†…å­˜ä¿¡æ¯
            memory = psutil.virtual_memory()
            memory_info = {
                "total_gb": memory.total / (1024**3),
                "available_gb": memory.available / (1024**3),
                "used_gb": memory.used / (1024**3),
                "percent": memory.percent
            }
            
            # CPUä¿¡æ¯
            cpu_info = {
                "count": psutil.cpu_count(),
                "percent": psutil.cpu_percent(interval=1),
                "freq": psutil.cpu_freq().current if psutil.cpu_freq() else 0
            }
            
            # ç£ç›˜ä¿¡æ¯
            disk = psutil.disk_usage(self.output_dir)
            disk_info = {
                "total_gb": disk.total / (1024**3),
                "used_gb": disk.used / (1024**3),
                "free_gb": disk.free / (1024**3),
                "percent": disk.percent
            }
            
            # GPUä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            gpu_info = self.get_gpu_info()
            
            system_info = {
                "memory": memory_info,
                "cpu": cpu_info,
                "disk": disk_info,
                "gpu": gpu_info,
                "timestamp": datetime.now().isoformat()
            }
            
            logger.info(f"ğŸ’¾ ç³»ç»Ÿèµ„æºæ£€æŸ¥å®Œæˆ:")
            logger.info(f"   å†…å­˜: {memory_info['available_gb']:.1f}GB å¯ç”¨ / {memory_info['total_gb']:.1f}GB æ€»è®¡")
            logger.info(f"   CPU: {cpu_info['count']} æ ¸å¿ƒ, {cpu_info['percent']:.1f}% ä½¿ç”¨ç‡")
            logger.info(f"   ç£ç›˜: {disk_info['free_gb']:.1f}GB å¯ç”¨ / {disk_info['total_gb']:.1f}GB æ€»è®¡")
            
            return system_info
            
        except Exception as e:
            logger.error(f"âŒ ç³»ç»Ÿèµ„æºæ£€æŸ¥å¤±è´¥: {e}")
            return {}
    
    def get_gpu_info(self) -> Dict[str, Any]:
        """è·å–GPUä¿¡æ¯"""
        try:
            # å°è¯•å¯¼å…¥GPUç›¸å…³åº“
            import torch
            if torch.cuda.is_available():
                gpu_count = torch.cuda.device_count()
                gpu_info = {
                    "available": True,
                    "count": gpu_count,
                    "devices": []
                }
                
                for i in range(gpu_count):
                    device = torch.cuda.get_device_properties(i)
                    gpu_info["devices"].append({
                        "id": i,
                        "name": device.name,
                        "memory_total_gb": device.total_memory / (1024**3),
                        "memory_allocated_gb": torch.cuda.memory_allocated(i) / (1024**3)
                    })
                
                logger.info(f"ğŸ® GPUä¿¡æ¯: {gpu_count} ä¸ªGPUå¯ç”¨")
                return gpu_info
            else:
                logger.warning("âš ï¸ GPUä¸å¯ç”¨")
                return {"available": False}
                
        except ImportError:
            logger.warning("âš ï¸ PyTorchæœªå®‰è£…ï¼Œæ— æ³•è·å–GPUä¿¡æ¯")
            return {"available": False}
        except Exception as e:
            logger.error(f"âŒ GPUä¿¡æ¯è·å–å¤±è´¥: {e}")
            return {"available": False}
    
    def optimize_environment(self):
        """ä¼˜åŒ–è¿è¡Œç¯å¢ƒ"""
        logger.info("ğŸ”§ ä¼˜åŒ–è¿è¡Œç¯å¢ƒ...")
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        env_vars = {
            "PYTHONPATH": f"{os.getcwd()}:{os.environ.get('PYTHONPATH', '')}",
            "CUDA_VISIBLE_DEVICES": "0,1,2,3" if self.enable_gpu else "",
            "OMP_NUM_THREADS": str(psutil.cpu_count()),
            "MKL_NUM_THREADS": str(psutil.cpu_count()),
            "NUMEXPR_NUM_THREADS": str(psutil.cpu_count()),
            "TOKENIZERS_PARALLELISM": "false"
        }
        
        # è®¾ç½®å†…å­˜é™åˆ¶
        if self.memory_limit_gb > 0:
            env_vars["PYTORCH_CUDA_ALLOC_CONF"] = f"max_split_size_mb:{self.memory_limit_gb * 1024}"
        
        # åº”ç”¨ç¯å¢ƒå˜é‡
        for key, value in env_vars.items():
            if value:
                os.environ[key] = value
                logger.info(f"   è®¾ç½®ç¯å¢ƒå˜é‡: {key}={value}")
        
        # æ¸…ç†å†…å­˜
        gc.collect()
        
        logger.info("âœ… ç¯å¢ƒä¼˜åŒ–å®Œæˆ")
    
    def create_training_script(self) -> str:
        """åˆ›å»ºè®­ç»ƒè„šæœ¬"""
        script_content = f'''#!/usr/bin/env python3
"""
è‡ªåŠ¨ç”Ÿæˆçš„å¤šæ¨¡å‹è®­ç»ƒè„šæœ¬
ç”Ÿæˆæ—¶é—´: {datetime.now().isoformat()}
"""

import os
import sys
import json
import time
import logging
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, "{os.getcwd()}")

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('{self.log_dir}/training.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹å¤šæ¨¡å‹è®­ç»ƒ...")
    
    try:
        # å¯¼å…¥è®­ç»ƒæ¨¡å—
        from demo.multi_model_single_env_simple import main as training_main
        
        # è¿è¡Œè®­ç»ƒ
        import asyncio
        asyncio.run(training_main())
        
        logger.info("âœ… è®­ç»ƒå®Œæˆ")
        
    except Exception as e:
        logger.error(f"âŒ è®­ç»ƒå¤±è´¥: {{e}}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
'''
        
        script_path = self.output_dir / "run_training.py"
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(script_content)
        
        # è®¾ç½®æ‰§è¡Œæƒé™
        os.chmod(script_path, 0o755)
        
        logger.info(f"ğŸ“ è®­ç»ƒè„šæœ¬å·²åˆ›å»º: {script_path}")
        return str(script_path)
    
    def monitor_performance(self, process: subprocess.Popen):
        """ç›‘æ§è®­ç»ƒè¿‡ç¨‹æ€§èƒ½"""
        logger.info("ğŸ“Š å¼€å§‹æ€§èƒ½ç›‘æ§...")
        
        while process.poll() is None:
            try:
                # è·å–è¿›ç¨‹ä¿¡æ¯
                process_info = psutil.Process(process.pid)
                
                # å†…å­˜ä½¿ç”¨
                memory_usage = process_info.memory_info()
                memory_gb = memory_usage.rss / (1024**3)
                
                # CPUä½¿ç”¨
                cpu_percent = process_info.cpu_percent()
                
                # ç£ç›˜ä½¿ç”¨
                disk_usage = psutil.disk_usage(self.output_dir)
                disk_gb = disk_usage.used / (1024**3)
                
                # è®°å½•æŒ‡æ ‡
                self.performance_metrics["memory_usage"].append({
                    "timestamp": datetime.now().isoformat(),
                    "memory_gb": memory_gb
                })
                
                self.performance_metrics["cpu_usage"].append({
                    "timestamp": datetime.now().isoformat(),
                    "cpu_percent": cpu_percent
                })
                
                self.performance_metrics["disk_usage"].append({
                    "timestamp": datetime.now().isoformat(),
                    "disk_gb": disk_gb
                })
                
                # æ¯30ç§’è®°å½•ä¸€æ¬¡
                if len(self.performance_metrics["memory_usage"]) % 30 == 0:
                    logger.info(f"ğŸ“ˆ æ€§èƒ½ç›‘æ§: å†…å­˜={memory_gb:.1f}GB, CPU={cpu_percent:.1f}%, ç£ç›˜={disk_gb:.1f}GB")
                
                time.sleep(1)
                
            except Exception as e:
                logger.error(f"âŒ æ€§èƒ½ç›‘æ§é”™è¯¯: {e}")
                break
    
    def save_checkpoint(self, checkpoint_name: str = None):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        if checkpoint_name is None:
            checkpoint_name = f"checkpoint_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        checkpoint_path = self.checkpoint_dir / checkpoint_name
        checkpoint_path.mkdir(exist_ok=True)
        
        # ä¿å­˜é…ç½®
        config_file = checkpoint_path / "run_config.json"
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(self.run_config, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜æ€§èƒ½æŒ‡æ ‡
        metrics_file = checkpoint_path / "performance_metrics.json"
        with open(metrics_file, 'w', encoding='utf-8') as f:
            json.dump(self.performance_metrics, f, indent=2, ensure_ascii=False)
        
        # å¤åˆ¶è®­ç»ƒç»“æœ
        result_files = list(self.output_dir.glob("*.json"))
        for result_file in result_files:
            shutil.copy2(result_file, checkpoint_path)
        
        # å¤åˆ¶æ—¥å¿—æ–‡ä»¶
        log_files = list(self.log_dir.glob("*.log"))
        for log_file in log_files:
            shutil.copy2(log_file, checkpoint_path)
        
        logger.info(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")
        
        # è®°å½•æ£€æŸ¥ç‚¹ä¿¡æ¯
        self.performance_metrics["checkpoints"].append({
            "name": checkpoint_name,
            "timestamp": datetime.now().isoformat(),
            "path": str(checkpoint_path)
        })
        
        return checkpoint_path
    
    def run_training(self) -> bool:
        """è¿è¡Œè®­ç»ƒ"""
        logger.info("ğŸš€ å¯åŠ¨å¤šæ¨¡å‹è®­ç»ƒç³»ç»Ÿ...")
        
        # æ£€æŸ¥ç³»ç»Ÿèµ„æº
        system_info = self.check_system_resources()
        self.run_config["system_info"] = system_info
        
        # ä¼˜åŒ–ç¯å¢ƒ
        self.optimize_environment()
        
        # åˆ›å»ºè®­ç»ƒè„šæœ¬
        script_path = self.create_training_script()
        
        # è®¾ç½®å·¥ä½œç›®å½•
        work_dir = os.getcwd()
        
        try:
            # å¯åŠ¨è®­ç»ƒè¿›ç¨‹
            logger.info(f"ğŸ“ æ‰§è¡Œè®­ç»ƒè„šæœ¬: {script_path}")
            
            process = subprocess.Popen(
                [sys.executable, script_path],
                cwd=work_dir,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                universal_newlines=True,
                bufsize=1
            )
            
            # å¯åŠ¨æ€§èƒ½ç›‘æ§ï¼ˆåœ¨åå°çº¿ç¨‹ä¸­ï¼‰
            import threading
            monitor_thread = threading.Thread(
                target=self.monitor_performance, 
                args=(process,),
                daemon=True
            )
            monitor_thread.start()
            
            # å®æ—¶è¾“å‡ºæ—¥å¿—
            logger.info("ğŸ“‹ è®­ç»ƒæ—¥å¿—:")
            logger.info("=" * 80)
            
            while True:
                output = process.stdout.readline()
                if output == '' and process.poll() is not None:
                    break
                if output:
                    print(output.strip())
            
            # ç­‰å¾…è¿›ç¨‹å®Œæˆ
            return_code = process.wait()
            
            logger.info("=" * 80)
            
            if return_code == 0:
                logger.info("âœ… è®­ç»ƒæˆåŠŸå®Œæˆ")
                
                # ä¿å­˜æœ€ç»ˆæ£€æŸ¥ç‚¹
                self.save_checkpoint("final_checkpoint")
                
                # ä¿å­˜è¿è¡ŒæŠ¥å‘Š
                self.save_run_report()
                
                return True
            else:
                logger.error(f"âŒ è®­ç»ƒå¤±è´¥ï¼Œè¿”å›ç : {return_code}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ è®­ç»ƒæ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def save_run_report(self):
        """ä¿å­˜è¿è¡ŒæŠ¥å‘Š"""
        report = {
            "run_config": self.run_config,
            "performance_metrics": self.performance_metrics,
            "end_time": datetime.now().isoformat(),
            "status": "completed"
        }
        
        report_file = self.output_dir / "run_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“Š è¿è¡ŒæŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        logger.info("ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
        
        # æ¸…ç†ä¸´æ—¶è„šæœ¬
        temp_script = self.output_dir / "run_training.py"
        if temp_script.exists():
            temp_script.unlink()
            logger.info(f"   åˆ é™¤ä¸´æ—¶è„šæœ¬: {temp_script}")
        
        logger.info("âœ… æ¸…ç†å®Œæˆ")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¤šæ¨¡å‹è®­ç»ƒç³»ç»Ÿè¿è¡Œå™¨")
    print("=" * 60)
    
    # é…ç½®å‚æ•°
    config = {
        "output_dir": "./training_outputs",
        "checkpoint_dir": "./checkpoints", 
        "log_dir": "./logs",
        "memory_limit_gb": 32,  # 32GBå†…å­˜é™åˆ¶
        "enable_gpu": True
    }
    
    # åˆ›å»ºè¿è¡Œå™¨
    runner = MultiModelTrainingRunner(**config)
    
    try:
        # è¿è¡Œè®­ç»ƒ
        success = runner.run_training()
        
        if success:
            print("\nğŸ‰ è®­ç»ƒæˆåŠŸå®Œæˆï¼")
            print(f"ğŸ“ è¾“å‡ºç›®å½•: {runner.output_dir}")
            print(f"ğŸ’¾ æ£€æŸ¥ç‚¹ç›®å½•: {runner.checkpoint_dir}")
            print(f"ğŸ“‹ æ—¥å¿—ç›®å½•: {runner.log_dir}")
        else:
            print("\nâŒ è®­ç»ƒå¤±è´¥ï¼")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\nâš ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        runner.save_checkpoint("interrupted_checkpoint")
    except Exception as e:
        print(f"\nâŒ è¿è¡Œå™¨é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    finally:
        # æ¸…ç†
        runner.cleanup()

if __name__ == "__main__":
    main()
