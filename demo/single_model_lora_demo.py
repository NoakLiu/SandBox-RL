#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å•æ¨¡å‹+8GPU LoRAå®Œæ•´æ¼”ç¤º

æ¼”ç¤ºåŠŸèƒ½ï¼š
1. å¯åŠ¨å•æ¨¡å‹+8GPU vLLMå®ä¾‹
2. å‘å¸ƒ8ä¸ªLoRAæƒé‡
3. è‡ªåŠ¨çƒ­æ›´æ–°
4. å¹¶å‘æµ‹è¯•
"""

import asyncio
import time
import json
import logging
import subprocess
import sys
import os
from pathlib import Path
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class SingleModelLoRADemo:
    """å•æ¨¡å‹+8GPU LoRAæ¼”ç¤º"""
    
    def __init__(self):
        self.vllm_process = None
        self.updater_process = None
        self.publisher_process = None
        
    def start_vllm(self):
        """å¯åŠ¨vLLMå®ä¾‹"""
        logger.info("ğŸš€ å¯åŠ¨å•æ¨¡å‹+8GPU vLLMå®ä¾‹...")
        
        # ä½¿ç”¨å¯åŠ¨è„šæœ¬
        script_path = "demo/launch_single_model_8gpu.sh"
        if not os.path.exists(script_path):
            logger.error(f"âŒ å¯åŠ¨è„šæœ¬ä¸å­˜åœ¨: {script_path}")
            return False
        
        try:
            # ç»™è„šæœ¬æ‰§è¡Œæƒé™
            os.chmod(script_path, 0o755)
            
            # å¯åŠ¨vLLM
            self.vllm_process = subprocess.Popen(
                [f"./{script_path}"],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            
            logger.info("âœ… vLLMå¯åŠ¨å‘½ä»¤å·²æ‰§è¡Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨vLLMå¤±è´¥: {e}")
            return False
    
    def start_lora_updater(self):
        """å¯åŠ¨LoRAçƒ­æ›´æ–°ç®¡ç†å™¨"""
        logger.info("ğŸ”„ å¯åŠ¨LoRAçƒ­æ›´æ–°ç®¡ç†å™¨...")
        
        try:
            self.updater_process = subprocess.Popen(
                [sys.executable, "demo/lora_updater_single.py"],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            
            logger.info("âœ… LoRAçƒ­æ›´æ–°ç®¡ç†å™¨å·²å¯åŠ¨")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨LoRAçƒ­æ›´æ–°ç®¡ç†å™¨å¤±è´¥: {e}")
            return False
    
    def publish_loras(self):
        """å‘å¸ƒLoRAæƒé‡"""
        logger.info("ğŸ“¤ å‘å¸ƒLoRAæƒé‡...")
        
        try:
            result = subprocess.run(
                [sys.executable, "demo/lora_publisher.py"],
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0:
                logger.info("âœ… LoRAæƒé‡å‘å¸ƒæˆåŠŸ")
                logger.info(result.stdout)
                return True
            else:
                logger.error(f"âŒ LoRAæƒé‡å‘å¸ƒå¤±è´¥: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ å‘å¸ƒLoRAæƒé‡å¼‚å¸¸: {e}")
            return False
    
    async def test_concurrent_requests(self):
        """æµ‹è¯•å¹¶å‘è¯·æ±‚"""
        logger.info("ğŸ§ª æµ‹è¯•å¹¶å‘LoRAè¯·æ±‚...")
        
        # å¯¼å…¥æµ‹è¯•å‡½æ•°
        try:
            from demo.test_single_model_lora import test_concurrent_requests
            success = await test_concurrent_requests()
            if success:
                logger.info("âœ… å¹¶å‘æµ‹è¯•æˆåŠŸ")
            else:
                logger.warning("âš ï¸ å¹¶å‘æµ‹è¯•éƒ¨åˆ†å¤±è´¥")
            return success
        except Exception as e:
            logger.error(f"âŒ å¹¶å‘æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def check_vllm_status(self):
        """æ£€æŸ¥vLLMçŠ¶æ€"""
        try:
            import requests
            response = requests.get("http://localhost:8001/health", timeout=5)
            if response.status_code == 200:
                logger.info("âœ… vLLMå®ä¾‹è¿è¡Œæ­£å¸¸")
                return True
            else:
                logger.warning(f"âš ï¸ vLLMå®ä¾‹å¼‚å¸¸: {response.status_code}")
                return False
        except Exception as e:
            logger.warning(f"âš ï¸ æ— æ³•è¿æ¥åˆ°vLLM: {e}")
            return False
    
    def wait_for_vllm(self, timeout=120):
        """ç­‰å¾…vLLMå¯åŠ¨"""
        logger.info(f"â³ ç­‰å¾…vLLMå¯åŠ¨ (æœ€å¤š{timeout}ç§’)...")
        
        start_time = time.time()
        while time.time() - start_time < timeout:
            if self.check_vllm_status():
                return True
            time.sleep(5)
        
        logger.error("âŒ vLLMå¯åŠ¨è¶…æ—¶")
        return False
    
    async def run_demo(self):
        """è¿è¡Œå®Œæ•´æ¼”ç¤º"""
        logger.info("ğŸ¬ å¼€å§‹å•æ¨¡å‹+8GPU LoRAæ¼”ç¤º...")
        
        try:
            # 1. å¯åŠ¨vLLM
            if not self.start_vllm():
                logger.error("âŒ æ— æ³•å¯åŠ¨vLLMï¼Œæ¼”ç¤ºç»ˆæ­¢")
                return
            
            # 2. ç­‰å¾…vLLMå¯åŠ¨
            if not self.wait_for_vllm():
                logger.error("âŒ vLLMå¯åŠ¨å¤±è´¥ï¼Œæ¼”ç¤ºç»ˆæ­¢")
                return
            
            # 3. å¯åŠ¨LoRAçƒ­æ›´æ–°ç®¡ç†å™¨
            if not self.start_lora_updater():
                logger.warning("âš ï¸ LoRAçƒ­æ›´æ–°ç®¡ç†å™¨å¯åŠ¨å¤±è´¥ï¼Œç»§ç»­æ¼”ç¤º")
            
            # 4. ç­‰å¾…ä¸€æ®µæ—¶é—´è®©çƒ­æ›´æ–°ç®¡ç†å™¨å¯åŠ¨
            logger.info("â³ ç­‰å¾…LoRAçƒ­æ›´æ–°ç®¡ç†å™¨å¯åŠ¨...")
            await asyncio.sleep(10)
            
            # 5. å‘å¸ƒLoRAæƒé‡
            if not self.publish_loras():
                logger.warning("âš ï¸ LoRAæƒé‡å‘å¸ƒå¤±è´¥ï¼Œç»§ç»­æ¼”ç¤º")
            
            # 6. ç­‰å¾…çƒ­æ›´æ–°
            logger.info("â³ ç­‰å¾…LoRAçƒ­æ›´æ–°...")
            await asyncio.sleep(15)
            
            # 7. æµ‹è¯•å¹¶å‘è¯·æ±‚
            await self.test_concurrent_requests()
            
            # 8. æ˜¾ç¤ºæœ€ç»ˆçŠ¶æ€
            logger.info("ğŸ“Š æ¼”ç¤ºå®Œæˆï¼")
            logger.info("ğŸ’¡ ç³»ç»Ÿç°åœ¨æ”¯æŒ:")
            logger.info("   - å•æ¨¡å‹+8GPUå¼ é‡å¹¶è¡Œ")
            logger.info("   - 8ä¸ªLoRAç‹¬ç«‹çƒ­æ›´æ–°")
            logger.info("   - å¹¶å‘è¯·æ±‚å¤„ç†")
            logger.info("   - RLç­–ç•¥é›†æˆ")
            
        except KeyboardInterrupt:
            logger.info("ğŸ›‘ ç”¨æˆ·ä¸­æ–­æ¼”ç¤º")
        except Exception as e:
            logger.error(f"âŒ æ¼”ç¤ºè¿è¡Œå¤±è´¥: {e}")
        finally:
            # æ¸…ç†
            self.cleanup()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        logger.info("ğŸ§¹ æ¸…ç†èµ„æº...")
        
        if self.updater_process:
            self.updater_process.terminate()
            logger.info("âœ… LoRAçƒ­æ›´æ–°ç®¡ç†å™¨å·²åœæ­¢")
        
        if self.vllm_process:
            self.vllm_process.terminate()
            logger.info("âœ… vLLMå®ä¾‹å·²åœæ­¢")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¬ å•æ¨¡å‹+8GPU LoRAæ¼”ç¤º")
    print("="*60)
    print("è¿™ä¸ªæ¼”ç¤ºå°†å±•ç¤º:")
    print("1. å•æ¨¡å‹+8GPUå¼ é‡å¹¶è¡Œ")
    print("2. 8ä¸ªLoRAç‹¬ç«‹çƒ­æ›´æ–°")
    print("3. å¹¶å‘è¯·æ±‚å¤„ç†")
    print("4. RLç­–ç•¥é›†æˆ")
    print("="*60)
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    required_files = [
        "demo/launch_single_model_8gpu.sh",
        "demo/lora_updater_single.py",
        "demo/lora_publisher.py",
        "demo/test_single_model_lora.py"
    ]
    
    for file_path in required_files:
        if not os.path.exists(file_path):
            print(f"âŒ ç¼ºå°‘å¿…è¦æ–‡ä»¶: {file_path}")
            return
    
    print("âœ… æ‰€æœ‰å¿…è¦æ–‡ä»¶å­˜åœ¨")
    
    # è¿è¡Œæ¼”ç¤º
    demo = SingleModelLoRADemo()
    await demo.run_demo()


if __name__ == "__main__":
    asyncio.run(main())
