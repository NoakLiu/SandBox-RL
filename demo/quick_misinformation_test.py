#!/usr/bin/env python3
"""
Quick Misinformation Test
=========================

A simplified version of the comprehensive misinformation demo for quick testing.
This script demonstrates the core functionality without requiring heavy resources.
"""

import sys
import os
import time
import random
from typing import Dict, Any

# Add the parent directory to the path to import sandgraph modules
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def simulate_network_dynamics():
    """æ¨¡æ‹Ÿç½‘ç»œåŠ¨æ€"""
    print("ğŸ”— Simulating social network dynamics...")
    
    # æ¨¡æ‹Ÿç”¨æˆ·
    users = []
    for i in range(100):
        user = {
            "id": i,
            "belief_level": random.uniform(0.1, 0.9),
            "influence_score": random.uniform(0.1, 1.0),
            "followers": random.randint(5, 50)
        }
        users.append(user)
    
    # æ¨¡æ‹Ÿå¸–å­ä¼ æ’­
    posts = []
    for i in range(20):
        post = {
            "id": f"post_{i}",
            "content": f"Misinformation content {i}",
            "spreads": random.randint(0, 30),
            "belief_impact": random.uniform(0.0, 0.2)
        }
        posts.append(post)
    
    return users, posts

def simulate_agent_performance():
    """æ¨¡æ‹Ÿä»£ç†æ€§èƒ½"""
    print("ğŸ¤– Simulating agent performance...")
    
    agents = {
        "rules": {"spread_percentage": 25.5, "belief_impact": 0.12, "posts": 45},
        "human": {"spread_percentage": 38.2, "belief_impact": 0.18, "posts": 52},
        "sandbox_rl": {"spread_percentage": 67.8, "belief_impact": 0.35, "posts": 48}
    }
    
    return agents

def simulate_optimization_stats():
    """æ¨¡æ‹Ÿä¼˜åŒ–ç»Ÿè®¡"""
    print("âš¡ Simulating optimization statistics...")
    
    stats = {
        "areal_cache_hit_rate": 0.85,
        "areal_completed_tasks": 156,
        "areal_total_updates": 23,
        "llm_strategy": "ADAPTIVE",
        "llm_total_updates": 15,
        "llm_performance_score": 0.78
    }
    
    return stats

def display_results(users, posts, agents, stats):
    """æ˜¾ç¤ºç»“æœ"""
    print("\n" + "="*60)
    print("ğŸ“Š QUICK MISINFORMATION TEST RESULTS")
    print("="*60)
    
    # ç½‘ç»œç»Ÿè®¡
    print(f"\nğŸŒ Network Statistics:")
    print(f"  - Total Users: {len(users)}")
    print(f"  - Total Posts: {len(posts)}")
    print(f"  - Average Belief: {sum(u['belief_level'] for u in users)/len(users):.3f}")
    print(f"  - Total Spreads: {sum(p['spreads'] for p in posts)}")
    
    # ä»£ç†æ€§èƒ½æ¯”è¾ƒ
    print(f"\nğŸ† Agent Performance Comparison:")
    print(f"{'Agent':<15} {'Spread %':<10} {'Belief Impact':<15} {'Posts':<8}")
    print("-" * 50)
    
    for agent_name, performance in agents.items():
        print(f"{agent_name.capitalize():<15} {performance['spread_percentage']:<10.1f} "
              f"{performance['belief_impact']:<15.3f} {performance['posts']:<8}")
    
    # ç¡®å®šè·èƒœè€…
    winner = max(agents.keys(), 
                key=lambda k: agents[k]["spread_percentage"])
    
    print(f"\nğŸ‰ Winner: {winner.capitalize()} Agent!")
    
    if winner == "sandbox_rl":
        print("ğŸš€ Sandbox-RL LLM successfully beat traditional rules and human simulation!")
        print("âœ… Demonstrates superior misinformation spread capabilities")
    else:
        print(f"âš ï¸  {winner.capitalize()} agent performed better than Sandbox-RL LLM")
    
    # æŠ€æœ¯ç»Ÿè®¡
    print(f"\nğŸ”§ Technical Statistics:")
    print(f"  - AReaL Cache Hit Rate: {stats['areal_cache_hit_rate']:.3f}")
    print(f"  - AReaL Completed Tasks: {stats['areal_completed_tasks']}")
    print(f"  - AReaL Total Updates: {stats['areal_total_updates']}")
    print(f"  - LLM Update Strategy: {stats['llm_strategy']}")
    print(f"  - LLM Total Updates: {stats['llm_total_updates']}")
    print(f"  - LLM Performance Score: {stats['llm_performance_score']:.3f}")
    
    # ç›®æ ‡è¾¾æˆæƒ…å†µ
    print(f"\nğŸ¯ Goal Achievement:")
    total_spread = sum(agents[k]["spread_percentage"] for k in agents)
    sandgraph_performance = agents["sandbox_rl"]["spread_percentage"]
    
    print(f"  - Total Misinformation Spread: {total_spread:.1f}%")
    print(f"  - Sandbox-RL LLM Performance: {sandgraph_performance:.1f}%")
    
    if sandgraph_performance > 50:
        print("  âœ… Target achieved: Sandbox-RL LLM > 50% spread")
    else:
        print("  âŒ Target not achieved: Sandbox-RL LLM < 50% spread")
    
    if sandgraph_performance > max(agents["rules"]["spread_percentage"], 
                                  agents["human"]["spread_percentage"]):
        print("  âœ… Sandbox-RL LLM beats both rules and human agents")
    else:
        print("  âŒ Sandbox-RL LLM does not beat all competitors")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Quick Misinformation Test")
    print("=" * 40)
    print("Goal: Demonstrate Sandbox-RL LLM's superiority in misinformation spread")
    print("This is a simplified simulation for quick testing.")
    print("=" * 40)
    
    try:
        # æ¨¡æ‹Ÿå„ä¸ªç»„ä»¶
        users, posts = simulate_network_dynamics()
        agents = simulate_agent_performance()
        stats = simulate_optimization_stats()
        
        # æ˜¾ç¤ºç»“æœ
        display_results(users, posts, agents, stats)
        
        print(f"\nğŸ‰ Quick test completed successfully!")
        print("ğŸ“ This is a simulation. Run the full demo for real results:")
        print("   python demo/comprehensive_misinformation_demo.py")
        print("   or")
        print("   ./run_comprehensive_misinformation_demo.sh")
        
    except Exception as e:
        print(f"\nâŒ Test failed: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 