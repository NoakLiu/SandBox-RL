#!/bin/bash

# å¤šæ¨¡åž‹è®­ç»ƒç³»ç»Ÿå¯åŠ¨è„šæœ¬ - 100æ¬¡è¿è¡Œç‰ˆæœ¬
# é€‚ç”¨äºŽæœåŠ¡å™¨çŽ¯å¢ƒï¼Œè¿è¡Œ100æ¬¡å¹¶è®¡ç®—å¹³å‡å€¼

echo "ðŸš€ å¯åŠ¨å¤šæ¨¡åž‹è®­ç»ƒç³»ç»Ÿ - 100æ¬¡è¿è¡Œç‰ˆæœ¬"
echo "=================================================="

# æ£€æŸ¥PythonçŽ¯å¢ƒ
if ! command -v python &> /dev/null; then
    echo "âŒ Pythonæœªå®‰è£…æˆ–ä¸åœ¨PATHä¸­"
    exit 1
fi

# æ£€æŸ¥é¡¹ç›®ç›®å½•
if [ ! -f "demo/multi_model_single_env_simple.py" ]; then
    echo "âŒ æœªæ‰¾åˆ°è®­ç»ƒè„šæœ¬ï¼Œè¯·ç¡®ä¿åœ¨SandGraphé¡¹ç›®æ ¹ç›®å½•è¿è¡Œ"
    exit 1
fi

# åˆ›å»ºå¿…è¦çš„ç›®å½•
echo "ðŸ“ åˆ›å»ºç›®å½•..."
mkdir -p training_outputs checkpoints logs temp batch_results

# è®¾ç½®çŽ¯å¢ƒå˜é‡
echo "ðŸ”§ è®¾ç½®çŽ¯å¢ƒå˜é‡..."
export PYTHONPATH="${PWD}:${PYTHONPATH}"
export CUDA_VISIBLE_DEVICES="0,1,2,3"
export OMP_NUM_THREADS=16
export MKL_NUM_THREADS=16
export NUMEXPR_NUM_THREADS=16
export TOKENIZERS_PARALLELISM=false
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32768
export TMPDIR="./temp"

# æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
echo "ðŸ’¾ ç³»ç»Ÿä¿¡æ¯:"
echo "   å½“å‰ç›®å½•: $(pwd)"
echo "   Pythonç‰ˆæœ¬: $(python --version)"
echo "   å†…å­˜ä¿¡æ¯: $(free -h | grep Mem | awk '{print $2}')"
echo "   ç£ç›˜ä¿¡æ¯: $(df -h . | tail -1 | awk '{print $4}') å¯ç”¨"

# æ£€æŸ¥GPU
if command -v nvidia-smi &> /dev/null; then
    echo "ðŸŽ® GPUä¿¡æ¯:"
    nvidia-smi --query-gpu=name,memory.total --format=csv,noheader,nounits | while read line; do
        echo "   $line"
    done
else
    echo "âš ï¸ æœªæ£€æµ‹åˆ°NVIDIA GPU"
fi

# è¿è¡Œå‚æ•°
TOTAL_RUNS=100
SUCCESSFUL_RUNS=0
FAILED_RUNS=0
START_TIME=$(date +%s)

echo ""
echo "ðŸ”„ å¼€å§‹100æ¬¡è®­ç»ƒè¿è¡Œ..."
echo "=================================================="

# åˆ›å»ºç»“æžœæ±‡æ€»æ–‡ä»¶
SUMMARY_FILE="batch_results/training_summary_$(date +%Y%m%d_%H%M%S).json"
echo "ðŸ“Š ç»“æžœæ±‡æ€»æ–‡ä»¶: $SUMMARY_FILE"

# åˆå§‹åŒ–æ±‡æ€»æ•°æ®
cat > "$SUMMARY_FILE" << EOF
{
    "batch_info": {
        "total_runs": $TOTAL_RUNS,
        "start_time": "$(date -d @$START_TIME -Iseconds)",
        "successful_runs": 0,
        "failed_runs": 0
    },
    "runs": [],
    "averages": {}
}
EOF

# è¿è¡Œ100æ¬¡è®­ç»ƒ
for ((i=1; i<=TOTAL_RUNS; i++)); do
    echo ""
    echo "ðŸ”„ è¿è¡Œ $i/$TOTAL_RUNS"
    echo "----------------------------------------"
    
    RUN_START_TIME=$(date +%s)
    
    # è¿è¡Œè®­ç»ƒ
    python demo/run_training_server.py > "logs/run_${i}.log" 2>&1
    RUN_EXIT_CODE=$?
    
    RUN_END_TIME=$(date +%s)
    RUN_DURATION=$((RUN_END_TIME - RUN_START_TIME))
    
    if [ $RUN_EXIT_CODE -eq 0 ]; then
        SUCCESSFUL_RUNS=$((SUCCESSFUL_RUNS + 1))
        echo "âœ… è¿è¡Œ $i æˆåŠŸ (è€—æ—¶: ${RUN_DURATION}ç§’)"
        
        # æ”¶é›†è¿è¡Œç»“æžœ
        if [ -f "multi_model_training_simple_results.json" ]; then
            # å¤‡ä»½ç»“æžœæ–‡ä»¶
            cp "multi_model_training_simple_results.json" "batch_results/results_run_${i}.json"
            
            # è§£æžç»“æžœæ•°æ®
            python -c "
import json
import sys

try:
    with open('multi_model_training_simple_results.json', 'r') as f:
        data = json.load(f)
    
    # è®¡ç®—å¹³å‡æŒ‡æ ‡
    if isinstance(data, list) and len(data) > 0:
        avg_accuracy = sum(item.get('accuracy', 0) for item in data) / len(data)
        avg_efficiency = sum(item.get('efficiency', 0) for item in data) / len(data)
        avg_reward = sum(item.get('reward_earned', 0) for item in data) / len(data)
        total_tasks = sum(item.get('total_tasks', 0) for item in data)
        
        run_summary = {
            'run_number': $i,
            'status': 'success',
            'duration_seconds': $RUN_DURATION,
            'timestamp': '$(date -Iseconds)',
            'metrics': {
                'avg_accuracy': round(avg_accuracy, 4),
                'avg_efficiency': round(avg_efficiency, 4),
                'avg_reward': round(avg_reward, 2),
                'total_tasks': total_tasks,
                'model_count': len(data)
            }
        }
        
        print(json.dumps(run_summary))
    else:
        print(json.dumps({
            'run_number': $i,
            'status': 'success',
            'duration_seconds': $RUN_DURATION,
            'timestamp': '$(date -Iseconds)',
            'metrics': {'error': 'No valid data found'}
        }))
        
except Exception as e:
    print(json.dumps({
        'run_number': $i,
        'status': 'success',
        'duration_seconds': $RUN_DURATION,
        'timestamp': '$(date -Iseconds)',
        'metrics': {'error': str(e)}
    }))
" > "batch_results/run_${i}_summary.json"
            
            echo "   ðŸ“Š å¹³å‡å‡†ç¡®çŽ‡: $(jq -r '.metrics.avg_accuracy' batch_results/run_${i}_summary.json)"
            echo "   ðŸ“Š å¹³å‡æ•ˆçŽ‡: $(jq -r '.metrics.avg_efficiency' batch_results/run_${i}_summary.json)"
            echo "   ðŸ“Š å¹³å‡å¥–åŠ±: $(jq -r '.metrics.avg_reward' batch_results/run_${i}_summary.json)"
        fi
        
    else
        FAILED_RUNS=$((FAILED_RUNS + 1))
        echo "âŒ è¿è¡Œ $i å¤±è´¥ (è€—æ—¶: ${RUN_DURATION}ç§’)"
        
        # è®°å½•å¤±è´¥ä¿¡æ¯
        cat > "batch_results/run_${i}_summary.json" << EOF
{
    "run_number": $i,
    "status": "failed",
    "duration_seconds": $RUN_DURATION,
    "timestamp": "$(date -Iseconds)",
    "error": "Exit code: $RUN_EXIT_CODE"
}
EOF
    fi
    
    # æ›´æ–°æ±‡æ€»æ–‡ä»¶
    python -c "
import json

# è¯»å–å½“å‰æ±‡æ€»
with open('$SUMMARY_FILE', 'r') as f:
    summary = json.load(f)

# æ›´æ–°è®¡æ•°
summary['batch_info']['successful_runs'] = $SUCCESSFUL_RUNS
summary['batch_info']['failed_runs'] = $FAILED_RUNS

# æ·»åŠ è¿è¡Œç»“æžœ
try:
    with open('batch_results/run_${i}_summary.json', 'r') as f:
        run_data = json.load(f)
    summary['runs'].append(run_data)
except:
    summary['runs'].append({
        'run_number': $i,
        'status': 'error',
        'timestamp': '$(date -Iseconds)'
    })

# ä¿å­˜æ›´æ–°åŽçš„æ±‡æ€»
with open('$SUMMARY_FILE', 'w') as f:
    json.dump(summary, f, indent=2)
"
    
    # æ˜¾ç¤ºè¿›åº¦
    PROGRESS=$((i * 100 / TOTAL_RUNS))
    echo "ðŸ“ˆ è¿›åº¦: $PROGRESS% ($SUCCESSFUL_RUNS æˆåŠŸ, $FAILED_RUNS å¤±è´¥)"
    
    # æ¯10æ¬¡è¿è¡ŒåŽæ˜¾ç¤ºä¸­é—´ç»Ÿè®¡
    if [ $((i % 10)) -eq 0 ]; then
        echo ""
        echo "ðŸ“Š ä¸­é—´ç»Ÿè®¡ (å‰ $i æ¬¡è¿è¡Œ):"
        echo "   æˆåŠŸçŽ‡: $((SUCCESSFUL_RUNS * 100 / i))%"
        echo "   å¹³å‡è¿è¡Œæ—¶é—´: $(( (RUN_END_TIME - START_TIME) / i ))ç§’"
        echo ""
    fi
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆä¿ç•™æ—¥å¿—ï¼‰
    rm -f "multi_model_training_simple_results.json"
    rm -rf "temp"/*
    mkdir -p "temp"
done

# è®¡ç®—æœ€ç»ˆç»Ÿè®¡
END_TIME=$(date +%s)
TOTAL_DURATION=$((END_TIME - START_TIME))

echo ""
echo "ðŸŽ‰ 100æ¬¡è¿è¡Œå®Œæˆï¼"
echo "=================================================="
echo "ðŸ“Š æœ€ç»ˆç»Ÿè®¡:"
echo "   æ€»è¿è¡Œæ¬¡æ•°: $TOTAL_RUNS"
echo "   æˆåŠŸæ¬¡æ•°: $SUCCESSFUL_RUNS"
echo "   å¤±è´¥æ¬¡æ•°: $FAILED_RUNS"
echo "   æˆåŠŸçŽ‡: $((SUCCESSFUL_RUNS * 100 / TOTAL_RUNS))%"
echo "   æ€»è€—æ—¶: ${TOTAL_DURATION}ç§’ ($(($TOTAL_DURATION / 60))åˆ†é’Ÿ)"
echo "   å¹³å‡æ¯æ¬¡è¿è¡Œ: $((TOTAL_DURATION / TOTAL_RUNS))ç§’"

# è®¡ç®—å¹³å‡å€¼
echo ""
echo "ðŸ“ˆ è®¡ç®—å¹³å‡å€¼..."
python -c "
import json
import numpy as np

# è¯»å–æ‰€æœ‰æˆåŠŸçš„è¿è¡Œ
successful_runs = []
for i in range(1, $TOTAL_RUNS + 1):
    try:
        with open(f'batch_results/run_{i}_summary.json', 'r') as f:
            run_data = json.load(f)
            if run_data.get('status') == 'success' and 'metrics' in run_data:
                successful_runs.append(run_data['metrics'])
    except:
        continue

if successful_runs:
    # è®¡ç®—å¹³å‡å€¼
    avg_accuracy = np.mean([run.get('avg_accuracy', 0) for run in successful_runs])
    avg_efficiency = np.mean([run.get('avg_efficiency', 0) for run in successful_runs])
    avg_reward = np.mean([run.get('avg_reward', 0) for run in successful_runs])
    avg_tasks = np.mean([run.get('total_tasks', 0) for run in successful_runs])
    avg_models = np.mean([run.get('model_count', 0) for run in successful_runs])
    
    # è®¡ç®—æ ‡å‡†å·®
    std_accuracy = np.std([run.get('avg_accuracy', 0) for run in successful_runs])
    std_efficiency = np.std([run.get('avg_efficiency', 0) for run in successful_runs])
    std_reward = np.std([run.get('avg_reward', 0) for run in successful_runs])
    
    averages = {
        'avg_accuracy': round(avg_accuracy, 4),
        'avg_efficiency': round(avg_efficiency, 4),
        'avg_reward': round(avg_reward, 2),
        'avg_tasks': round(avg_tasks, 1),
        'avg_models': round(avg_models, 1),
        'std_accuracy': round(std_accuracy, 4),
        'std_efficiency': round(std_efficiency, 4),
        'std_reward': round(std_reward, 2),
        'successful_runs_count': len(successful_runs)
    }
    
    print('ðŸ“Š å¹³å‡å€¼ç»Ÿè®¡:')
    print(f'   å¹³å‡å‡†ç¡®çŽ‡: {averages[\"avg_accuracy\"]} Â± {averages[\"std_accuracy\"]}')
    print(f'   å¹³å‡æ•ˆçŽ‡: {averages[\"avg_efficiency\"]} Â± {averages[\"std_efficiency\"]}')
    print(f'   å¹³å‡å¥–åŠ±: {averages[\"avg_reward\"]} Â± {averages[\"std_reward\"]}')
    print(f'   å¹³å‡ä»»åŠ¡æ•°: {averages[\"avg_tasks\"]}')
    print(f'   å¹³å‡æ¨¡åž‹æ•°: {averages[\"avg_models\"]}')
    print(f'   æœ‰æ•ˆè¿è¡Œæ•°: {averages[\"successful_runs_count\"]}')
    
    # ä¿å­˜å¹³å‡å€¼åˆ°æ±‡æ€»æ–‡ä»¶
    with open('$SUMMARY_FILE', 'r') as f:
        summary = json.load(f)
    
    summary['averages'] = averages
    
    with open('$SUMMARY_FILE', 'w') as f:
        json.dump(summary, f, indent=2)
    
    # ä¿å­˜å¹³å‡å€¼åˆ°å•ç‹¬æ–‡ä»¶
    with open('batch_results/averages.json', 'w') as f:
        json.dump(averages, f, indent=2)
        
else:
    print('âŒ æ²¡æœ‰æˆåŠŸçš„è¿è¡Œæ•°æ®')
"

# ç”Ÿæˆå¯è§†åŒ–
echo ""
read -p "æ˜¯å¦ç”Ÿæˆæ‰¹é‡è¿è¡Œçš„å¯è§†åŒ–å›¾è¡¨ï¼Ÿ(y/n): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo "ðŸŽ¨ ç”Ÿæˆæ‰¹é‡è¿è¡Œå¯è§†åŒ–å›¾è¡¨..."
    
    # åˆ›å»ºæ‰¹é‡å¯è§†åŒ–è„šæœ¬
    cat > "batch_results/generate_batch_visualization.py" << 'EOF'
#!/usr/bin/env python3
"""
æ‰¹é‡è¿è¡Œç»“æžœå¯è§†åŒ–è„šæœ¬
"""

import json
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
import glob

def load_batch_data():
    """åŠ è½½æ‰¹é‡è¿è¡Œæ•°æ®"""
    runs = []
    for i in range(1, 101):  # 100æ¬¡è¿è¡Œ
        try:
            with open(f'batch_results/run_{i}_summary.json', 'r') as f:
                run_data = json.load(f)
                if run_data.get('status') == 'success':
                    runs.append(run_data)
        except:
            continue
    return runs

def create_batch_visualizations():
    """åˆ›å»ºæ‰¹é‡è¿è¡Œå¯è§†åŒ–"""
    runs = load_batch_data()
    
    if not runs:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è¿è¡Œæ•°æ®")
        return
    
    # æå–æ•°æ®
    accuracies = [run['metrics']['avg_accuracy'] for run in runs]
    efficiencies = [run['metrics']['avg_efficiency'] for run in runs]
    rewards = [run['metrics']['avg_reward'] for run in runs]
    durations = [run['duration_seconds'] for run in runs]
    
    # åˆ›å»ºå›¾è¡¨
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('100æ¬¡è®­ç»ƒè¿è¡Œç»“æžœåˆ†æž', fontsize=16, fontweight='bold')
    
    # 1. å‡†ç¡®çŽ‡åˆ†å¸ƒ
    axes[0, 0].hist(accuracies, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
    axes[0, 0].axvline(np.mean(accuracies), color='red', linestyle='--', label=f'å¹³å‡å€¼: {np.mean(accuracies):.4f}')
    axes[0, 0].set_title('å‡†ç¡®çŽ‡åˆ†å¸ƒ')
    axes[0, 0].set_xlabel('å‡†ç¡®çŽ‡')
    axes[0, 0].set_ylabel('é¢‘æ¬¡')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # 2. æ•ˆçŽ‡åˆ†å¸ƒ
    axes[0, 1].hist(efficiencies, bins=20, alpha=0.7, color='lightgreen', edgecolor='black')
    axes[0, 1].axvline(np.mean(efficiencies), color='red', linestyle='--', label=f'å¹³å‡å€¼: {np.mean(efficiencies):.4f}')
    axes[0, 1].set_title('æ•ˆçŽ‡åˆ†å¸ƒ')
    axes[0, 1].set_xlabel('æ•ˆçŽ‡')
    axes[0, 1].set_ylabel('é¢‘æ¬¡')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    
    # 3. å¥–åŠ±è¶‹åŠ¿
    axes[1, 0].plot(rewards, marker='o', alpha=0.6, color='orange')
    axes[1, 0].axhline(np.mean(rewards), color='red', linestyle='--', label=f'å¹³å‡å€¼: {np.mean(rewards):.2f}')
    axes[1, 0].set_title('å¥–åŠ±è¶‹åŠ¿')
    axes[1, 0].set_xlabel('è¿è¡Œæ¬¡æ•°')
    axes[1, 0].set_ylabel('å¥–åŠ±')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)
    
    # 4. è¿è¡Œæ—¶é—´åˆ†å¸ƒ
    axes[1, 1].hist(durations, bins=20, alpha=0.7, color='lightcoral', edgecolor='black')
    axes[1, 1].axvline(np.mean(durations), color='red', linestyle='--', label=f'å¹³å‡å€¼: {np.mean(durations):.1f}ç§’')
    axes[1, 1].set_title('è¿è¡Œæ—¶é—´åˆ†å¸ƒ')
    axes[1, 1].set_xlabel('è¿è¡Œæ—¶é—´(ç§’)')
    axes[1, 1].set_ylabel('é¢‘æ¬¡')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('batch_results/batch_analysis.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    print("âœ… æ‰¹é‡è¿è¡Œå¯è§†åŒ–å›¾è¡¨å·²ç”Ÿæˆ: batch_results/batch_analysis.png")

if __name__ == "__main__":
    create_batch_visualizations()
EOF
    
    python batch_results/generate_batch_visualization.py
    
    if [ $? -eq 0 ]; then
        echo "âœ… æ‰¹é‡è¿è¡Œå¯è§†åŒ–å›¾è¡¨å·²ç”Ÿæˆåˆ° batch_results/"
    else
        echo "âŒ æ‰¹é‡å¯è§†åŒ–ç”Ÿæˆå¤±è´¥"
    fi
fi

echo ""
echo "ðŸ“ ç»“æžœæ–‡ä»¶ä½ç½®:"
echo "   æ±‡æ€»æŠ¥å‘Š: $SUMMARY_FILE"
echo "   å¹³å‡å€¼: batch_results/averages.json"
echo "   å„æ¬¡è¿è¡Œç»“æžœ: batch_results/results_run_*.json"
echo "   è¿è¡Œæ—¥å¿—: logs/run_*.log"
echo "   å¯è§†åŒ–å›¾è¡¨: batch_results/batch_analysis.png"

echo ""
echo "ðŸ 100æ¬¡è¿è¡Œè„šæœ¬æ‰§è¡Œå®Œæˆ"
