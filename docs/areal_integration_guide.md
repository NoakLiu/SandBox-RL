# AReaLé›†æˆæŒ‡å—

æœ¬æŒ‡å—è¯¦ç»†ä»‹ç»å¦‚ä½•åœ¨SandGraphXä¸­æ·±åº¦é›†æˆAReaLæ¡†æ¶ï¼Œæœ€å¤§åŒ–å¤ç”¨AReaLçš„è½®å­ï¼Œæå‡ç³»ç»Ÿæ€§èƒ½å’Œå¯æ‰©å±•æ€§ã€‚

## ğŸš€ AReaLæ¡†æ¶ç®€ä»‹

AReaLæ˜¯ä¸€ä¸ªé«˜æ€§èƒ½çš„ç¼“å­˜å’Œä¼˜åŒ–æ¡†æ¶ï¼Œæä¾›äº†ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½ï¼š

- **é«˜çº§ç¼“å­˜ç³»ç»Ÿ**: æ”¯æŒå¤šç§ç¼“å­˜ç­–ç•¥å’Œåç«¯
- **åˆ†å¸ƒå¼å¤„ç†**: ä»»åŠ¡è°ƒåº¦å’ŒèŠ‚ç‚¹ç®¡ç†
- **å®æ—¶æŒ‡æ ‡æ”¶é›†**: æ€§èƒ½ç›‘æ§å’Œæ•°æ®åˆ†æ
- **è‡ªé€‚åº”ä¼˜åŒ–**: èµ„æºç®¡ç†å’Œæ€§èƒ½è°ƒä¼˜
- **å®¹é”™æœºåˆ¶**: æ•…éšœæ¢å¤å’Œé”™è¯¯å¤„ç†

## ğŸ“¦ å®‰è£…å’Œé…ç½®

### 1. å®‰è£…AReaLæ¡†æ¶

```bash
# å®‰è£…AReaLæ ¸å¿ƒæ¡†æ¶
pip install areal

# å®‰è£…å¯é€‰ä¾èµ–
pip install numpy torch psutil

# å®‰è£…é«˜çº§åŠŸèƒ½ä¾èµ–
pip install redis python-memcached ray dask
```

### 2. éªŒè¯å®‰è£…

```python
from sandgraph.core.areal_integration import get_areal_status

status = get_areal_status()
print(f"AReaL Available: {status['areal_available']}")
print(f"Version: {status['version']}")
```

## ğŸ”§ é›†æˆçº§åˆ«

SandGraphXæä¾›äº†ä¸‰ä¸ªAReaLé›†æˆçº§åˆ«ï¼š

### 1. åŸºç¡€é›†æˆ (BASIC)

é€‚ç”¨äºç®€å•åº”ç”¨åœºæ™¯ï¼Œæä¾›åŸºæœ¬çš„ç¼“å­˜å’ŒæŒ‡æ ‡åŠŸèƒ½ã€‚

```python
from sandgraph.core.areal_integration import create_areal_integration, IntegrationLevel

# åˆ›å»ºåŸºç¡€é›†æˆ
areal_manager = create_areal_integration(
    integration_level=IntegrationLevel.BASIC,
    cache_size=5000,
    max_memory_gb=4.0
)

# ä½¿ç”¨ç¼“å­˜
cache = areal_manager.get_cache()
cache.put("key", "value")
value = cache.get("key")

# ä½¿ç”¨æŒ‡æ ‡æ”¶é›†
metrics = areal_manager.get_metrics()
metrics.record_metric("request_count", 1.0)
```

### 2. é«˜çº§é›†æˆ (ADVANCED)

é€‚ç”¨äºå¤æ‚åº”ç”¨åœºæ™¯ï¼Œæä¾›ä»»åŠ¡è°ƒåº¦å’Œä¼˜åŒ–åŠŸèƒ½ã€‚

```python
# åˆ›å»ºé«˜çº§é›†æˆ
areal_manager = create_areal_integration(
    integration_level=IntegrationLevel.ADVANCED,
    cache_size=10000,
    max_memory_gb=8.0,
    enable_optimization=True
)

# ä½¿ç”¨ä»»åŠ¡è°ƒåº¦å™¨
scheduler = areal_manager.get_scheduler()
task_id = scheduler.submit_task("my_task", my_task_function)
result = scheduler.get_task_result(task_id)

# ä½¿ç”¨ä¼˜åŒ–å™¨
optimizer = areal_manager.get_optimizer()
optimal_policy = optimizer.optimize_cache_policy(cache_stats)
```

### 3. å®Œæ•´é›†æˆ (FULL)

é€‚ç”¨äºä¼ä¸šçº§åº”ç”¨åœºæ™¯ï¼Œæä¾›å®Œæ•´çš„åˆ†å¸ƒå¼å’Œä¼˜åŒ–åŠŸèƒ½ã€‚

```python
# åˆ›å»ºå®Œæ•´é›†æˆ
areal_manager = create_areal_integration(
    integration_level=IntegrationLevel.FULL,
    cache_size=20000,
    max_memory_gb=16.0,
    enable_distributed=True,
    enable_optimization=True
)

# ä½¿ç”¨åˆ†å¸ƒå¼ç®¡ç†å™¨
distributed_manager = areal_manager.get_distributed_manager()
distributed_manager.register_node("node_1", {"cpu_cores": 8, "memory_gb": 16})
task_ids = distributed_manager.distribute_task("task_1", task_data)
```

## ğŸ¯ æ ¸å¿ƒç»„ä»¶ä½¿ç”¨

### 1. ç¼“å­˜ç³»ç»Ÿ

AReaLæä¾›äº†é«˜æ€§èƒ½çš„ç¼“å­˜ç³»ç»Ÿï¼Œæ”¯æŒå¤šç§ç­–ç•¥å’Œåç«¯ã€‚

```python
# è·å–ç¼“å­˜åç«¯
cache = areal_manager.get_cache()

# åŸºæœ¬æ“ä½œ
cache.put("user:123", {"name": "Alice", "age": 30})
user_data = cache.get("user:123")
cache.delete("user:123")

# æ‰¹é‡æ“ä½œ
batch_data = {
    "user:1": {"name": "Bob"},
    "user:2": {"name": "Charlie"},
    "user:3": {"name": "David"}
}

for key, value in batch_data.items():
    cache.put(key, value)

# è·å–ç»Ÿè®¡ä¿¡æ¯
stats = cache.get_stats()
print(f"Hit Rate: {stats['hit_rate']:.3f}")
print(f"Cache Size: {stats['size']}")
print(f"Memory Usage: {stats['memory_usage']:.2f} MB")
```

### 2. æŒ‡æ ‡æ”¶é›†ç³»ç»Ÿ

å®æ—¶æ”¶é›†å’Œåˆ†æç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡ã€‚

```python
# è·å–æŒ‡æ ‡åç«¯
metrics = areal_manager.get_metrics()

# è®°å½•æŒ‡æ ‡
metrics.record_metric("api.response_time", 0.15, {"endpoint": "/users"})
metrics.record_metric("system.cpu_usage", 65.5, {"node": "server-1"})
metrics.record_metric("cache.hit_rate", 0.85, {"cache": "user_cache"})

# æŸ¥è¯¢æŒ‡æ ‡
recent_metrics = metrics.get_metrics(name="api.response_time")
endpoint_metrics = metrics.get_metrics(tags={"endpoint": "/users"})

# èšåˆæŒ‡æ ‡
avg_response_time = metrics.aggregate_metrics("api.response_time", "avg", 300)
max_cpu_usage = metrics.aggregate_metrics("system.cpu_usage", "max", 600)
```

### 3. ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿ

å¼‚æ­¥ä»»åŠ¡è°ƒåº¦å’Œæ‰§è¡Œç®¡ç†ã€‚

```python
# è·å–ä»»åŠ¡è°ƒåº¦å™¨
scheduler = areal_manager.get_scheduler()

# å®šä¹‰ä»»åŠ¡
def process_user_data(user_id):
    # æ¨¡æ‹Ÿæ•°æ®å¤„ç†
    time.sleep(0.1)
    return {"user_id": user_id, "processed": True}

def generate_report(report_type):
    # æ¨¡æ‹ŸæŠ¥å‘Šç”Ÿæˆ
    time.sleep(0.5)
    return {"report_type": report_type, "generated": True}

# æäº¤ä»»åŠ¡
task_ids = []
for i in range(5):
    task_id = scheduler.submit_task(f"process_user_{i}", 
                                   lambda x=i: process_user_data(x))
    task_ids.append(task_id)

# æäº¤é«˜ä¼˜å…ˆçº§ä»»åŠ¡
report_task_id = scheduler.submit_task("generate_report", 
                                      lambda: generate_report("daily"))

# ç›‘æ§ä»»åŠ¡çŠ¶æ€
for task_id in task_ids:
    status = scheduler.get_task_status(task_id)
    print(f"Task {task_id}: {status}")

# è·å–ä»»åŠ¡ç»“æœ
for task_id in task_ids:
    result = scheduler.get_task_result(task_id)
    if result:
        print(f"Task {task_id} result: {result}")
```

### 4. åˆ†å¸ƒå¼ç®¡ç†ç³»ç»Ÿ

ç®¡ç†åˆ†å¸ƒå¼èŠ‚ç‚¹å’Œä»»åŠ¡åˆ†å‘ã€‚

```python
# è·å–åˆ†å¸ƒå¼ç®¡ç†å™¨
distributed_manager = areal_manager.get_distributed_manager()

# æ³¨å†ŒèŠ‚ç‚¹
node_configs = [
    {"cpu_cores": 8, "memory_gb": 16, "gpu_count": 1, "location": "us-east"},
    {"cpu_cores": 4, "memory_gb": 8, "gpu_count": 0, "location": "us-west"},
    {"cpu_cores": 16, "memory_gb": 32, "gpu_count": 2, "location": "eu-west"}
]

for i, config in enumerate(node_configs):
    node_id = f"node_{i+1}"
    success = distributed_manager.register_node(node_id, config)
    print(f"Registered {node_id}: {'âœ…' if success else 'âŒ'}")

# åˆ†å‘ä»»åŠ¡
task_data = {
    "type": "computation",
    "parameters": {"iterations": 1000, "complexity": "high"},
    "priority": "high",
    "target_nodes": ["node_1", "node_3"]  # æŒ‡å®šç›®æ ‡èŠ‚ç‚¹
}

task_ids = distributed_manager.distribute_task("distributed_task_1", task_data)

# æ”¶é›†ç»“æœ
results = distributed_manager.collect_results(task_ids)
for task_id, result in results.items():
    print(f"Task {task_id}: {result}")
```

### 5. ä¼˜åŒ–ç³»ç»Ÿ

è‡ªé€‚åº”ä¼˜åŒ–ç¼“å­˜ç­–ç•¥å’Œèµ„æºåˆ†é…ã€‚

```python
# è·å–ä¼˜åŒ–å™¨
optimizer = areal_manager.get_optimizer()

# ä¼˜åŒ–ç¼“å­˜ç­–ç•¥
cache_stats = {
    "hit_rate": 0.75,
    "size": 5000,
    "evictions": 100,
    "memory_usage": 2.5
}

optimal_policy = optimizer.optimize_cache_policy(cache_stats)
print(f"Optimal cache policy: {optimal_policy}")

# ä¼˜åŒ–èµ„æºåˆ†é…
resource_usage = {
    "cpu_percent": 65.0,
    "memory_percent": 45.0,
    "disk_percent": 30.0,
    "network_io": 100.0
}

optimal_allocation = optimizer.optimize_resource_allocation(resource_usage)
print(f"Optimal resource allocation: {optimal_allocation}")

# ä¼˜åŒ–æ‰¹æ¬¡å¤§å°
performance_metrics = {
    "avg_response_time": 0.8,
    "throughput": 1000.0,
    "error_rate": 0.02,
    "queue_length": 50
}

optimal_batch_size = optimizer.optimize_batch_size(performance_metrics)
print(f"Optimal batch size: {optimal_batch_size}")
```

## ğŸ”„ ä¸SandGraphXé›†æˆ

### 1. åœ¨Workflowä¸­ä½¿ç”¨AReaL

```python
from sandgraph.core.sg_workflow import SG_Workflow, WorkflowMode, NodeType
from sandgraph.core.areal_integration import create_areal_integration

# åˆ›å»ºAReaLé›†æˆç®¡ç†å™¨
areal_manager = create_areal_integration(
    integration_level=IntegrationLevel.ADVANCED,
    cache_size=10000,
    max_memory_gb=8.0
)

# åˆ›å»ºWorkflow
workflow = SG_Workflow("areal_workflow", WorkflowMode.TRADITIONAL, llm_manager)

# æ·»åŠ ä½¿ç”¨AReaLç¼“å­˜çš„èŠ‚ç‚¹
class ArealCachedNode:
    def __init__(self, areal_manager):
        self.cache = areal_manager.get_cache()
        self.metrics = areal_manager.get_metrics()
    
    def process(self, data):
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"processed_{hash(str(data))}"
        cached_result = self.cache.get(cache_key)
        
        if cached_result:
            self.metrics.record_metric("cache.hit", 1.0)
            return cached_result
        
        # å¤„ç†æ•°æ®
        result = self._process_data(data)
        
        # ç¼“å­˜ç»“æœ
        self.cache.put(cache_key, result)
        self.metrics.record_metric("cache.miss", 1.0)
        
        return result
    
    def _process_data(self, data):
        # å®é™…çš„æ•°æ®å¤„ç†é€»è¾‘
        return {"processed": data, "timestamp": time.time()}

# æ·»åŠ èŠ‚ç‚¹åˆ°workflow
workflow.add_node(NodeType.SANDBOX, "cached_processor", 
                 {"sandbox": ArealCachedNode(areal_manager)})
```

### 2. åœ¨RLè®­ç»ƒä¸­ä½¿ç”¨AReaL

```python
from sandgraph.core.enhanced_rl_algorithms import EnhancedRLTrainer
from sandgraph.core.areal_integration import create_areal_integration

# åˆ›å»ºAReaLé›†æˆç®¡ç†å™¨
areal_manager = create_areal_integration(
    integration_level=IntegrationLevel.ADVANCED,
    enable_optimization=True
)

# åˆ›å»ºå¢å¼ºRLè®­ç»ƒå™¨
rl_trainer = EnhancedRLTrainer(config, llm_manager)

# ä½¿ç”¨AReaLç¼“å­˜ä¼˜åŒ–è®­ç»ƒ
def optimized_training_step(trajectory):
    # ç¼“å­˜è½¨è¿¹æ•°æ®
    cache = areal_manager.get_cache()
    cache_key = f"trajectory_{hash(str(trajectory))}"
    
    cached_result = cache.get(cache_key)
    if cached_result:
        return cached_result
    
    # æ‰§è¡Œè®­ç»ƒæ­¥éª¤
    result = rl_trainer.update_policy(trajectory)
    
    # ç¼“å­˜ç»“æœ
    cache.put(cache_key, result)
    
    # è®°å½•æŒ‡æ ‡
    metrics = areal_manager.get_metrics()
    metrics.record_metric("rl.training_loss", result.get("loss", 0.0))
    metrics.record_metric("rl.training_time", result.get("time", 0.0))
    
    return result
```

### 3. åœ¨ç›‘æ§ç³»ç»Ÿä¸­ä½¿ç”¨AReaL

```python
from sandgraph.core.monitoring import SocialNetworkMonitor
from sandgraph.core.areal_integration import create_areal_integration

# åˆ›å»ºAReaLé›†æˆç®¡ç†å™¨
areal_manager = create_areal_integration(
    integration_level=IntegrationLevel.BASIC,
    enable_metrics=True
)

# åˆ›å»ºç›‘æ§å™¨
monitor = SocialNetworkMonitor(config)

# ä½¿ç”¨AReaLæŒ‡æ ‡æ”¶é›†
metrics = areal_manager.get_metrics()

def enhanced_monitoring_callback(metrics_data):
    # è®°å½•åˆ°AReaLæŒ‡æ ‡ç³»ç»Ÿ
    metrics.record_metric("network.total_users", metrics_data.total_users)
    metrics.record_metric("network.engagement_rate", metrics_data.engagement_rate)
    metrics.record_metric("network.response_time", metrics_data.response_time_avg)
    
    # è®°å½•åˆ°SandGraphXç›‘æ§ç³»ç»Ÿ
    monitor.update_metrics(metrics_data)

# è®¾ç½®å›è°ƒ
monitor.set_callback(enhanced_monitoring_callback)
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. ç¼“å­˜ä¼˜åŒ–ç­–ç•¥

```python
# æ ¹æ®è®¿é—®æ¨¡å¼é€‰æ‹©ç¼“å­˜ç­–ç•¥
def optimize_cache_strategy(access_pattern):
    if access_pattern == "frequent_small":
        return "lru"  # æœ€è¿‘æœ€å°‘ä½¿ç”¨
    elif access_pattern == "frequent_large":
        return "lfu"  # æœ€å°‘ä½¿ç”¨
    elif access_pattern == "random":
        return "adaptive"  # è‡ªé€‚åº”
    else:
        return "priority"  # ä¼˜å…ˆçº§

# åŠ¨æ€è°ƒæ•´ç¼“å­˜å¤§å°
def adjust_cache_size(usage_stats):
    hit_rate = usage_stats.get("hit_rate", 0.0)
    memory_usage = usage_stats.get("memory_usage", 0.0)
    
    if hit_rate < 0.5 and memory_usage < 0.7:
        return "increase"  # å¢åŠ ç¼“å­˜å¤§å°
    elif hit_rate > 0.9 or memory_usage > 0.9:
        return "decrease"  # å‡å°‘ç¼“å­˜å¤§å°
    else:
        return "maintain"  # ä¿æŒå½“å‰å¤§å°
```

### 2. ä»»åŠ¡è°ƒåº¦ä¼˜åŒ–

```python
# æ ¹æ®ä»»åŠ¡ç±»å‹è®¾ç½®ä¼˜å…ˆçº§
def set_task_priority(task_type, task_data):
    if task_type == "critical":
        return "high"
    elif task_type == "batch":
        return "low"
    elif task_type == "interactive":
        return "normal"
    else:
        return "normal"

# æ‰¹é‡å¤„ç†ä¼˜åŒ–
def batch_process_tasks(tasks, batch_size=10):
    scheduler = areal_manager.get_scheduler()
    results = []
    
    for i in range(0, len(tasks), batch_size):
        batch = tasks[i:i+batch_size]
        batch_results = []
        
        for task in batch:
            task_id = scheduler.submit_task(f"batch_task_{i}", task)
            batch_results.append(task_id)
        
        # ç­‰å¾…æ‰¹æ¬¡å®Œæˆ
        time.sleep(0.1)
        
        for task_id in batch_results:
            result = scheduler.get_task_result(task_id)
            results.append(result)
    
    return results
```

### 3. åˆ†å¸ƒå¼ä¼˜åŒ–

```python
# æ™ºèƒ½èŠ‚ç‚¹é€‰æ‹©
def select_optimal_nodes(task_requirements, available_nodes):
    selected_nodes = []
    
    for node_id, node_config in available_nodes.items():
        if (node_config["cpu_cores"] >= task_requirements["min_cpu"] and
            node_config["memory_gb"] >= task_requirements["min_memory"]):
            selected_nodes.append(node_id)
    
    # æŒ‰è´Ÿè½½æ’åº
    selected_nodes.sort(key=lambda x: available_nodes[x].get("load", 0))
    
    return selected_nodes[:task_requirements["max_nodes"]]

# è´Ÿè½½å‡è¡¡
def balance_load(tasks, nodes):
    distributed_manager = areal_manager.get_distributed_manager()
    
    # è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„è´Ÿè½½
    node_loads = {}
    for node_id in nodes:
        node_loads[node_id] = 0
    
    # åˆ†é…ä»»åŠ¡
    for task in tasks:
        # é€‰æ‹©è´Ÿè½½æœ€ä½çš„èŠ‚ç‚¹
        target_node = min(node_loads, key=node_loads.get)
        node_loads[target_node] += 1
        
        # åˆ†å‘ä»»åŠ¡
        distributed_manager.distribute_task(task["id"], task["data"], [target_node])
```

## ğŸ›¡ï¸ å®¹é”™å’Œç›‘æ§

### 1. é”™è¯¯å¤„ç†

```python
# ç¼“å­˜é”™è¯¯å¤„ç†
def safe_cache_operation(cache, operation, *args, **kwargs):
    try:
        if operation == "get":
            return cache.get(*args, **kwargs)
        elif operation == "put":
            return cache.put(*args, **kwargs)
        elif operation == "delete":
            return cache.delete(*args, **kwargs)
    except Exception as e:
        logger.error(f"Cache operation failed: {e}")
        return None

# ä»»åŠ¡é‡è¯•æœºåˆ¶
def retry_task(task_func, max_retries=3, delay=1.0):
    for attempt in range(max_retries):
        try:
            return task_func()
        except Exception as e:
            if attempt == max_retries - 1:
                raise e
            time.sleep(delay * (2 ** attempt))  # æŒ‡æ•°é€€é¿
```

### 2. å¥åº·æ£€æŸ¥

```python
# ç³»ç»Ÿå¥åº·æ£€æŸ¥
def health_check(areal_manager):
    health_status = {
        "cache": False,
        "metrics": False,
        "scheduler": False,
        "distributed": False,
        "optimizer": False
    }
    
    try:
        # æ£€æŸ¥ç¼“å­˜
        cache = areal_manager.get_cache()
        if cache:
            cache.put("health_check", "ok")
            result = cache.get("health_check")
            health_status["cache"] = (result == "ok")
    except Exception as e:
        logger.error(f"Cache health check failed: {e}")
    
    try:
        # æ£€æŸ¥æŒ‡æ ‡æ”¶é›†
        metrics = areal_manager.get_metrics()
        if metrics:
            metrics.record_metric("health_check", 1.0)
            health_status["metrics"] = True
    except Exception as e:
        logger.error(f"Metrics health check failed: {e}")
    
    return health_status
```

### 3. æ€§èƒ½ç›‘æ§

```python
# æ€§èƒ½ç›‘æ§è£…é¥°å™¨
def monitor_performance(metric_name):
    def decorator(func):
        def wrapper(*args, **kwargs):
            metrics = areal_manager.get_metrics()
            start_time = time.time()
            
            try:
                result = func(*args, **kwargs)
                success = True
            except Exception as e:
                success = False
                raise e
            finally:
                end_time = time.time()
                duration = end_time - start_time
                
                if metrics:
                    metrics.record_metric(f"{metric_name}.duration", duration)
                    metrics.record_metric(f"{metric_name}.success", 1.0 if success else 0.0)
            
            return result
        return wrapper
    return decorator

# ä½¿ç”¨ç›‘æ§è£…é¥°å™¨
@monitor_performance("user_processing")
def process_user(user_data):
    # ç”¨æˆ·å¤„ç†é€»è¾‘
    time.sleep(0.1)
    return {"processed": True}
```

## ğŸš€ æœ€ä½³å®è·µ

### 1. é…ç½®ä¼˜åŒ–

```python
# æ ¹æ®åº”ç”¨åœºæ™¯ä¼˜åŒ–é…ç½®
def get_optimal_config(application_type):
    configs = {
        "web_service": {
            "cache_size": 50000,
            "max_memory_gb": 8.0,
            "integration_level": IntegrationLevel.ADVANCED,
            "enable_optimization": True
        },
        "batch_processing": {
            "cache_size": 10000,
            "max_memory_gb": 16.0,
            "integration_level": IntegrationLevel.FULL,
            "enable_distributed": True
        },
        "real_time": {
            "cache_size": 1000,
            "max_memory_gb": 2.0,
            "integration_level": IntegrationLevel.BASIC,
            "enable_metrics": True
        }
    }
    
    return configs.get(application_type, configs["web_service"])
```

### 2. èµ„æºç®¡ç†

```python
# èµ„æºä½¿ç”¨ç›‘æ§
def monitor_resource_usage(areal_manager):
    stats = areal_manager.get_stats()
    
    # æ£€æŸ¥å†…å­˜ä½¿ç”¨
    cache_stats = stats.get("cache_stats", {})
    memory_usage = cache_stats.get("memory_usage", 0)
    
    if memory_usage > 0.8:  # 80%å†…å­˜ä½¿ç”¨ç‡
        logger.warning("High memory usage detected")
        # æ¸…ç†ç¼“å­˜
        cache = areal_manager.get_cache()
        if cache:
            cache.clear()
    
    # æ£€æŸ¥æŒ‡æ ‡æ•°é‡
    metrics_summary = stats.get("metrics_summary", {})
    total_metrics = metrics_summary.get("total_metrics", 0)
    
    if total_metrics > 100000:  # 10ä¸‡æ¡æŒ‡æ ‡
        logger.info("Large number of metrics, consider archiving")
```

### 3. æ‰©å±•æ€§è®¾è®¡

```python
# å¯æ‰©å±•çš„ç¼“å­˜ç­–ç•¥
class AdaptiveCacheStrategy:
    def __init__(self, areal_manager):
        self.areal_manager = areal_manager
        self.cache = areal_manager.get_cache()
        self.optimizer = areal_manager.get_optimizer()
    
    def get(self, key):
        # æ ¹æ®è®¿é—®æ¨¡å¼è°ƒæ•´ç­–ç•¥
        access_pattern = self._analyze_access_pattern(key)
        optimal_policy = self.optimizer.optimize_cache_policy({
            "access_pattern": access_pattern,
            "hit_rate": self.cache.get_stats().get("hit_rate", 0.0)
        })
        
        return self.cache.get(key)
    
    def _analyze_access_pattern(self, key):
        # åˆ†æè®¿é—®æ¨¡å¼
        return "frequent"  # ç®€åŒ–ç¤ºä¾‹
```

## ğŸ“š ç¤ºä¾‹å’Œæ¼”ç¤º

### è¿è¡Œæ¼”ç¤º

```bash
# è¿è¡ŒåŸºç¡€æ¼”ç¤º
python demo/enhanced_areal_integration_demo.py --demo basic

# è¿è¡Œé«˜çº§æ¼”ç¤º
python demo/enhanced_areal_integration_demo.py --demo advanced

# è¿è¡Œå®Œæ•´æ¼”ç¤º
python demo/enhanced_areal_integration_demo.py --demo full

# è¿è¡Œæ€§èƒ½å¯¹æ¯”
python demo/enhanced_areal_integration_demo.py --demo performance

# è¿è¡Œæ‰€æœ‰æ¼”ç¤º
python demo/enhanced_areal_integration_demo.py --demo all
```

### è‡ªå®šä¹‰é…ç½®

```python
# åˆ›å»ºè‡ªå®šä¹‰AReaLé›†æˆ
custom_areal_manager = create_areal_integration(
    integration_level=IntegrationLevel.FULL,
    cache_size=50000,
    max_memory_gb=16.0,
    enable_distributed=True,
    enable_optimization=True
)

# è¿è¡Œè‡ªå®šä¹‰æ¼”ç¤º
python demo/enhanced_areal_integration_demo.py \
    --demo advanced \
    --cache-size 50000 \
    --max-memory 16.0
```

## ğŸ”— ç›¸å…³èµ„æº

- [AReaLå®˜æ–¹æ–‡æ¡£](https://github.com/inclusionAI/AReaL)
- [SandGraphX APIå‚è€ƒ](api_reference.md)
- [ç›‘æ§æŒ‡å—](monitoring_guide.md)
- [æ€§èƒ½ä¼˜åŒ–æŒ‡å—](performance_optimization_guide.md)

## ğŸ†˜ å¸¸è§é—®é¢˜

### Q: AReaLæ¡†æ¶ä¸å¯ç”¨æ—¶æ€ä¹ˆåŠï¼Ÿ
A: SandGraphXæä¾›äº†å®Œæ•´çš„å¤‡ç”¨å®ç°ï¼Œå³ä½¿AReaLä¸å¯ç”¨ä¹Ÿèƒ½æ­£å¸¸å·¥ä½œã€‚

### Q: å¦‚ä½•é€‰æ‹©åˆé€‚çš„é›†æˆçº§åˆ«ï¼Ÿ
A: æ ¹æ®åº”ç”¨åœºæ™¯é€‰æ‹©ï¼šåŸºç¡€åº”ç”¨ç”¨BASICï¼Œå¤æ‚åº”ç”¨ç”¨ADVANCEDï¼Œä¼ä¸šçº§åº”ç”¨ç”¨FULLã€‚

### Q: å¦‚ä½•ä¼˜åŒ–ç¼“å­˜æ€§èƒ½ï¼Ÿ
A: ç›‘æ§å‘½ä¸­ç‡ï¼Œæ ¹æ®è®¿é—®æ¨¡å¼è°ƒæ•´ç¼“å­˜ç­–ç•¥ï¼Œå®šæœŸæ¸…ç†è¿‡æœŸæ•°æ®ã€‚

### Q: å¦‚ä½•å¤„ç†åˆ†å¸ƒå¼èŠ‚ç‚¹æ•…éšœï¼Ÿ
A: å®ç°èŠ‚ç‚¹å¥åº·æ£€æŸ¥ï¼Œè‡ªåŠ¨æ•…éšœè½¬ç§»ï¼Œä»»åŠ¡é‡è¯•æœºåˆ¶ã€‚

### Q: å¦‚ä½•ç›‘æ§AReaLé›†æˆçŠ¶æ€ï¼Ÿ
A: ä½¿ç”¨`get_stats()`æ–¹æ³•è·å–è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ï¼Œå®šæœŸæ£€æŸ¥å¥åº·çŠ¶æ€ã€‚ 